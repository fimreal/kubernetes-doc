<!doctype html>
<html lang="zh" class="no-js">
  <head>
    

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-36037335-10"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-36037335-10');
</script>


<link rel="alternate" hreflang="en" href="https://kubernetes.io/docs/tasks/debug-application-cluster/">
<link rel="alternate" hreflang="ko" href="https://kubernetes.io/ko/docs/tasks/debug-application-cluster/">
<link rel="alternate" hreflang="ja" href="https://kubernetes.io/ja/docs/tasks/debug-application-cluster/">
<link rel="alternate" hreflang="fr" href="https://kubernetes.io/fr/docs/tasks/debug-application-cluster/">
<link rel="alternate" hreflang="de" href="https://kubernetes.io/de/docs/tasks/debug-application-cluster/">
<link rel="alternate" hreflang="es" href="https://kubernetes.io/es/docs/tasks/debug-application-cluster/">
<link rel="alternate" hreflang="id" href="https://kubernetes.io/id/docs/tasks/debug-application-cluster/">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.88.1" />

<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">

<link rel="canonical" type="text/html" href="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/">
<link rel="shortcut icon" type="image/png" href="/images/favicon.png">
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="manifest" href="/manifest.webmanifest">
<link rel="apple-touch-icon" href="/images/kubernetes-192x192.png">
<title>监控、日志和排错 | Kubernetes</title><meta property="og:title" content="监控、日志和排错" />
<meta property="og:description" content="设置监视和日志记录以对集群进行故障排除或调试容器化应用。" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/" /><meta property="og:site_name" content="Kubernetes" />

<meta itemprop="name" content="监控、日志和排错">
<meta itemprop="description" content="设置监视和日志记录以对集群进行故障排除或调试容器化应用。"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="监控、日志和排错"/>
<meta name="twitter:description" content="设置监视和日志记录以对集群进行故障排除或调试容器化应用。"/>





<link rel="preload" href="/scss/main.min.0bda2f3af46d1514ab4d3cad78295716cfd9557a35a41868b7db38040502bb54.css" as="style">
<link href="/scss/main.min.0bda2f3af46d1514ab4d3cad78295716cfd9557a35a41868b7db38040502bb54.css" rel="stylesheet" integrity="">


<script
  src="/js/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>





<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "url": "https://kubernetes.io",
    "logo": "https://kubernetes.io/images/favicon.png",
    "potentialAction": {
      "@type": "SearchAction",
      "target": "https://kubernetes.io/search/?q={search_term_string}",
      "query-input": "required name=search_term_string"
    }

  }
</script>
<meta name="theme-color" content="#326ce5">




<link rel="stylesheet" href="/css/feature-states.css">



<meta name="description" content="设置监视和日志记录以对集群进行故障排除或调试容器化应用。">
<meta property="og:description" content="设置监视和日志记录以对集群进行故障排除或调试容器化应用。">
<meta name="twitter:description" content="设置监视和日志记录以对集群进行故障排除或调试容器化应用。">
<meta property="og:url" content="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/">
<meta property="og:title" content="监控、日志和排错">
<meta name="twitter:title" content="监控、日志和排错">
<meta name="twitter:image" content="https://kubernetes.io/images/favicon.png" />

<meta name="twitter:image:alt" content="Kubernetes">

<meta property="og:image" content="/images/kubernetes-horizontal-color.png">

<meta property="og:type" content="article">



<script src="/js/script.js"></script>


  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark  flex-row td-navbar" data-auto-burger="primary">
        <a class="navbar-brand" href="/zh/"></a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link active" href="/zh/docs/" >文档</span></a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/blog/" >Kubernetes 博客</span></a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/training/" >培训</span></a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/partners/" >合作伙伴</span></a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/community/" >社区</span></a>
			</li>
			
			
			
			<li class="nav-item mr-2 mb-lg-0">
				
				<a class="nav-link" href="/zh/case-studies/" >案例分析</span></a>
			</li>
			
			
			
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	版本列表
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/releases">Release Information</a>
	
	<a class="dropdown-item" href="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/">v1.22</a>
	
	<a class="dropdown-item" href="https://v1-21.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/">v1.21</a>
	
	<a class="dropdown-item" href="https://v1-20.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/">v1.20</a>
	
	<a class="dropdown-item" href="https://v1-19.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/">v1.19</a>
	
	<a class="dropdown-item" href="https://v1-18.docs.kubernetes.io/zh/docs/tasks/debug-application-cluster/">v1.18</a>
	
</div>
			</li>
			
			
			<li class="nav-item dropdown">
				

<a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
	中文 Chinese
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownMenuLink">
	
	<a class="dropdown-item" href="/docs/tasks/debug-application-cluster/">English</a>
	
	<a class="dropdown-item" href="/ko/docs/tasks/debug-application-cluster/">한국어 Korean</a>
	
	<a class="dropdown-item" href="/ja/docs/tasks/debug-application-cluster/">日本語 Japanese</a>
	
	<a class="dropdown-item" href="/fr/docs/tasks/debug-application-cluster/">Français</a>
	
	<a class="dropdown-item" href="/de/docs/tasks/debug-application-cluster/">Deutsch</a>
	
	<a class="dropdown-item" href="/es/docs/tasks/debug-application-cluster/">Español</a>
	
	<a class="dropdown-item" href="/id/docs/tasks/debug-application-cluster/">Bahasa Indonesia</a>
	
</div>

			</li>
			
		</ul>
	</div>
	<button id="hamburger" onclick="kub.toggleMenu()" data-auto-burger-exclude><div></div></button>
</nav>
    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
          </div>
          <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
          </div>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href="#" onclick="print();return false;">点击此处打印</a>.
</p><p>
<a href="/zh/docs/tasks/debug-application-cluster/">返回本页常规视图</a>.
</p>
</div>



<h1 class="title">监控、日志和排错</h1>
<div class="lead">设置监视和日志记录以对集群进行故障排除或调试容器化应用。</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-5e4a82f171ec2c11da7360a67efb4abf">使用 crictl 对 Kubernetes 节点进行调试</a></li>


    
  
    
    
	
<li>2: <a href="#pg-d25a16285195bd17d9055b1eb7bc605c">在本地开发和调试服务</a></li>


    
  
    
    
	
<li>3: <a href="#pg-cbd33a50cc4779f855318a0dd00d7b06">审计</a></li>


    
  
    
    
	
<li>4: <a href="#pg-3556c4dbd027b9e90a5b3d72649003fb">应用故障排查</a></li>


    
  
    
    
	
<li>5: <a href="#pg-731bb8b338c16aebfb9590ba2bd3fdd1">应用自测与调试</a></li>


    
  
    
    
	
<li>6: <a href="#pg-434e0133d71583a27478b10fc1d3d105">故障诊断</a></li>


    
  
    
    
	
<li>7: <a href="#pg-ef360b1f8e65236251826db478cfcab3">确定 Pod 失败的原因</a></li>


    
  
    
    
	
<li>8: <a href="#pg-bc729eafe3688124d3a6f1110bd5a89c">节点健康监测</a></li>


    
  
    
    
	
<li>9: <a href="#pg-9713ac27b6d9e3034033200d968221f2">获取正在运行容器的 Shell</a></li>


    
  
    
    
	
<li>10: <a href="#pg-06bb252f25983de12f635c806d180d30">调试 Init 容器</a></li>


    
  
    
    
	
<li>11: <a href="#pg-858517cd46a1b5a1fd2e650edd785cea">调试 Pods 和 ReplicationControllers</a></li>


    
  
    
    
	
<li>12: <a href="#pg-f79645981e310858111bd5673614cab6">调试 Service</a></li>


    
  
    
    
	
<li>13: <a href="#pg-a070b1250ee142402d492b505a56ca83">调试StatefulSet</a></li>


    
  
    
    
	
<li>14: <a href="#pg-c0ec963f381296ca26b839cdf0a6f242">调试运行中的 Pod</a></li>


    
  
    
    
	
<li>15: <a href="#pg-96b25d30e732385047272b84d3c4188f">资源指标管道</a></li>


    
  
    
    
	
<li>16: <a href="#pg-9e6e1b706f11386fe2c4b4ffda1409e4">资源监控工具</a></li>


    
  
    
    
	
<li>17: <a href="#pg-47290c80fb8b00accec6729f3da49734">集群故障排查</a></li>


    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-5e4a82f171ec2c11da7360a67efb4abf">1 - 使用 crictl 对 Kubernetes 节点进行调试</h1>
    
	<!--
reviewers:
- Random-Liu
- feiskyer
- mrunalp
title: Debugging Kubernetes nodes with crictl
content_type: task
-->
<!-- overview -->





<div style="margin-top: 10px; margin-bottom: 10px;">
<b>FEATURE STATE:</b> <code>Kubernetes v1.11 [stable]</code>
</div>

<!--
`crictl` is a command-line interface for CRI-compatible container runtimes.
You can use it to inspect and debug container runtimes and applications on a
Kubernetes node. `crictl` and its source are hosted in the
[cri-tools](https://github.com/kubernetes-sigs/cri-tools) repository.
-->
<p><code>crictl</code> 是 CRI 兼容的容器运行时命令行接口。
你可以使用它来检查和调试 Kubernetes 节点上的容器运行时和应用程序。
<code>crictl</code> 和它的源代码在
<a href="https://github.com/kubernetes-sigs/cri-tools">cri-tools</a> 代码库。</p>
<h2 id="准备开始">准备开始</h2>
<!--
`crictl` requires a Linux operating system with a CRI runtime.
-->
<p><code>crictl</code> 需要带有 CRI 运行时的 Linux 操作系统。</p>
<!-- steps -->
<!--
## Installing crictl

You can download a compressed archive `crictl` from the cri-tools [release
page](https://github.com/kubernetes-sigs/cri-tools/releases), for several
different architectures. Download the version that corresponds to your version
of Kubernetes. Extract it and move it to a location on your system path, such as
`/usr/local/bin/`.
-->
<h2 id="安装-crictl">安装 crictl</h2>
<p>你可以从 cri-tools <a href="https://github.com/kubernetes-sigs/cri-tools/releases">发布页面</a>
下载一个压缩的 <code>crictl</code> 归档文件，用于几种不同的架构。
下载与你的 kubernetes 版本相对应的版本。
提取它并将其移动到系统路径上的某个位置，例如<code>/usr/local/bin/</code>。</p>
<!--
## General usage

The `crictl` command has several subcommands and runtime flags. Use
`crictl help` or `crictl <subcommand> help` for more details.
-->
<h2 id="一般用法">一般用法</h2>
<p><code>crictl</code> 命令有几个子命令和运行时参数。
有关详细信息，请使用 <code>crictl help</code> 或 <code>crictl &lt;subcommand&gt; help</code> 获取帮助信息。</p>
<!--
`crictl` connects to `unix:///var/run/dockershim.sock` by default. For other
runtimes, you can set the endpoint in multiple different ways:
-->
<p><code>crictl</code> 默认连接到 <code>unix:///var/run/dockershim.sock</code>。
对于其他的运行时，你可以用多种不同的方法设置端点：</p>
<!--
- By setting flags `--runtime-endpoint` and `--image-endpoint`
- By setting environment variables `CONTAINER_RUNTIME_ENDPOINT` and `IMAGE_SERVICE_ENDPOINT`
- By setting the endpoint in the config file `--config=/etc/crictl.yaml`
-->
<ul>
<li>通过设置参数 <code>--runtime-endpoint</code> 和 <code>--image-endpoint</code></li>
<li>通过设置环境变量 <code>CONTAINER_RUNTIME_ENDPOINT</code> 和 <code>IMAGE_SERVICE_ENDPOINT</code></li>
<li>通过在配置文件中设置端点 <code>--config=/etc/crictl.yaml</code></li>
</ul>
<!--
You can also specify timeout values when connecting to the server and enable or
disable debugging, by specifying `timeout` or `debug` values in the configuration
file or using the `--timeout` and `--debug` command-line flags.
-->
<p>你还可以在连接到服务器并启用或禁用调试时指定超时值，方法是在配置文件中指定
<code>timeout</code> 或 <code>debug</code> 值，或者使用 <code>--timeout</code> 和 <code>--debug</code> 命令行参数。</p>
<!--
To view or edit the current configuration, view or edit the contents of
`/etc/crictl.yaml`.
-->
<p>要查看或编辑当前配置，请查看或编辑 <code>/etc/crictl.yaml</code> 的内容。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">cat /etc/crictl.yaml
</code></pre></div><pre tabindex="0"><code>runtime-endpoint: unix:///var/run/dockershim.sock
image-endpoint: unix:///var/run/dockershim.sock
timeout: 10
debug: true
</code></pre><!--
## Example crictl commands

The following examples show some `crictl` commands and example output.
-->
<h2 id="crictl-命令示例">crictl 命令示例</h2>
<blockquote class="warning callout">
  <div><strong>警告：</strong> <!--
If you use `crictl` to create pod sandboxes or containers on a running
Kubernetes cluster, the Kubelet will eventually delete them. `crictl` is not a
general purpose workflow tool, but a tool that is useful for debugging.
-->
<p>如果使用 <code>crictl</code> 在正在运行的 Kubernetes 集群上创建 Pod 沙盒或容器，
kubelet 最终将删除它们。
<code>crictl</code> 不是一个通用的工作流工具，而是一个对调试有用的工具。</div>
</blockquote>

<!--
### List pods

List all pods:
-->
<h3 id="打印-pod-清单">打印 Pod 清单</h3>
<p>打印所有 Pod 的清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl pods
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">POD ID              CREATED              STATE               NAME                         NAMESPACE           ATTEMPT
926f1b5a1d33a       About a minute ago   Ready               sh-84d7dcf559-4r2gq          default             0
4dccb216c4adb       About a minute ago   Ready               nginx-65899c769f-wv2gp       default             0
a86316e96fa89       17 hours ago         Ready               kube-proxy-gblk4             kube-system         0
919630b8f81f1       17 hours ago         Ready               nvidia-device-plugin-zgbbv   kube-system         0
</code></pre><!--
List pods by name:
-->
<p>根据名称打印 Pod 清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl pods --name nginx-65899c769f-wv2gp
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT
4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0
</code></pre><!--
List pods by label:
-->
<p>根据标签打印 Pod 清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl pods --label <span style="color:#b8860b">run</span><span style="color:#666">=</span>nginx
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT
4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0
</code></pre><!--
### List images

List all images:
-->
<h3 id="打印镜像清单">打印镜像清单</h3>
<p>打印所有镜像清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl images
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">IMAGE                                     TAG                 IMAGE ID            SIZE
busybox                                   latest              8c811b4aec35f       1.15MB
k8s-gcrio.azureedge.net/hyperkube-amd64   v1.10.3             e179bbfe5d238       665MB
k8s-gcrio.azureedge.net/pause-amd64       3.1                 da86e6ba6ca19       742kB
nginx                                     latest              cd5239a0906a6       109MB
</code></pre><!--
List images by repository:
-->
<p>根据仓库打印镜像清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl images nginx
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">IMAGE               TAG                 IMAGE ID            SIZE
nginx               latest              cd5239a0906a6       109MB
</code></pre><!--
Only list image IDs:
-->
<p>只打印镜像 ID：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl images -q
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">sha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a
sha256:e179bbfe5d238de6069f3b03fccbecc3fb4f2019af741bfff1233c4d7b2970c5
sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e
sha256:cd5239a0906a6ccf0562354852fae04bc5b52d72a2aff9a871ddb6bd57553569
</code></pre><!--
### List containers

List all containers:
-->
<h3 id="打印容器清单">打印容器清单</h3>
<p>打印所有容器清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl ps -a
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT
1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   7 minutes ago       Running             sh                         1
9c5951df22c78       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   8 minutes ago       Exited              sh                         0
87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     8 minutes ago       Running             nginx                      0
1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   18 hours ago        Running             kube-proxy                 0
</code></pre><!--
List running containers:
-->
<p>打印正在运行的容器清单：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl ps
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT
1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   6 minutes ago       Running             sh                         1
87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     7 minutes ago       Running             nginx                      0
1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   17 hours ago        Running             kube-proxy                 0
</code></pre><!--
### Execute a command in a running container
-->
<h3 id="在正在运行的容器上执行命令">在正在运行的容器上执行命令</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl <span style="color:#a2f">exec</span> -i -t 1f73f2d81bf98 ls
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">bin   dev   etc   home  proc  root  sys   tmp   usr   var
</code></pre><!--
### Get a container's logs

Get all container logs:
-->
<h3 id="获取容器日志">获取容器日志</h3>
<p>获取容器的所有日志：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl logs 87d3992f84f74
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">10.240.0.96 - - [06/Jun/2018:02:45:49 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;
10.240.0.96 - - [06/Jun/2018:02:45:50 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;
10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;
</code></pre><!--
Get only the latest `N` lines of logs:
-->
<p>获取最近的 <code>N</code> 行日志：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl logs --tail<span style="color:#666">=</span><span style="color:#666">1</span> 87d3992f84f74
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;
</code></pre><!--
### Run a pod sandbox

Using `crictl` to run a pod sandbox is useful for debugging container runtimes.
On a running Kubernetes cluster, the sandbox will eventually be stopped and
deleted by the Kubelet.
-->
<h3 id="运行-pod-沙盒">运行 Pod 沙盒</h3>
<p>用 <code>crictl</code> 运行 Pod 沙盒对容器运行时排错很有帮助。
在运行的 Kubernetes 集群中，沙盒会随机地被 kubelet 停止和删除。</p>
<ol>
<li>
<!--Create a JSON file like the following:-->
<p>编写下面的 JSON 文件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
    <span style="color:#008000;font-weight:bold">&#34;metadata&#34;</span>: {
        <span style="color:#008000;font-weight:bold">&#34;name&#34;</span>: <span style="color:#b44">&#34;nginx-sandbox&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;namespace&#34;</span>: <span style="color:#b44">&#34;default&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;attempt&#34;</span>: <span style="color:#666">1</span>,
        <span style="color:#008000;font-weight:bold">&#34;uid&#34;</span>: <span style="color:#b44">&#34;hdishd83djaidwnduwk28bcsb&#34;</span>
    },
    <span style="color:#008000;font-weight:bold">&#34;logDirectory&#34;</span>: <span style="color:#b44">&#34;/tmp&#34;</span>,
    <span style="color:#008000;font-weight:bold">&#34;linux&#34;</span>: {
    }
}
</code></pre></div></li>
<li>
<!--Use the `crictl runp` command to apply the JSON and run the sandbox.-->
<p>使用 <code>crictl runp</code> 命令应用 JSON 文件并运行沙盒。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl runp pod-config.json
</code></pre></div><!--The ID of the sandbox is returned.-->
<p>返回了沙盒的 ID。</p>
</li>
</ol>
<!--
### Create a container

Using `crictl` to create a container is useful for debugging container runtimes.
On a running Kubernetes cluster, the sandbox will eventually be stopped and
deleted by the Kubelet.
-->
<h3 id="创建容器">创建容器</h3>
<p>用 <code>crictl</code> 创建容器对容器运行时排错很有帮助。
在运行的 Kubernetes 集群中，沙盒会随机的被 kubelet 停止和删除。</p>
<ol>
<li>
<!--Pull a busybox image-->
<p>拉取 busybox 镜像</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">crictl pull busybox
Image is up to date <span style="color:#a2f;font-weight:bold">for</span> busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47
</code></pre></div></li>
<li>
<!--Create configs for the pod and the container:-->
<p>创建 Pod 和容器的配置：</p>
<!--**Pod config**:-->
<p><strong>Pod 配置</strong>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">{<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">&#34;metadata&#34;: </span>{<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">&#34;name&#34;: </span><span style="color:#b44">&#34;nginx-sandbox&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">&#34;namespace&#34;: </span><span style="color:#b44">&#34;default&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">&#34;attempt&#34;: </span><span style="color:#666">1</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">&#34;uid&#34;: </span><span style="color:#b44">&#34;hdishd83djaidwnduwk28bcsb&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span>},<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">&#34;log_directory&#34;: </span><span style="color:#b44">&#34;/tmp&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">&#34;linux&#34;: </span>{<span style="color:#bbb">
</span><span style="color:#bbb">    </span>}<span style="color:#bbb">
</span><span style="color:#bbb"></span>}<span style="color:#bbb">
</span></code></pre></div><!--**Container config**:-->
<p><strong>容器配置</strong>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">{<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">&#34;metadata&#34;: </span>{<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">&#34;name&#34;: </span><span style="color:#b44">&#34;busybox&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>},<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#b44">&#34;image&#34;</span>:{<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">&#34;image&#34;: </span><span style="color:#b44">&#34;busybox&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>},<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">&#34;command&#34;: </span>[<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#b44">&#34;top&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>],<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#b44">&#34;log_path&#34;</span>:<span style="color:#b44">&#34;busybox.log&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">&#34;linux&#34;: </span>{<span style="color:#bbb">
</span><span style="color:#bbb">  </span>}<span style="color:#bbb">
</span><span style="color:#bbb"></span>}<span style="color:#bbb">
</span></code></pre></div></li>
<li>
<!--Create the container, passing the ID of the previously-created pod, the
container config file, and the pod config file. The ID of the container is
returned.-->
<p>创建容器，传递先前创建的 Pod 的 ID、容器配置文件和 Pod 配置文件。返回容器的 ID。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">crictl create f84dd361f8dc51518ed291fbadd6db537b0496536c1d2d6c05ff943ce8c9a54f container-config.json pod-config.json
</code></pre></div></li>
<li>
<!--List all containers and verify that the newly-created container has its
state set to `Created`.-->
<p>查询所有容器并确认新创建的容器状态为 <code>Created</code>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">crictl ps -a
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">CONTAINER ID        IMAGE               CREATED             STATE               NAME                ATTEMPT
3e025dd50a72d       busybox             32 seconds ago      Created             busybox             0
</code></pre></li>
</ol>
<!--
### Start a container

To start a container, pass its ID to `crictl start`:
-->
<h3 id="启动容器">启动容器</h3>
<p>要启动容器，要将容器 ID 传给 <code>crictl start</code>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl start 3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60
</code></pre><!--
Check the container has its state set to `Running`.
-->
<p>确认容器的状态为 <code>Running</code>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">crictl ps
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">CONTAINER ID        IMAGE               CREATED              STATE               NAME                ATTEMPT
3e025dd50a72d       busybox             About a minute ago   Running             busybox             0
</code></pre><!-- discussion -->
<!--
See [kubernetes-sigs/cri-tools](https://github.com/kubernetes-sigs/cri-tools)
for more information.
-->
<p>更多信息请参考 <a href="https://github.com/kubernetes-sigs/cri-tools">kubernetes-sigs/cri-tools</a>。</p>
<!--
## Mapping from docker cli to crictl
-->
<h2 id="docker-cli-和-crictl-的映射">Docker CLI 和 crictl 的映射</h2>
<!--
The exact versions for below mapping table are for docker cli v1.40 and crictl v1.19.0. Please note that the list is not exhaustive. For example, it doesn't include experimental commands of docker cli.
-->
<p>以下的映射表格只适用于 Docker CLI v1.40 和 crictl v1.19.0 版本。
请注意该表格并不详尽。例如，其中不包含 Docker CLI 的实验性命令。</p>
<!--
<blockquote class="note callout">
  <div><strong>说明：</strong> The output format of CRICTL is similar to Docker CLI, despite some missing columns for some CLI. Make sure to check output for the specific command if your script output parsing.</div>
</blockquote>
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> 尽管有些命令的输出缺少了一些数据列，CRICTL 的输出格式与 Docker CLI 是类似的。
如果你的脚本程序需要解析命令的输出，请确认检查该特定命令的输出。</div>
</blockquote>
<!--
### Retrieve Debugging Information






<p>--&gt;</p>
<h3 id="获取调试信息">获取调试信息</h3>
<!--
docker cli | crictl | Description | Unsupported Features
-- | -- | -- | --
`attach` | `attach` | Attach to a running container | `--detach-keys`, `--sig-proxy`
`exec` | `exec` | Run a command in a running container | `--privileged`, `--user`, `--detach-keys`
`images` | `images` | List images |  
`info` | `info` | Display system-wide information |  
`inspect` | `inspect`, `inspecti` | Return low-level information on a container, image or task |  
`logs` | `logs` | Fetch the logs of a container | `--details`
`ps` | `ps` | List containers |  
`stats` | `stats` | Display a live stream of container(s) resource usage statistics | Column: NET/BLOCK I/O, PIDs
`version` | `version` | Show the runtime (Docker, ContainerD, or others) version information |
-->
<table><caption style="display: none;">mapping from docker cli to crictl - retrieve debugging information</caption>
<thead>
<tr>
<th>docker cli</th>
<th>crictl</th>
<th>描述</th>
<th>不支持的功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>attach</code></td>
<td><code>attach</code></td>
<td>连接到一个运行中的容器</td>
<td><code>--detach-keys</code>, <code>--sig-proxy</code></td>
</tr>
<tr>
<td><code>exec</code></td>
<td><code>exec</code></td>
<td>在运行中的容器里运行一个命令</td>
<td><code>--privileged</code>, <code>--user</code>, <code>--detach-keys</code></td>
</tr>
<tr>
<td><code>images</code></td>
<td><code>images</code></td>
<td>列举镜像</td>
<td> </td>
</tr>
<tr>
<td><code>info</code></td>
<td><code>info</code></td>
<td>显示系统级的信息</td>
<td> </td>
</tr>
<tr>
<td><code>inspect</code></td>
<td><code>inspect</code>, <code>inspecti</code></td>
<td>返回容器、镜像或者任务的详细信息</td>
<td> </td>
</tr>
<tr>
<td><code>logs</code></td>
<td><code>logs</code></td>
<td>获取容器的日志</td>
<td><code>--details</code></td>
</tr>
<tr>
<td><code>ps</code></td>
<td><code>ps</code></td>
<td>列举容器</td>
<td> </td>
</tr>
<tr>
<td><code>stats</code></td>
<td><code>stats</code></td>
<td>实时显示容器的资源使用统计信息</td>
<td>列：NET/BLOCK I/O, PIDs</td>
</tr>
<tr>
<td><code>version</code></td>
<td><code>version</code></td>
<td>显示运行时（Docker、ContainerD、或者其他) 的版本信息</td>
<td> </td>
</tr>
</tbody>
</table>


<!--
### Perform Changes






<p>--&gt;</p>
<h3 id="进行改动">进行改动</h3>
<!--
docker cli | crictl | Description | Unsupported Features
-- | -- | -- | --
`create` | `create` | Create a new container |  
`kill` | `stop` (timeout = 0) | Kill one or more running container | `--signal`
`pull` | `pull` | Pull an image or a repository from a registry | `--all-tags`, `--disable-content-trust`
`rm` | `rm` | Remove one or more containers |  
`rmi` | `rmi` | Remove one or more images |  
`run` | `run` | Run a command in a new container |  
`start` | `start` | Start one or more stopped containers | `--detach-keys`
`stop` | `stop` | Stop one or more running containers |  
`update` | `update` | Update configuration of one or more containers | `--restart`, `--blkio-weight` and some other resource limit not supported by CRI.
-->
<table><caption style="display: none;">mapping from docker cli to crictl - perform changes</caption>
<thead>
<tr>
<th>docker cli</th>
<th>crictl</th>
<th>描述</th>
<th>不支持的功能</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>create</code></td>
<td><code>create</code></td>
<td>创建一个新的容器</td>
<td> </td>
</tr>
<tr>
<td><code>kill</code></td>
<td><code>stop</code> (timeout=0)</td>
<td>杀死一个或多个正在运行的容器</td>
<td><code>--signal</code></td>
</tr>
<tr>
<td><code>pull</code></td>
<td><code>pull</code></td>
<td>从镜像仓库拉取镜像或者代码仓库</td>
<td><code>--all-tags</code>, <code>--disable-content-trust</code></td>
</tr>
<tr>
<td><code>rm</code></td>
<td><code>rm</code></td>
<td>移除一个或多个容器</td>
<td> </td>
</tr>
<tr>
<td><code>rmi</code></td>
<td><code>rmi</code></td>
<td>移除一个或多个镜像</td>
<td> </td>
</tr>
<tr>
<td><code>run</code></td>
<td><code>run</code></td>
<td>在新容器里运行一个命令</td>
<td> </td>
</tr>
<tr>
<td><code>start</code></td>
<td><code>start</code></td>
<td>启动一个或多个停止的容器</td>
<td><code>--detach-keys</code></td>
</tr>
<tr>
<td><code>stop</code></td>
<td><code>stop</code></td>
<td>停止一个或多个正运行的容器</td>
<td> </td>
</tr>
<tr>
<td><code>update</code></td>
<td><code>update</code></td>
<td>更新一个或多个容器的配置</td>
<td>CRI 不支持 <code>--restart</code>、<code>--blkio-weight</code> 以及一些其他的资源限制选项。</td>
</tr>
</tbody>
</table>


<!--
### Supported only in crictl






<p>--&gt;</p>
<h3 id="仅-crictl-支持">仅 crictl 支持</h3>
<!--
crictl | Description
-- | --
`imagefsinfo` | Return image filesystem info
`inspectp` | Display the status of one or more pods
`port-forward` | Forward local port to a pod
`pods` | List pods
`runp` | Run a new pod
`rmp` | Remove one or more pods
`stopp` | Stop one or more running pods
-->
<table><caption style="display: none;">mapping from docker cli to crictl - supported only in crictl</caption>
<thead>
<tr>
<th>crictl</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>imagefsinfo</code></td>
<td>返回镜像的文件系统信息</td>
</tr>
<tr>
<td><code>inspectp</code></td>
<td>显示一个或多个 Pod 的状态</td>
</tr>
<tr>
<td><code>port-forward</code></td>
<td>转发本地端口到 Pod</td>
</tr>
<tr>
<td><code>pods</code></td>
<td>列举 Pod</td>
</tr>
<tr>
<td><code>runp</code></td>
<td>运行一个新的 Pod</td>
</tr>
<tr>
<td><code>rmp</code></td>
<td>移除一个或多个 Pod</td>
</tr>
<tr>
<td><code>stopp</code></td>
<td>停止一个或多个正运行的 Pod</td>
</tr>
</tbody>
</table>


</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-d25a16285195bd17d9055b1eb7bc605c">2 - 在本地开发和调试服务</h1>
    
	<!--
title: Developing and debugging services locally
content_type: task
-->
<!-- overview -->
<!--
Kubernetes applications usually consist of multiple, separate services, each running in its own container. Developing and debugging these services on a remote Kubernetes cluster can be cumbersome, requiring you to [get a shell on a running container](/docs/tasks/debug-application-cluster/get-shell-running-container/) and running your tools inside the remote shell.
-->
<p>Kubernetes 应用程序通常由多个独立的服务组成，每个服务都在自己的容器中运行。
在远端的 Kubernetes 集群上开发和调试这些服务可能很麻烦，需要
<a href="/zh/docs/tasks/debug-application-cluster/get-shell-running-container/">在运行的容器上打开 Shell</a>，
然后在远端 Shell 中运行你所需的工具。</p>
<!--
`telepresence` is a tool to ease the process of developing and debugging services locally, while proxying the service to a remote Kubernetes cluster. Using `telepresence` allows you to use custom tools, such as a debugger and IDE, for a local service and provides the service full access to ConfigMap, secrets, and the services running on the remote cluster.
-->
<p><code>telepresence</code> 是一种工具，用于在本地轻松开发和调试服务，同时将服务代理到远程 Kubernetes 集群。
使用 <code>telepresence</code> 可以为本地服务使用自定义工具（如调试器和 IDE），
并提供对 Configmap、Secret 和远程集群上运行的服务的完全访问。</p>
<!--
This document describes using `telepresence` to develop and debug services running on a remote cluster locally.
-->
<p>本文档描述如何在本地使用 <code>telepresence</code> 开发和调试远程集群上运行的服务。</p>
<h2 id="准备开始">准备开始</h2>
<!--
* Kubernetes cluster is installed
* `kubectl` is configured to communicate with the cluster
* [Telepresence](https://www.telepresence.io/reference/install) is installed
-->
<ul>
<li>Kubernetes 集群安装完毕</li>
<li>配置好 <code>kubectl</code> 与集群交互</li>
<li><a href="https://www.telepresence.io/reference/install">Telepresence</a> 安装完毕</li>
</ul>
<!-- steps -->
<!--
## Getting a shell on a remote cluster

Open a terminal and run `telepresence` with no arguments to get a `telepresence` shell. This shell runs locally, giving you full access to your local filesystem.
-->
<p>打开终端，不带参数运行 <code>telepresence</code>，以打开 <code>telepresence</code> Shell。
这个 Shell 在本地运行，使你可以完全访问本地文件系统。</p>
<!--
The `telepresence` shell can be used in a variety of ways. For example, write a shell script on your laptop, and run it directly from the shell in real time. You can do this on a remote shell as well, but you might not be able to use your preferred code editor, and the script is deleted when the container is terminated.

Enter `exit` to quit and close the shell.
-->
<p><code>telepresence</code> Shell 的使用方式多种多样。
例如，在你的笔记本电脑上写一个 Shell 脚本，然后直接在 Shell 中实时运行它。
你也可以在远端 Shell 上执行此操作，但这样可能无法使用首选的代码编辑器，并且在容器终止时脚本将被删除。</p>
<!--
## Developing or debugging an existing service

When developing an application on Kubernetes, you typically program or debug a single service. The service might require access to other services for testing and debugging. One option is to use the continuous deployment pipeline, but even the fastest deployment pipeline introduces a delay in the program or debug cycle.
-->
<h2 id="开发和调试现有的服务">开发和调试现有的服务</h2>
<p>在 Kubernetes 上开发应用程序时，通常对单个服务进行编程或调试。
服务可能需要访问其他服务以进行测试和调试。
一种选择是使用连续部署流水线，但即使最快的部署流水线也会在程序或调试周期中引入延迟。</p>
<!--
Use the `--swap-deployment` option to swap an existing deployment with the Telepresence proxy. Swapping allows you to run a service locally and connect to the remote Kubernetes cluster. The services in the remote cluster can now access the locally running instance.

To run telepresence with `--swap-deployment`, enter:
-->
<p>使用 <code>--swap-deployment</code> 选项将现有部署与 Telepresence 代理交换。
交换允许你在本地运行服务并能够连接到远端的 Kubernetes 集群。
远端集群中的服务现在就可以访问本地运行的实例。</p>
<p>要运行 telepresence 并带有 <code>--swap-deployment</code> 选项，请输入：</p>
<p><code>telepresence --swap-deployment $DEPLOYMENT_NAME</code></p>
<!--
where $DEPLOYMENT_NAME is the name of your existing deployment.

Running this command spawns a shell. In the shell, start your service. You can then make edits to the source code locally, save, and see the changes take effect immediately. You can also run your service in a debugger, or any other local development tool.
-->
<p>这里的 <code>$DEPLOYMENT_NAME</code> 是你现有的部署名称。</p>
<p>运行此命令将生成 Shell。在该 Shell 中，启动你的服务。
然后，你就可以在本地对源代码进行编辑、保存并能看到更改立即生效。
你还可以在调试器或任何其他本地开发工具中运行服务。</p>
<h2 id="接下来">接下来</h2>
<!--
If you're interested in a hands-on tutorial, check out [this tutorial](https://cloud.google.com/community/tutorials/developing-services-with-k8s) that walks through locally developing the Guestbook application on Google Kubernetes Engine.
-->
<p>如果你对实践教程感兴趣，请查看<a href="https://cloud.google.com/community/tutorials/developing-services-with-k8s">本教程</a>，其中介绍了在 Google Kubernetes Engine 上本地开发 Guestbook 应用程序。</p>
<!--
Telepresence has [numerous proxying options](https://www.telepresence.io/reference/methods), depending on your situation.

For further reading, visit the [Telepresence website](https://www.telepresence.io).
-->
<p>Telepresence 有<a href="https://www.telepresence.io/reference/methods">多种代理选项</a>，以满足你的各种情况。</p>
<p>要了解更多信息，请访问 <a href="https://www.telepresence.io">Telepresence 网站</a>。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-cbd33a50cc4779f855318a0dd00d7b06">3 - 审计</h1>
    
	<!--
reviewers:
- soltysh
- sttts
- ericchiang
content_type: concept
title: Auditing
-->
<!-- overview -->





<div style="margin-top: 10px; margin-bottom: 10px;">
<b>FEATURE STATE:</b> <code>Kubernetes v1.22 [beta]</code>
</div>

<!--
Kubernetes _auditing_ provides a security-relevant, chronological set of records documenting
the sequence of actions in a cluster. The cluster audits the activities generated by users,
by applications that use the Kubernetes API, and by the control plane itself.

Auditing allows cluster administrators to answer the following questions:
-->
<p>Kubernetes <em>审计（Auditing）</em> 功能提供了与安全相关的、按时间顺序排列的记录集，
记录每个用户、使用 Kubernetes API 的应用以及控制面自身引发的活动。</p>
<p>审计功能使得集群管理员能够回答以下问题：</p>
<!--
 - what happened?
 - when did it happen?
 - who initiated it?
 - on what did it happen?
 - where was it observed?
 - from where was it initiated?
 - to where was it going?
-->
<ul>
<li>发生了什么？</li>
<li>什么时候发生的？</li>
<li>谁触发的？</li>
<li>活动发生在哪个（些）对象上？</li>
<li>在哪观察到的？</li>
<li>它从哪触发的？</li>
<li>活动的后续处理行为是什么？</li>
</ul>
<!-- body -->
<!--
Audit records begin their lifecycle inside the
[kube-apiserver](/docs/reference/command-line-tools-reference/kube-apiserver/)
component. Each request on each stage
of its execution generates an audit event, which is then pre-processed according to
a certain policy and written to a backend. The policy determines what's recorded
and the backends persist the records. The current backend implementations
include logs files and webhooks.
-->
<p>审计记录最初产生于
<a href="/zh/docs/reference/command-line-tools-reference/kube-apiserver/">kube-apiserver</a>
内部。每个请求在不同执行阶段都会生成审计事件；这些审计事件会根据特定策略
被预处理并写入后端。策略确定要记录的内容和用来存储记录的后端。
当前的后端支持日志文件和 webhook。</p>
<!--
Each request can be recorded with an associated _stage_. The defined stages are:

- `RequestReceived` - The stage for events generated as soon as the audit
  handler receives the request, and before it is delegated down the handler
  chain.
- `ResponseStarted` - Once the response headers are sent, but before the
  response body is sent. This stage is only generated for long-running requests
  (e.g. watch).
- `ResponseComplete` - The response body has been completed and no more bytes
  will be sent.
- `Panic` - Events generated when a panic occurred.
-->
<p>每个请求都可被记录其相关的 <em>阶段（stage）</em>。已定义的阶段有：</p>
<ul>
<li><code>RequestReceived</code> - 此阶段对应审计处理器接收到请求后，并且在委托给
其余处理器之前生成的事件。</li>
<li><code>ResponseStarted</code> - 在响应消息的头部发送后，响应消息体发送前生成的事件。
只有长时间运行的请求（例如 watch）才会生成这个阶段。</li>
<li><code>ResponseComplete</code> - 当响应消息体完成并且没有更多数据需要传输的时候。</li>
<li><code>Panic</code> - 当 panic 发生时生成。</li>
</ul>
<!-- 
The configuration of an
[Audit Event configuration](/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event)
is different from the
[Event](/docs/reference/generated/kubernetes-api/v1.22/#event-v1-core)
API object.
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> <a href="/zh/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event">审计事件配置</a>
的配置与 <a href="/zh/docs/reference/generated/kubernetes-api/v1.22/#event-v1-core">Event</a>
API 对象不同。</div>
</blockquote>
<!--
The audit logging feature increases the memory consumption of the API server
because some context required for auditing is stored for each request.
Additionally, memory consumption depends on the audit logging configuration.
-->
<p>审计日志记录功能会增加 API server 的内存消耗，因为需要为每个请求存储审计所需的某些上下文。
此外，内存消耗取决于审计日志记录的配置。</p>
<!--
## Audit Policy

Audit policy defines rules about what events should be recorded and what data
they should include. The audit policy object structure is defined in the
[`audit.k8s.io` API group](/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy).
When an event is processed, it's
compared against the list of rules in order. The first matching rule sets the
_audit level_ of the event. The defined audit levels are:
-->
<h2 id="audit-policy">审计策略 </h2>
<p>审计政策定义了关于应记录哪些事件以及应包含哪些数据的规则。
审计策略对象结构定义在
<a href="/zh/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy"><code>audit.k8s.io</code> API 组</a>
处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的
<em>审计级别（Audit Level）</em>。已定义的审计级别有：</p>
<!--
- `None` - don't log events that match this rule.
- `Metadata` - log request metadata (requesting user, timestamp, resource,
  verb, etc.) but not request or response body.
- `Request` - log event metadata and request body but not response body.
  This does not apply for non-resource requests.
- `RequestResponse` - log event metadata, request and response bodies.
  This does not apply for non-resource requests.
-->
<ul>
<li><code>None</code> - 符合这条规则的日志将不会记录。</li>
<li><code>Metadata</code> - 记录请求的元数据（请求的用户、时间戳、资源、动词等等），
但是不记录请求或者响应的消息体。</li>
<li><code>Request</code> - 记录事件的元数据和请求的消息体，但是不记录响应的消息体。
这不适用于非资源类型的请求。</li>
<li><code>RequestResponse</code> - 记录事件的元数据，请求和响应的消息体。这不适用于非资源类型的请求。</li>
</ul>
<!--
You can pass a file with the policy to `kube-apiserver`
using the `--audit-policy-file` flag. If the flag is omitted, no events are logged.
Note that the `rules` field __must__ be provided in the audit policy file.
A policy with no (0) rules is treated as illegal.

Below is an example audit policy file:
-->
<p>你可以使用 <code>--audit-policy-file</code> 标志将包含策略的文件传递给 <code>kube-apiserver</code>。
如果不设置该标志，则不记录事件。
注意 <code>rules</code> 字段 <strong>必须</strong> 在审计策略文件中提供。没有（0）规则的策略将被视为非法配置。</p>
<p>以下是一个审计策略文件的示例：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/audit/audit-policy.yaml" download="audit/audit-policy.yaml"><code>audit/audit-policy.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('audit-audit-policy-yaml')" title="Copy audit/audit-policy.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="audit-audit-policy-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>audit.k8s.io/v1<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># This is required.</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Policy<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#080;font-style:italic"># Don&#39;t generate audit events for all requests in RequestReceived stage.</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">omitStages</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#b44">&#34;RequestReceived&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">rules</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Log pod changes at RequestResponse level</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>RequestResponse<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#080;font-style:italic"># Resource &#34;pods&#34; doesn&#39;t match requests to any subresource of pods,</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#080;font-style:italic"># which is consistent with the RBAC policy.</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;pods&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Log &#34;pods/log&#34;, &#34;pods/status&#34; at Metadata level</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>Metadata<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;pods/log&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;pods/status&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Don&#39;t log requests to a configmap called &#34;controller-leader&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>None<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;configmaps&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resourceNames</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;controller-leader&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Don&#39;t log watch requests by the &#34;system:kube-proxy&#34; on endpoints or services</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>None<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">users</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;system:kube-proxy&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">verbs</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;watch&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># core API group</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;endpoints&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;services&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Don&#39;t log authenticated requests to certain non-resource URL paths.</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>None<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">userGroups</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;system:authenticated&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">nonResourceURLs</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#b44">&#34;/api*&#34;</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Wildcard matching.</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#b44">&#34;/version&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Log the request body of configmap changes in kube-system.</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>Request<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># core API group</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;configmaps&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#080;font-style:italic"># This rule only applies to resources in the &#34;kube-system&#34; namespace.</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#080;font-style:italic"># The empty string &#34;&#34; can be used to select non-namespaced resources.</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">namespaces</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;kube-system&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Log configmap and secret changes in all other namespaces at the Metadata level.</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>Metadata<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># core API group</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;secrets&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;configmaps&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># Log all other resources in core and extensions at the Request level.</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>Request<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># core API group</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">group</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;extensions&#34;</span><span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Version of group should NOT be included.</span><span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#080;font-style:italic"># A catch-all rule to log all other requests at the Metadata level.</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>Metadata<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#080;font-style:italic"># Long-running requests like watches that fall under this rule will not</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#080;font-style:italic"># generate an audit event in RequestReceived.</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">omitStages</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#b44">&#34;RequestReceived&#34;</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
You can use a minimal audit policy file to log all requests at the `Metadata` level:
-->
<p>你可以使用最低限度的审计策略文件在 <code>Metadata</code> 级别记录所有请求：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#080;font-style:italic"># 在 Metadata 级别为所有请求生成日志</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>audit.k8s.io/v1beta1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Policy<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">rules</span>:<span style="color:#bbb">
</span><span style="color:#bbb"></span>- <span style="color:#008000;font-weight:bold">level</span>:<span style="color:#bbb"> </span>Metadata<span style="color:#bbb">
</span></code></pre></div><!--
If you're crafting your own audit profile, you can use the audit profile for Google Container-Optimized OS as a starting point. You can check the
[configure-helper.sh](https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/gci/configure-helper.sh)
script, which generates the audit policy file. You can see most of the audit policy file by looking directly at the script.

You can also refer to the [`Policy` configuration reference](/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy)
for details about the fields defined.
-->
<p>如果你在打磨自己的审计配置文件，你可以使用为 Google Container-Optimized OS
设计的审计配置作为出发点。你可以参考
<a href="https://github.com/kubernetes/kubernetes/blob/master/cluster/gce/gci/configure-helper.sh">configure-helper.sh</a>
脚本，该脚本能够生成审计策略文件。你可以直接在脚本中看到审计策略的绝大部份内容。</p>
<p>你也可以参考 <a href="/zh/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Policy"><code>Policy</code> 配置参考</a>
以获取有关已定义字段的详细信息。</p>
<!--
## Audit backends

Audit backends persist audit events to an external storage.
Out of the box, the kube-apiserver provides two backends:

- Log backend, which writes events into the filesystem
- Webhook backend, which sends events to an external HTTP API

In all cases, audit events follow a structure defined by the Kubernetes API in the
[`audit.k8s.io` API group](/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event).
-->
<h2 id="audit-backends">审计后端  </h2>
<p>审计后端实现将审计事件导出到外部存储。<code>Kube-apiserver</code> 默认提供两个后端：</p>
<ul>
<li>Log 后端，将事件写入到文件系统</li>
<li>Webhook 后端，将事件发送到外部 HTTP API</li>
</ul>
<p>在这所有情况下，审计事件均遵循 Kubernetes API 在
<a href="/zh/docs/reference/config-api/apiserver-audit.v1/#audit-k8s-io-v1-Event"><code>audit.k8s.io</code> API 组</a>
中定义的结构。</p>
<!--
In case of patches, request body is a JSON array with patch operations, not a JSON object
with an appropriate Kubernetes API object. For example, the following request body is a valid patch
request to `/apis/batch/v1/namespaces/some-namespace/jobs/some-job-name`.
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> <p>对于 patch 请求，请求的消息体需要是设定 patch 操作的 JSON 所构成的一个串，
而不是一个完整的 Kubernetes API 对象 JSON 串。
例如，以下的示例是一个合法的 patch 请求消息体，该请求对应
<code>/apis/batch/v1/namespaces/some-namespace/jobs/some-job-name</code>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">[
  {
    <span style="color:#008000;font-weight:bold">&#34;op&#34;</span>: <span style="color:#b44">&#34;replace&#34;</span>,
    <span style="color:#008000;font-weight:bold">&#34;path&#34;</span>: <span style="color:#b44">&#34;/spec/parallelism&#34;</span>,
    <span style="color:#008000;font-weight:bold">&#34;value&#34;</span>: <span style="color:#666">0</span>
  },
  {
    <span style="color:#008000;font-weight:bold">&#34;op&#34;</span>: <span style="color:#b44">&#34;remove&#34;</span>,
    <span style="color:#008000;font-weight:bold">&#34;path&#34;</span>: <span style="color:#b44">&#34;/spec/template/spec/containers/0/terminationMessagePolicy&#34;</span>
  }
]
</code></pre></div></div>
</blockquote>
<!--
### Log backend

The log backend writes audit events to a file in [JSONlines](https://jsonlines.org/) format.
You can configure the log audit backend using the following `kube-apiserver` flags:

Log backend writes audit events to a file in JSON format. You can configure
log audit backend using the following [kube-apiserver][kube-apiserver] flags:
-->
<h3 id="log-后端">Log 后端</h3>
<p>Log 后端将审计事件写入 <a href="https://jsonlines.org/">JSONlines</a>  格式的文件。
你可以使用以下 <code>kube-apiserver</code> 标志配置 Log 审计后端：</p>
<!--
- `--audit-log-path` specifies the log file path that log backend uses to write
  audit events. Not specifying this flag disables log backend. `-` means standard out
- `--audit-log-maxage` defined the maximum number of days to retain old audit log files
- `--audit-log-maxbackup` defines the maximum number of audit log files to retain
- `--audit-log-maxsize` defines the maximum size in megabytes of the audit log file before it gets rotated
-->
<ul>
<li><code>--audit-log-path</code> 指定用来写入审计事件的日志文件路径。不指定此标志会禁用日志后端。<code>-</code> 意味着标准化</li>
<li><code>--audit-log-maxage</code> 定义保留旧审计日志文件的最大天数</li>
<li><code>--audit-log-maxbackup</code> 定义要保留的审计日志文件的最大数量</li>
<li><code>--audit-log-maxsize</code> 定义审计日志文件的最大大小（兆字节）</li>
</ul>
<!--
If your cluster's control plane runs the kube-apiserver as a Pod, remember to mount the `hostPath`
to the location of the policy file and log file, so that audit records are persisted. For example:
-->
<p>如果你的集群控制面以 Pod 的形式运行 kube-apiserver，记得要通过 <code>hostPath</code>
卷来访问策略文件和日志文件所在的目录，这样审计记录才会持久保存下来。例如：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">  --audit-policy-file<span style="color:#666">=</span>/etc/kubernetes/audit-policy.yaml
  --audit-log-path<span style="color:#666">=</span>/var/log/audit.log
</code></pre></div><p>接下来挂载数据卷：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/etc/kubernetes/audit-policy.yaml<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>audit<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/var/log/audit.log<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>audit-log<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">false</span><span style="color:#bbb">
</span></code></pre></div><!-- 
and finally configure the `hostPath`:
-->
<p>最后配置 <code>hostPath</code>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>audit<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span>/etc/kubernetes/audit-policy.yaml<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>File<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb"></span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>audit-log<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span>/var/log/audit.log<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>FileOrCreate<span style="color:#bbb">
</span></code></pre></div><!--
### Webhook backend

The webhook audit backend sends audit events to a remote web API, which is assumed to
be a form of the Kubernetes API, including means of authentication. You can configure
a webhook audit backend using the following kube-apiserver flags:
-->
<h3 id="webhook-backend">Webhook 后端  </h3>
<p>Webhook 后端将审计事件发送到远程 Web API，该远程 API 应该暴露与 <code>kube-apiserver</code>
形式相同的 API，包括其身份认证机制。你可以使用如下 kube-apiserver 标志来配置
Webhook 审计后端：</p>
<!--
- `--audit-webhook-config-file` specifies the path to a file with a webhook
  configuration. The webhook configuration is effectively a specialized
  [kubeconfig](/docs/tasks/access-application-cluster/configure-access-multiple-clusters).
- `--audit-webhook-initial-backoff` specifies the amount of time to wait after the first failed
  request before retrying. Subsequent requests are retried with exponential backoff.

The webhook config file uses the kubeconfig format to specify the remote address of
the service and credentials used to connect to it.
-->
<ul>
<li><code>--audit-webhook-config-file</code> 设置 Webhook 配置文件的路径。Webhook 配置文件实际上是一个
<a href="/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/">kubeconfig 文件</a>。</li>
<li><code>--audit-webhook-initial-backoff</code> 指定在第一次失败后重发请求等待的时间。随后的请求将以指数退避重试。</li>
</ul>
<p>Webhook 配置文件使用 kubeconfig 格式指定服务的远程地址和用于连接它的凭据。</p>
<!--
## Event batching {#batching}

Both log and webhook backends support batching. Using webhook as an example, here's the list of
available flags. To get the same flag for log backend, replace `webhook` with `log` in the flag
name. By default, batching is enabled in `webhook` and disabled in `log`. Similarly, by default
throttling is enabled in `webhook` and disabled in `log`.
-->
<h2 id="batching">事件批处理 </h2>
<p>日志和 Webhook 后端都支持批处理。以 Webhook 为例，以下是可用参数列表。要获取日志
后端的同样参数，请在参数名称中将 <code>webhook</code> 替换为 <code>log</code>。
默认情况下，在 <code>webhook</code> 中批处理是被启用的，在 <code>log</code> 中批处理是被禁用的。
同样，默认情况下，在 <code>webhook</code> 中启用带宽限制，在 <code>log</code> 中禁用带宽限制。</p>
<!--
  - `--audit-webhook-mode` defines the buffering strategy. One of the following:
  - `batch` - buffer events and asynchronously process them in batches. This is the default.
  - `blocking` - block API server responses on processing each individual event.
  - `blocking-strict` - Same as blocking, but when there is a failure during audit logging at the
     RequestReceived stage, the whole request to the kube-apiserver fails.
-->
<ul>
<li><code>--audit-webhook-mode</code> 定义缓存策略，可选值如下：
<ul>
<li><code>batch</code> - 以批处理缓存事件和异步的过程。这是默认值。</li>
<li><code>blocking</code> - 在 API 服务器处理每个单独事件时，阻塞其响应。</li>
<li><code>blocking-strict</code> - 与 <code>blocking</code> 相同，不过当审计日志在 RequestReceived 阶段
失败时，整个 API 服务请求会失效。</li>
</ul>
</li>
</ul>
<!--
The following flags are used only in the `batch` mode.

- `--audit-webhook-batch-buffer-size` defines the number of events to buffer before batching.
  If the rate of incoming events overflows the buffer, events are dropped.
- `--audit-webhook-batch-max-size` defines the maximum number of events in one batch.
- `--audit-webhook-batch-max-wait` defines the maximum amount of time to wait before unconditionally
  batching events in the queue.
- `--audit-webhook-batch-throttle-qps` defines the maximum average number of batches generated
  per second.
- `--audit-webhook-batch-throttle-burst` defines the maximum number of batches generated at the same
  moment if the allowed QPS was underutilized previously.
-->
<p>以下参数仅用于 <code>batch</code> 模式。</p>
<ul>
<li><code>--audit-webhook-batch-buffer-size</code> 定义 batch 之前要缓存的事件数。
如果传入事件的速率溢出缓存区，则会丢弃事件。</li>
<li><code>--audit-webhook-batch-max-size</code> 定义一个 batch 中的最大事件数。</li>
<li><code>--audit-webhook-batch-max-wait</code> 无条件 batch 队列中的事件前等待的最大事件。</li>
<li><code>--audit-webhook-batch-throttle-qps</code> 每秒生成的最大批次数。</li>
<li><code>--audit-webhook-batch-throttle-burst</code> 在达到允许的 QPS 前，同一时刻允许存在的最大 batch 生成数。</li>
</ul>
<!--
## Parameter tuning

Parameters should be set to accommodate the load on the API server.

For example, if kube-apiserver receives 100 requests each second, and each request is audited only
on `ResponseStarted` and `ResponseComplete` stages, you should account for ≅200 audit
events being generated each second. Assuming that there are up to 100 events in a batch,
you should set throttling level at least 2 queries per second. Assuming that the backend can take up to
5 seconds to write events, you should set the buffer size to hold up to 5 seconds of events;
that is: 10 batches, or 1000 events.
-->
<h2 id="parameter-tuning">参数调整  </h2>
<p>需要设置参数以适应 API 服务器上的负载。</p>
<p>例如，如果 kube-apiserver 每秒收到 100 个请求，并且每个请求仅在 <code>ResponseStarted</code>
和 <code>ResponseComplete</code> 阶段进行审计，则应该考虑每秒生成约 200 个审计事件。
假设批处理中最多有 100 个事件，则应将限制级别设置为每秒至少 2 个查询。
假设后端最多需要 5 秒钟来写入事件，你应该设置缓冲区大小以容纳最多 5 秒的事件，
即 10 个 batch，即 1000 个事件。</p>
<!--
In most cases however, the default parameters should be sufficient and you don't have to worry about
setting them manually. You can look at the following Prometheus metrics exposed by kube-apiserver
and in the logs to monitor the state of the auditing subsystem.

- `apiserver_audit_event_total` metric contains the total number of audit events exported.
- `apiserver_audit_error_total` metric contains the total number of events dropped due to an error
  during exporting.
-->
<p>但是，在大多数情况下，默认参数应该足够了，你不必手动设置它们。
你可以查看 kube-apiserver 公开的以下 Prometheus 指标，并在日志中监控审计子系统的状态。</p>
<ul>
<li><code>apiserver_audit_event_total</code> 包含所有暴露的审计事件数量的指标。</li>
<li><code>apiserver_audit_error_total</code> 在暴露时由于发生错误而被丢弃的事件的数量。</li>
</ul>
<!--
### Log entry truncation {#truncate}

Both log and webhook backends support limiting the size of events that are logged.
As an example, the following is the list of flags available for the log backend:
-->
<h3 id="truncate">日志条目截断  </h3>
<p>日志后端和 Webhook 后端都支持限制所输出的事件的尺寸。
例如，下面是可以为日志后端配置的标志列表：</p>
<!--
- `audit-log-truncate-enabled` whether event and batch truncating is enabled.
- `audit-log-truncate-max-batch-size` maximum size in bytes of the batch sent to the underlying backend.
- `audit-log-truncate-max-event-size` maximum size in bytes of the audit event sent to the underlying backend.
-->
<ul>
<li><code>audit-log-truncate-enabled</code>：是否弃用事件和批次的截断处理。</li>
<li><code>audit-log-truncate-max-batch-size</code>：向下层后端发送的各批次的最大尺寸字节数。</li>
<li><code>audit-log-truncate-max-event-size</code>：向下层后端发送的审计事件的最大尺寸字节数。</li>
</ul>
<!--
By default truncate is disabled in both `webhook` and `log`, a cluster administrator should set
`audit-log-truncate-enabled` or `audit-webhook-truncate-enabled` to enable the feature.
-->
<p>默认情况下，截断操作在 <code>webhook</code> 和 <code>log</code> 后端都是被禁用的，集群管理员需要设置
<code>audit-log-truncate-enabled</code> 或 <code>audit-webhook-truncate-enabled</code> 标志来启用此操作。</p>
<h2 id="接下来">接下来</h2>
<!--
* Learn about [Mutating webhook auditing annotations](/docs/reference/access-authn-authz/extensible-admission-controllers/#mutating-webhook-auditing-annotations).
-->
<ul>
<li>了解 <a href="/zh/docs/reference/access-authn-authz/extensible-admission-controllers/#mutating-webhook-auditing-annotations">Mutating webhook 审计注解</a>。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-3556c4dbd027b9e90a5b3d72649003fb">4 - 应用故障排查</h1>
    
	<!--
title: Troubleshoot Applications
content_type: concept
-->
<!-- overview -->
<!--
This guide is to help users debug applications that are deployed into Kubernetes and not behaving correctly.
This is *not* a guide for people who want to debug their cluster.  For that you should check out
[this guide](/docs/admin/cluster-troubleshooting).
-->
<p>本指南帮助用户调试那些部署到 Kubernetes 上后没有正常运行的应用。
本指南 <em>并非</em> 指导用户如何调试集群。
如果想调试集群的话，请参阅<a href="/zh/docs/tasks/debug-application-cluster/debug-cluster/">这里</a>。</p>
<!-- body -->
<!--
## Diagnosing the problem

The first step in troubleshooting is triage.  What is the problem?  Is it your Pods, your Replication Controller or
your Service?

   * [Debugging Pods](#debugging-pods)
   * [Debugging Replication Controllers](#debugging-replication-controllers)
   * [Debugging Services](#debugging-services)
-->
<h2 id="diagnosing-the-problem">诊断问题  </h2>
<p>故障排查的第一步是先给问题分类。问题是什么？是关于 Pods、Replication Controller 还是 Service？</p>
<ul>
<li><a href="#debugging-pods">调试 Pods</a></li>
<li><a href="#debugging-replication-controllers">调试副本控制器</a></li>
<li><a href="#debugging-services">调试服务</a></li>
</ul>
<!--
### Debugging Pods

The first step in debugging a Pod is taking a look at it.  Check the current state of the Pod and recent events with the following command:
-->
<h3 id="debugging-pods">调试 Pods  </h3>
<p>调试 Pod 的第一步是查看 Pod 信息。用如下命令查看 Pod 的当前状态和最近的事件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pods <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">POD_NAME</span><span style="color:#b68;font-weight:bold">}</span>
</code></pre></div><!--
Look at the state of the containers in the pod.  Are they all `Running`?  Have there been recent restarts?

Continue debugging depending on the state of the pods.
-->
<p>查看一下 Pod 中的容器所处的状态。这些容器的状态都是 <code>Running</code> 吗？最近有没有重启过？</p>
<p>后面的调试都是要依靠 Pod 的状态的。</p>
<!--
#### My pod stays pending

If a Pod is stuck in `Pending` it means that it can not be scheduled onto a node.  Generally this is because
there are insufficient resources of one type or another that prevent scheduling.  Look at the output of the
`kubectl describe ...` command above.  There should be messages from the scheduler about why it can not schedule
your pod.  Reasons include:
-->
<h4 id="pod-停滞在-pending-状态">Pod 停滞在 Pending 状态</h4>
<p>如果一个 Pod 停滞在 <code>Pending</code> 状态，表示 Pod 没有被调度到节点上。通常这是因为
某种类型的资源不足导致无法调度。
查看上面的 <code>kubectl describe ...</code> 命令的输出，其中应该显示了为什么没被调度的原因。
常见原因如下：</p>
<!--
* **You don't have enough resources**:  You may have exhausted the supply of CPU or Memory in your cluster, in this case
you need to delete Pods, adjust resource requests, or add new nodes to your cluster. See [Compute Resources document](/docs/user-guide/compute-resources/#my-pods-are-pending-with-event-message-failedscheduling) for more information.

* **You are using `hostPort`**:  When you bind a Pod to a `hostPort` there are a limited number of places that pod can be
scheduled.  In most cases, `hostPort` is unnecessary, try using a Service object to expose your Pod.  If you do require
`hostPort` then you can only schedule as many Pods as there are nodes in your Kubernetes cluster.
-->
<ul>
<li>
<p><strong>资源不足</strong>:
你可能耗尽了集群上所有的 CPU 或内存。此时，你需要删除 Pod、调整资源请求或者为集群添加节点。
更多信息请参阅<a href="/zh/docs/concepts/configuration/manage-resources-containers/">计算资源文档</a></p>
</li>
<li>
<p><strong>使用了 <code>hostPort</code></strong>:
如果绑定 Pod 到 <code>hostPort</code>，那么能够运行该 Pod 的节点就有限了。
多数情况下，<code>hostPort</code> 是非必要的，而应该采用 Service 对象来暴露 Pod。
如果确实需要使用 <code>hostPort</code>，那么集群中节点的个数就是所能创建的 Pod
的数量上限。</p>
</li>
</ul>
<!--
#### My pod stays waiting

If a Pod is stuck in the `Waiting` state, then it has been scheduled to a worker node, but it can't run on that machine.
Again, the information from `kubectl describe ...` should be informative.  The most common cause of `Waiting` pods is a failure to pull the image.  There are three things to check:

* Make sure that you have the name of the image correct.
* Have you pushed the image to the repository?
* Run a manual `docker pull <image>` on your machine to see if the image can be pulled.
-->
<h4 id="pod-停滞在-waiting-状态">Pod 停滞在 Waiting 状态</h4>
<p>如果 Pod 停滞在 <code>Waiting</code> 状态，则表示 Pod 已经被调度到某工作节点，但是无法在该节点上运行。
同样，<code>kubectl describe ...</code> 命令的输出可能很有用。
<code>Waiting</code> 状态的最常见原因是拉取镜像失败。要检查的有三个方面：</p>
<ul>
<li>确保镜像名字拼写正确</li>
<li>确保镜像已被推送到镜像仓库</li>
<li>用手动命令 <code>docker pull &lt;镜像&gt;</code> 试试看镜像是否可拉取</li>
</ul>
<!--
#### My pod is crashing or otherwise unhealthy

Once your pod has been scheduled, the methods described in [Debug Running Pods](
/docs/tasks/debug-application-cluster/debug-running-pod/) are available for debugging.
-->
<h4 id="pod-处于-crashing-或别的不健康状态">Pod 处于 Crashing 或别的不健康状态</h4>
<p>一旦 Pod 被调度，就可以采用
<a href="/zh/docs/tasks/debug-application-cluster/debug-running-pod/">调试运行中的 Pod</a>
中的方法来进一步调试。</p>
<!--
#### My pod is running but not doing what I told it to do

If your pod is not behaving as you expected, it may be that there was an error in your
pod description (e.g. `mypod.yaml` file on your local machine), and that the error
was silently ignored when you created the pod.  Often a section of the pod description
is nested incorrectly, or a key name is typed incorrectly, and so the key is ignored.
For example, if you misspelled `command` as `commnd` then the pod will be created but
will not use the command line you intended it to use.
-->
<h4 id="pod-处于-running-态但是没有正常工作">Pod 处于 Running 态但是没有正常工作</h4>
<p>如果 Pod 行为不符合预期，很可能 Pod 描述（例如你本地机器上的 <code>mypod.yaml</code>）中有问题，
并且该错误在创建 Pod 时被忽略掉，没有报错。
通常，Pod 的定义中节区嵌套关系错误、字段名字拼错的情况都会引起对应内容被忽略掉。
例如，如果你误将 <code>command</code> 写成 <code>commnd</code>，Pod 虽然可以创建，但它不会执行
你期望它执行的命令行。</p>
<!--
The first thing to do is to delete your pod and try creating it again with the `--validate` option.
For example, run `kubectl apply --validate -f mypod.yaml`.
If you misspelled `command` as `commnd` then will give an error like this:
-->
<p>可以做的第一件事是删除你的 Pod，并尝试带有 <code>--validate</code> 选项重新创建。
例如，运行 <code>kubectl apply --validate -f mypod.yaml</code>。
如果 <code>command</code>  被误拼成 <code>commnd</code>，你将会看到下面的错误信息：</p>
<pre tabindex="0"><code>I0805 10:43:25.129850   46757 schema.go:126] unknown field: commnd
I0805 10:43:25.129973   46757 schema.go:129] this may be a false alarm, see https://github.com/kubernetes/kubernetes/issues/6842
pods/mypod
</code></pre><!-- TODO: Now that #11914 is merged, this advice may need to be updated -->
<!--
The next thing to check is whether the pod on the apiserver
matches the pod you meant to create (e.g. in a yaml file on your local machine).
For example, run `kubectl get pods/mypod -o yaml > mypod-on-apiserver.yaml` and then
manually compare the original pod description, `mypod.yaml` with the one you got
back from apiserver, `mypod-on-apiserver.yaml`.  There will typically be some
lines on the "apiserver" version that are not on the original version.  This is
expected.  However, if there are lines on the original that are not on the apiserver
version, then this may indicate a problem with your pod spec.
-->
<p>接下来就要检查的是 API 服务器上的 Pod 与你所期望创建的是否匹配
（例如，你原本使用本机上的一个 YAML 文件来创建 Pod）。
例如，运行 <code>kubectl get pods/mypod -o yaml &gt; mypod-on-apiserver.yaml</code>，之后
手动比较 <code>mypod.yaml</code> 与从 API 服务器取回的 Pod 描述。
从 API 服务器处获得的 YAML 通常包含一些创建 Pod 所用的 YAML 中不存在的行，这是正常的。
不过，如果如果源文件中有些行在 API 服务器版本中不存在，则意味着
Pod 规约是有问题的。</p>
<!--
### Debugging Replication Controllers

Replication controllers are fairly straightforward.  They can either create Pods or they can't.  If they can't
create pods, then please refer to the [instructions above](#debugging-pods) to debug your pods.

You can also use `kubectl describe rc ${CONTROLLER_NAME}` to introspect events related to the replication
controller.
-->
<h3 id="debugging-replication-controllers">调试副本控制器 </h3>
<p>副本控制器相对比较简单直接。它们要么能创建 Pod，要么不能。
如果不能创建 Pod，请参阅<a href="#debugging-pods">上述说明</a>调试 Pod。</p>
<p>你也可以使用 <code>kubectl describe rc ${CONTROLLER_NAME}</code> 命令来检视副本控制器相关的事件。</p>
<!--
### Debugging Services

Services provide load balancing across a set of pods.  There are several common problems that can make Services
not work properly.  The following instructions should help debug Service problems.

First, verify that there are endpoints for the service. For every Service object, the apiserver makes an `endpoints` resource available.

You can view this resource with:
-->
<h3 id="debugging-services">调试服务  </h3>
<p>服务支持在多个 Pod 间负载均衡。
有一些常见的问题可以造成服务无法正常工作。
以下说明将有助于调试服务的问题。</p>
<p>首先，验证服务是否有端点。对于每一个 Service 对象，API 服务器为其提供
对应的 <code>endpoints</code> 资源。</p>
<p>通过如下命令可以查看 endpoints 资源：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get endpoints <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">SERVICE_NAME</span><span style="color:#b68;font-weight:bold">}</span>
</code></pre></div><!--
Make sure that the endpoints match up with the number of pods that you expect to be members of your service.
For example, if your Service is for an nginx container with 3 replicas, you would expect to see three different
IP addresses in the Service's endpoints.
-->
<p>确保 Endpoints 与服务成员 Pod 个数一致。
例如，如果你的 Service 用来运行 3 个副本的 nginx 容器，你应该会在服务的 Endpoints
中看到 3 个不同的 IP 地址。</p>
<!--
#### My service is missing endpoints

If you are missing endpoints, try listing pods using the labels that Service uses.  Imagine that you have
a Service where the labels are:
-->
<h4 id="服务缺少-endpoints">服务缺少 Endpoints</h4>
<p>如果没有 Endpoints，请尝试使用 Service 所使用的标签列出 Pod。
假定你的服务包含如下标签选择算符：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#00f;font-weight:bold">...</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">     </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">     </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>frontend<span style="color:#bbb">
</span></code></pre></div><!--
You can use:
```shell
kubectl get pods --selector=name=nginx,type=frontend
```

to list pods that match this selector.  Verify that the list matches the Pods that you expect to provide your Service.
-->
<p>你可以使用如下命令列出与选择算符相匹配的 Pod，并验证这些 Pod 是否归属于创建的服务：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods --selector<span style="color:#666">=</span><span style="color:#b8860b">name</span><span style="color:#666">=</span>nginx,type<span style="color:#666">=</span>frontend
</code></pre></div><!--
Verify that the pod's `containerPort` matches up with the Service's `targetPort`
-->
<p>验证 Pod 的 <code>containerPort</code> 与服务的 <code>targetPort</code> 是否匹配。</p>
<!--
#### Network traffic is not forwarded

Please see [debugging service](/docs/tasks/debug-application-cluster/debug-service/) for more information.
-->
<h4 id="网络流量未被转发">网络流量未被转发</h4>
<p>请参阅<a href="/zh/docs/tasks/debug-application-cluster/debug-service/">调试 service</a> 了解更多信息。</p>
<h2 id="接下来">接下来</h2>
<!--
If none of the above solves your problem, follow the instructions in [Debugging Service document](/docs/user-guide/debugging-services) to make sure that your `Service` is running, has `Endpoints`, and your `Pods` are actually serving; you have DNS working, iptables rules installed, and kube-proxy does not seem to be misbehaving.

You may also visit [troubleshooting document](/docs/troubleshooting/) for more information.
-->
<p>如果上述方法都不能解决你的问题，请按照
<a href="/zh/docs/tasks/debug-application-cluster/debug-service/">调试服务文档</a>中的介绍，
确保你的 <code>Service</code> 处于 Running 态，有 <code>Endpoints</code> 被创建，<code>Pod</code> 真的在提供服务；
DNS 服务已配置并正常工作，iptables 规则也以安装并且 <code>kube-proxy</code> 也没有异常行为。</p>
<p>你也可以访问<a href="/zh/docs/tasks/debug-application-cluster/troubleshooting/">故障排查文档</a>来获取更多信息。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-731bb8b338c16aebfb9590ba2bd3fdd1">5 - 应用自测与调试</h1>
    
	<!-- overview -->
<!--
Once your application is running, you'll inevitably need to debug problems with it.
Earlier we described how you can use `kubectl get pods` to retrieve simple status information about
your pods. But there are a number of ways to get even more information about your application.
-->
<p>运行应用时，不可避免的需要定位问题。
前面我们介绍了如何使用 <code>kubectl get pods</code> 来查询 pod 的简单信息。
除此之外，还有一系列的方法来获取应用的更详细信息。</p>
<!-- body -->
<!--
## Using `kubectl describe pod` to fetch details about pods
-->
<h2 id="使用-kubectl-describe-pod-命令获取-pod-详情">使用 <code>kubectl describe pod</code> 命令获取 Pod 详情</h2>
<!--
For this example we'll use a Deployment to create two pods, similar to the earlier example.
-->
<p>与之前的例子类似，我们使用一个 Deployment 来创建两个 Pod。</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/nginx-with-request.yaml" download="application/nginx-with-request.yaml"><code>application/nginx-with-request.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-nginx-with-request-yaml')" title="Copy application/nginx-with-request.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-nginx-with-request-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx-deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">2</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;128Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;500m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
Create deployment by running following command:
-->
<p>使用如下命令创建 Deployment：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/application/nginx-with-request.yaml
</code></pre></div><pre tabindex="0"><code>deployment.apps/nginx-deployment created
</code></pre><!--
Check pod status by following command:
-->
<p>使用如下命令查看 Pod 状态：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods
</code></pre></div><pre tabindex="0"><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1006230814-6winp   1/1       Running   0          11s
nginx-deployment-1006230814-fmgu3   1/1       Running   0          11s
</code></pre><!--
We can retrieve a lot more information about each of these pods using `kubectl describe pod`. For example:
-->
<p>我们可以使用 <code>kubectl describe pod</code> 命令来查询每个 Pod 的更多信息，比如：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pod nginx-deployment-1006230814-6winp
</code></pre></div><pre tabindex="0"><code>Name:		nginx-deployment-1006230814-6winp
Namespace:	default
Node:		kubernetes-node-wul5/10.240.0.9
Start Time:	Thu, 24 Mar 2016 01:39:49 +0000
Labels:		app=nginx,pod-template-hash=1006230814
Annotations:    kubernetes.io/created-by={&quot;kind&quot;:&quot;SerializedReference&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;reference&quot;:{&quot;kind&quot;:&quot;ReplicaSet&quot;,&quot;namespace&quot;:&quot;default&quot;,&quot;name&quot;:&quot;nginx-deployment-1956810328&quot;,&quot;uid&quot;:&quot;14e607e7-8ba1-11e7-b5cb-fa16&quot; ...
Status:		Running
IP:		10.244.0.6
Controllers:	ReplicaSet/nginx-deployment-1006230814
Containers:
  nginx:
    Container ID:	docker://90315cc9f513c724e9957a4788d3e625a078de84750f244a40f97ae355eb1149
    Image:		nginx
    Image ID:		docker://6f62f48c4e55d700cf3eb1b5e33fa051802986b77b874cc351cce539e5163707
    Port:		80/TCP
    QoS Tier:
      cpu:	Guaranteed
      memory:	Guaranteed
    Limits:
      cpu:	500m
      memory:	128Mi
    Requests:
      memory:		128Mi
      cpu:		500m
    State:		Running
      Started:		Thu, 24 Mar 2016 01:39:51 +0000
    Ready:		True
    Restart Count:	0
    Environment:        &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5kdvl (ro)
Conditions:
  Type          Status
  Initialized   True
  Ready         True
  PodScheduled  True
Volumes:
  default-token-4bcbi:
    Type:	Secret (a volume populated by a Secret)
    SecretName:	default-token-4bcbi
    Optional:   false
QoS Class:      Guaranteed
Node-Selectors: &lt;none&gt;
Tolerations:    &lt;none&gt;
Events:
  FirstSeen	LastSeen	Count	From					SubobjectPath		Type		Reason		Message
  ---------	--------	-----	----					-------------		--------	------		-------
  54s		54s		1	{default-scheduler }						Normal		Scheduled	Successfully assigned nginx-deployment-1006230814-6winp to kubernetes-node-wul5
  54s		54s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Pulling		pulling image &quot;nginx&quot;
  53s		53s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Pulled		Successfully pulled image &quot;nginx&quot;
  53s		53s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Created		Created container with docker id 90315cc9f513
  53s		53s		1	{kubelet kubernetes-node-wul5}	spec.containers{nginx}	Normal		Started		Started container with docker id 90315cc9f513
</code></pre><!--
Here you can see configuration information about the container(s) and Pod (labels, resource requirements, etc.), 
as well as status information about the container(s) and Pod (state, readiness, restart count, events, etc.).
-->
<p>这里可以看到容器和 Pod 的标签、资源需求等配置信息，还可以看到状态、就绪态、
重启次数、事件等状态信息。</p>
<!--
The container state is one of Waiting, Running, or Terminated. 
Depending on the state, additional information will be provided -- here you can see that for a container in Running state, the system tells you when the container started.
-->
<p>容器状态是 Waiting、Running 和 Terminated 之一。
根据状态的不同，还有对应的额外的信息 —— 在这里你可以看到，
对于处于运行状态的容器，系统会告诉你容器的启动时间。</p>
<!--
Ready tells you whether the container passed its last readiness probe. 
(In this case, the container does not have a readiness probe configured; the container is assumed to be ready if no readiness probe is configured.)
-->
<p>Ready 指示是否通过了最后一个就绪态探测。
(在本例中，容器没有配置就绪态探测；如果没有配置就绪态探测，则假定容器已经就绪。)</p>
<!--
Restart Count tells you how many times the container has been restarted; 
this information can be useful for detecting crash loops in containers that are configured with a restart policy of 'always.'
-->
<p>Restart Count 告诉你容器已重启的次数；
这些信息对于定位配置了 “Always” 重启策略的容器持续崩溃问题非常有用。</p>
<!--
Currently the only Condition associated with a Pod is the binary Ready condition, 
which indicates that the pod is able to service requests and should be added to the load balancing pools of all matching services.
-->
<p>目前，唯一与 Pod 有关的状态是 Ready 状况，该状况表明 Pod 能够为请求提供服务，
并且应该添加到相应服务的负载均衡池中。</p>
<!--
Lastly, you see a log of recent events related to your Pod. 
The system compresses multiple identical events by indicating the first and last time it was seen and the number of times it was seen. 
"From" indicates the component that is logging the event, 
"SubobjectPath" tells you which object (e.g. container within the pod) is being referred to, 
and "Reason" and "Message" tell you what happened.
-->
<p>最后，你还可以看到与 Pod 相关的近期事件。
系统通过指示第一次和最后一次看到事件以及看到该事件的次数来压缩多个相同的事件。
“From” 标明记录事件的组件，
“SubobjectPath” 告诉你引用了哪个对象（例如 Pod 中的容器），
“Reason” 和 “Message” 告诉你发生了什么。</p>
<!--
## Example: debugging Pending Pods

A common scenario that you can detect using events is when you've created a Pod that won't fit on any node. 
For example, the Pod might request more resources than are free on any node, 
or it might specify a label selector that doesn't match any nodes. 
Let's say we created the previous Deployment with 5 replicas (instead of 2) and requesting 600 millicores instead of 500, 
on a four-node cluster where each (virtual) machine has 1 CPU. 
In that case one of the Pods will not be able to schedule. 
(Note that because of the cluster addon pods such as fluentd, skydns, etc., that run on each node, if we requested 1000 millicores then none of the Pods would be able to schedule.)
-->
<h2 id="例子-调试-pending-状态的-pod">例子: 调试 Pending 状态的 Pod</h2>
<p>可以使用事件来调试的一个常见的场景是，你创建 Pod 无法被调度到任何节点。
比如，Pod 请求的资源比较多，没有任何一个节点能够满足，或者它指定了一个标签，没有节点可匹配。
假定我们创建之前的 Deployment 时指定副本数是 5（不再是 2），并且请求 600 毫核（不再是 500），
对于一个 4 个节点的集群，若每个节点只有 1 个 CPU，这时至少有一个 Pod 不能被调度。
（需要注意的是，其他集群插件 Pod，比如 fluentd、skydns 等等会在每个节点上运行，
如果我们需求 1000 毫核，将不会有 Pod 会被调度。）</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods
</code></pre></div><pre tabindex="0"><code>NAME                                READY     STATUS    RESTARTS   AGE
nginx-deployment-1006230814-6winp   1/1       Running   0          7m
nginx-deployment-1006230814-fmgu3   1/1       Running   0          7m
nginx-deployment-1370807587-6ekbw   1/1       Running   0          1m
nginx-deployment-1370807587-fg172   0/1       Pending   0          1m
nginx-deployment-1370807587-fz9sd   0/1       Pending   0          1m
</code></pre><!--
To find out why the nginx-deployment-1370807587-fz9sd pod is not running, we can use `kubectl describe pod` on the pending Pod and look at its events:
-->
<p>为了查找 Pod nginx-deployment-1370807587-fz9sd 没有运行的原因，我们可以使用
<code>kubectl describe pod</code> 命令描述 Pod，查看其事件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pod nginx-deployment-1370807587-fz9sd
</code></pre></div><pre tabindex="0"><code>  Name:		nginx-deployment-1370807587-fz9sd
  Namespace:	default
  Node:		/
  Labels:		app=nginx,pod-template-hash=1370807587
  Status:		Pending
  IP:
  Controllers:	ReplicaSet/nginx-deployment-1370807587
  Containers:
    nginx:
      Image:	nginx
      Port:	80/TCP
      QoS Tier:
        memory:	Guaranteed
        cpu:	Guaranteed
      Limits:
        cpu:	1
        memory:	128Mi
      Requests:
        cpu:	1
        memory:	128Mi
      Environment Variables:
  Volumes:
    default-token-4bcbi:
      Type:	Secret (a volume populated by a Secret)
      SecretName:	default-token-4bcbi
  Events:
    FirstSeen	LastSeen	Count	From			        SubobjectPath	Type		Reason			    Message
    ---------	--------	-----	----			        -------------	--------	------			    -------
    1m		    48s		    7	    {default-scheduler }			        Warning		FailedScheduling	pod (nginx-deployment-1370807587-fz9sd) failed to fit in any node
  fit failure on node (kubernetes-node-6ta5): Node didn't have enough resource: CPU, requested: 1000, used: 1420, capacity: 2000
  fit failure on node (kubernetes-node-wul5): Node didn't have enough resource: CPU, requested: 1000, used: 1100, capacity: 2000
</code></pre><!--
Here you can see the event generated by the scheduler saying that the Pod failed to schedule for reason `FailedScheduling` (and possibly others).  
The message tells us that there were not enough resources for the Pod on any of the nodes.
-->
<p>这里你可以看到由调度器记录的事件，它表明了 Pod 不能被调度的原因是 <code>FailedScheduling</code>（也可能是其他值）。
其 message 部分表明没有任何节点拥有足够多的资源。</p>
<!--
To correct this situation, you can use `kubectl scale` to update your Deployment to specify four or fewer replicas. (Or you could leave the one Pod pending, which is harmless.)
-->
<p>要纠正这种情况，可以使用 <code>kubectl scale</code> 更新 Deployment，以指定 4 个或更少的副本。
(或者你可以让 Pod 继续保持这个状态，这是无害的。)</p>
<!--
Events such as the ones you saw at the end of `kubectl describe pod` are persisted in etcd and 
provide high-level information on what is happening in the cluster. 
To list all events you can use
-->
<p>你在 <code>kubectl describe pod</code> 结尾处看到的事件都保存在 etcd 中，
并提供关于集群中正在发生的事情的高级信息。
如果需要列出所有事件，可使用命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get events
</code></pre></div><!--
but you have to remember that events are namespaced. 
This means that if you're interested in events for some namespaced object 
(e.g. what happened with Pods in namespace `my-namespace`) you need to explicitly provide a namespace to the command:
-->
<p>但是，需要注意的是，事件是区分名字空间的。
如果你对某些名字空间域的对象（比如 <code>my-namespace</code> 名字下的 Pod）的事件感兴趣,
你需要显式地在命令行中指定名字空间：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get events --namespace<span style="color:#666">=</span>my-namespace
</code></pre></div><!--
To see events from all namespaces, you can use the `--all-namespaces` argument.
-->
<p>查看所有 namespace 的事件，可使用 <code>--all-namespaces</code> 参数。</p>
<!--
In addition to `kubectl describe pod`, another way to get extra information about a pod (beyond what is provided by `kubectl get pod`) is 
to pass the `-o yaml` output format flag to `kubectl get pod`. 
This will give you, in YAML format, even more information than `kubectl describe pod`--essentially all of the information the system has about the Pod. 
Here you will see things like annotations (which are key-value metadata without the label restrictions, that is used internally by Kubernetes system components), 
restart policy, ports, and volumes.
-->
<p>除了 <code>kubectl describe pod</code> 以外，另一种获取 Pod 额外信息（除了 <code>kubectl get pod</code>）的方法
是给 <code>kubectl get pod</code> 增加 <code>-o yaml</code> 输出格式参数。
该命令将以 YAML 格式为你提供比 <code>kubectl describe pod</code> 更多的信息 —— 实际上是系统拥有的关于 Pod 的所有信息。
在这里，你将看到注解（没有标签限制的键值元数据，由 Kubernetes 系统组件在内部使用）、
重启策略、端口和卷等。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod nginx-deployment-1006230814-6winp -o yaml
</code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">annotations</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubernetes.io/created-by</span>:<span style="color:#bbb"> </span>|<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">      </span><span style="color:#bbb">      </span>{<span style="color:#b44">&#34;kind&#34;</span>:<span style="color:#b44">&#34;SerializedReference&#34;</span>,<span style="color:#b44">&#34;apiVersion&#34;</span>:<span style="color:#b44">&#34;v1&#34;</span>,<span style="color:#b44">&#34;reference&#34;</span>:{<span style="color:#b44">&#34;kind&#34;</span>:<span style="color:#b44">&#34;ReplicaSet&#34;</span>,<span style="color:#b44">&#34;namespace&#34;</span>:<span style="color:#b44">&#34;default&#34;</span>,<span style="color:#b44">&#34;name&#34;</span>:<span style="color:#b44">&#34;nginx-deployment-1006230814&#34;</span>,<span style="color:#b44">&#34;uid&#34;</span>:<span style="color:#b44">&#34;4c84c175-f161-11e5-9a78-42010af00005&#34;</span>,<span style="color:#b44">&#34;apiVersion&#34;</span>:<span style="color:#b44">&#34;extensions&#34;</span>,<span style="color:#b44">&#34;resourceVersion&#34;</span>:<span style="color:#b44">&#34;133434&#34;</span>}}<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">creationTimestamp</span>:<span style="color:#bbb"> </span>2016-03-24T01:39:50Z<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">generateName</span>:<span style="color:#bbb"> </span>nginx-deployment-1006230814-<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">pod-template-hash</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;1006230814&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx-deployment-1006230814-6winp<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">namespace</span>:<span style="color:#bbb"> </span>default<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">resourceVersion</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;133447&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">uid</span>:<span style="color:#bbb"> </span>4c879808-f161-11e5-9a78-42010af00005<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">imagePullPolicy</span>:<span style="color:#bbb"> </span>Always<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">containerPort</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">protocol</span>:<span style="color:#bbb"> </span>TCP<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span>500m<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span>128Mi<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span>500m<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span>128Mi<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">terminationMessagePath</span>:<span style="color:#bbb"> </span>/dev/termination-log<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/var/run/secrets/kubernetes.io/serviceaccount<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>default-token-4bcbi<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">dnsPolicy</span>:<span style="color:#bbb"> </span>ClusterFirst<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">nodeName</span>:<span style="color:#bbb"> </span>kubernetes-node-wul5<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">restartPolicy</span>:<span style="color:#bbb"> </span>Always<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">securityContext</span>:<span style="color:#bbb"> </span>{}<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">serviceAccount</span>:<span style="color:#bbb"> </span>default<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">serviceAccountName</span>:<span style="color:#bbb"> </span>default<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">terminationGracePeriodSeconds</span>:<span style="color:#bbb"> </span><span style="color:#666">30</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>default-token-4bcbi<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">secret</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">secretName</span>:<span style="color:#bbb"> </span>default-token-4bcbi<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">conditions</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">lastProbeTime</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">null</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">lastTransitionTime</span>:<span style="color:#bbb"> </span>2016-03-24T01:39:51Z<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;True&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Ready<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">containerStatuses</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">containerID</span>:<span style="color:#bbb"> </span>docker://90315cc9f513c724e9957a4788d3e625a078de84750f244a40f97ae355eb1149<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">imageID</span>:<span style="color:#bbb"> </span>docker://6f62f48c4e55d700cf3eb1b5e33fa051802986b77b874cc351cce539e5163707<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">lastState</span>:<span style="color:#bbb"> </span>{}<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">ready</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">restartCount</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">state</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">running</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">startedAt</span>:<span style="color:#bbb"> </span>2016-03-24T01:39:51Z<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">hostIP</span>:<span style="color:#bbb"> </span><span style="color:#666">10.240.0.9</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">phase</span>:<span style="color:#bbb"> </span>Running<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">podIP</span>:<span style="color:#bbb"> </span><span style="color:#666">10.244.0.6</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">startTime</span>:<span style="color:#bbb"> </span>2016-03-24T01:39:49Z<span style="color:#bbb">
</span></code></pre></div><!--
## Example: debugging a down/unreachable node

Sometimes when debugging it can be useful to look at the status of a node 
-- for example, because you've noticed strange behavior of a Pod that's running on the node, 
or to find out why a Pod won't schedule onto the node. 
As with Pods, you can use `kubectl describe node` and `kubectl get node -o yaml` to 
retrieve detailed information about nodes. 
For example, here's what you'll see if a node is down 
(disconnected from the network, or kubelet dies and won't restart, etc.). 
Notice the events that show the node is NotReady, and 
also notice that the pods are no longer running 
(they are evicted after five minutes of NotReady status).
-->
<h2 id="示例-调试宕机或无法联系的节点">示例：调试宕机或无法联系的节点</h2>
<p>有时候，在调试时，查看节点的状态是很有用的 —— 例如，因为你已经注意到节点上运行的 Pod 的奇怪行为，
或者想了解为什么 Pod 不会调度到节点上。
与 Pod 一样，你可以使用 <code>kubectl describe node</code> 和 <code>kubectl get node -o yaml</code> 来查询节点的详细信息。
例如，如果某个节点宕机（与网络断开连接，或者 kubelet 挂掉无法重新启动等等），你将看到以下情况。
请注意显示节点未就绪的事件，也请注意 Pod 不再运行(它们在5分钟未就绪状态后被驱逐)。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get nodes
</code></pre></div><pre tabindex="0"><code>NAME                     STATUS       ROLES     AGE     VERSION
kubernetes-node-861h     NotReady     &lt;none&gt;    1h      v1.13.0
kubernetes-node-bols     Ready        &lt;none&gt;    1h      v1.13.0
kubernetes-node-st6x     Ready        &lt;none&gt;    1h      v1.13.0
kubernetes-node-unaj     Ready        &lt;none&gt;    1h      v1.13.0
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe node kubernetes-node-861h
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Name:			kubernetes-node-861h
Role
Labels:		 kubernetes.io/arch=amd64
           kubernetes.io/os=linux
           kubernetes.io/hostname=kubernetes-node-861h
Annotations:        node.alpha.kubernetes.io/ttl=0
                    volumes.kubernetes.io/controller-managed-attach-detach=true
Taints:             &lt;none&gt;
CreationTimestamp:	Mon, 04 Sep 2017 17:13:23 +0800
Phase:
Conditions:
  Type		Status		LastHeartbeatTime			LastTransitionTime			Reason					Message
  ----    ------    -----------------     ------------------      ------          -------
  OutOfDisk             Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
  MemoryPressure        Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
  DiskPressure          Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
  Ready                 Unknown         Fri, 08 Sep 2017 16:04:28 +0800         Fri, 08 Sep 2017 16:20:58 +0800         NodeStatusUnknown       Kubelet stopped posting node status.
Addresses:	10.240.115.55,104.197.0.26
Capacity:
 cpu:           2
 hugePages:     0
 memory:        4046788Ki
 pods:          110
Allocatable:
 cpu:           1500m
 hugePages:     0
 memory:        1479263Ki
 pods:          110
System Info:
 Machine ID:                    8e025a21a4254e11b028584d9d8b12c4
 System UUID:                   349075D1-D169-4F25-9F2A-E886850C47E3
 Boot ID:                       5cd18b37-c5bd-4658-94e0-e436d3f110e0
 Kernel Version:                4.4.0-31-generic
 OS Image:                      Debian GNU/Linux 8 (jessie)
 Operating System:              linux
 Architecture:                  amd64
 Container Runtime Version:     docker://1.12.5
 Kubelet Version:               v1.6.9+a3d1dfa6f4335
 Kube-Proxy Version:            v1.6.9+a3d1dfa6f4335
ExternalID:                     15233045891481496305
Non-terminated Pods:            (9 in total)
  Namespace                     Name                                            CPU Requests    CPU Limits      Memory Requests Memory Limits
  ---------                     ----                                            ------------    ----------      --------------- -------------
......
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  CPU Requests  CPU Limits      Memory Requests         Memory Limits
  ------------  ----------      ---------------         -------------
  900m (60%)    2200m (146%)    1009286400 (66%)        5681286400 (375%)
Events:         &lt;none&gt;
</code></pre><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get node kubernetes-node-861h -o yaml
</code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Node<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">creationTimestamp</span>:<span style="color:#bbb"> </span>2015-07-10T21:32:29Z<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubernetes.io/hostname</span>:<span style="color:#bbb"> </span>kubernetes-node-861h<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>kubernetes-node-861h<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">resourceVersion</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;757&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selfLink</span>:<span style="color:#bbb"> </span>/api/v1/nodes/kubernetes-node-861h<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">uid</span>:<span style="color:#bbb"> </span>2a69374e-274b-11e5-a234-42010af0d969<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">externalID</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;15233045891481496305&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">podCIDR</span>:<span style="color:#bbb"> </span><span style="color:#666">10.244.0.0</span>/24<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">providerID</span>:<span style="color:#bbb"> </span>gce://striped-torus-760/us-central1-b/kubernetes-node-861h<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">addresses</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">address</span>:<span style="color:#bbb"> </span><span style="color:#666">10.240.115.55</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>InternalIP<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">address</span>:<span style="color:#bbb"> </span><span style="color:#666">104.197.0.26</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>ExternalIP<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">capacity</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;1&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span>3800808Ki<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">pods</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;100&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">conditions</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">lastHeartbeatTime</span>:<span style="color:#bbb"> </span>2015-07-10T21:34:32Z<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">lastTransitionTime</span>:<span style="color:#bbb"> </span>2015-07-10T21:35:15Z<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">reason</span>:<span style="color:#bbb"> </span>Kubelet stopped posting node status.<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">status</span>:<span style="color:#bbb"> </span>Unknown<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">type</span>:<span style="color:#bbb"> </span>Ready<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">nodeInfo</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">bootID</span>:<span style="color:#bbb"> </span><span style="color:#666">4e316776</span>-b40d-4f78-a4ea-ab0d73390897<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">containerRuntimeVersion</span>:<span style="color:#bbb"> </span>docker://Unknown<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kernelVersion</span>:<span style="color:#bbb"> </span><span style="color:#666">3.16.0-0.</span>bpo.4-amd64<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubeProxyVersion</span>:<span style="color:#bbb"> </span>v0.21.1-185-gffc5a86098dc01<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubeletVersion</span>:<span style="color:#bbb"> </span>v0.21.1-185-gffc5a86098dc01<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">machineID</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">osImage</span>:<span style="color:#bbb"> </span>Debian GNU/Linux 7 (wheezy)<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">systemUUID</span>:<span style="color:#bbb"> </span>ABE5F6B4-D44B-108B-C46A-24CCE16C8B6E<span style="color:#bbb">
</span></code></pre></div><h2 id="接下来">接下来</h2>
<!--
Learn about additional debugging tools, including:
-->
<p>了解更多的调试工具：</p>
<!--
* [Logging](/docs/concepts/cluster-administration/logging/)
* [Monitoring](/docs/tasks/debug-application-cluster/resource-usage-monitoring/)
* [Getting into containers via `exec`](/docs/tasks/debug-application-cluster/get-shell-running-container/)
* [Connecting to containers via proxies](/docs/tasks/extend-kubernetes/http-proxy-access-api/)
* [Connecting to containers via port forwarding](/docs/tasks/access-application-cluster/port-forward-access-application-cluster/)
* [Inspect Kubernetes node with crictl](/docs/tasks/debug-application-cluster/crictl/)
-->
<ul>
<li><a href="/zh/docs/concepts/cluster-administration/logging/">日志</a></li>
<li><a href="/zh/docs/tasks/debug-application-cluster/resource-usage-monitoring/">监控</a></li>
<li><a href="/zh/docs/tasks/debug-application-cluster/get-shell-running-container/">使用 <code>exec</code> 进入容器</a></li>
<li><a href="/zh/docs/tasks/extend-kubernetes/http-proxy-access-api/">使用代理连接容器</a></li>
<li><a href="/zh/docs/tasks/access-application-cluster/port-forward-access-application-cluster/">使用端口转发连接容器</a></li>
<li><a href="/zh/docs/tasks/debug-application-cluster/crictl/">使用 crictl 检查节点</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-434e0133d71583a27478b10fc1d3d105">6 - 故障诊断</h1>
    
	<!--
reviewers:
- brendandburns
- davidopp
content_type: concept
title: Troubleshooting
-->
<!-- overview -->
<!--
Sometimes things go wrong. This guide is aimed at making them right. It has
two sections:
-->
<p>有时候事情会出错。本指南旨在解决这些问题。它包含两个部分：</p>
<!--
   * [Troubleshooting your application](/docs/tasks/debug-application-cluster/debug-application/) - Useful for users who are deploying code into Kubernetes and wondering why it is not working.
   * [Troubleshooting your cluster](/docs/tasks/debug-application-cluster/debug-cluster/) - Useful for cluster administrators and people whose Kubernetes cluster is unhappy.
-->
<ul>
<li><a href="/zh/docs/tasks/debug-application-cluster/debug-application/">应用排错</a> -
针对部署代码到 Kubernetes 并想知道代码为什么不能正常运行的用户。</li>
<li><a href="/zh/docs/tasks/debug-application-cluster/debug-cluster/">集群排错</a> -
针对集群管理员以及 Kubernetes 集群表现异常的用户。</li>
</ul>
<!--
You should also check the known issues for the [release](https://github.com/kubernetes/kubernetes/releases)
you're using.
-->
<p>你也应该查看所用<a href="https://github.com/kubernetes/kubernetes/releases">发行版本</a>的已知问题。</p>
<!-- body -->
<!--
## Getting help

If your problem isn't answered by any of the guides above, there are variety of
ways for you to get help from the Kubernetes team.
-->
<h2 id="getting-help">获取帮助 </h2>
<p>如果你的问题在上述指南中没有得到答案，你还有另外几种方式从 Kubernetes 团队获得帮助。</p>
<!--
### Questions

The documentation on this site has been structured to provide answers to a wide
range of questions. [Concepts](/docs/concepts/) explain the Kubernetes
architecture and how each component works, while [Setup](/docs/setup/) provides
practical instructions for getting started. [Tasks](/docs/tasks/) show how to
accomplish commonly used tasks, and [Tutorials](/docs/tutorials/) are more
comprehensive walkthroughs of real-world, industry-specific, or end-to-end
development scenarios. The [Reference](/docs/reference/) section provides
detailed documentation on the [Kubernetes API](/docs/reference/generated/kubernetes-api/v1.22/)
and command-line interfaces (CLIs), such as [`kubectl`](/docs/user-guide/kubectl-overview/).
-->
<h3 id="questions">问题 </h3>
<p>本网站上的文档针对回答各类问题进行了结构化组织和分类。
<a href="/zh/docs/concepts/">概念</a>部分解释 Kubernetes 体系结构以及每个组件的工作方式，
<a href="/zh/docs/setup/">安装</a>部分提供了安装的实用说明。
<a href="/zh/docs/tasks/">任务</a>部分展示了如何完成常用任务，
<a href="/zh/docs/tutorials/">教程</a>部分则提供对现实世界、特定行业或端到端开发场景的更全面的演练。
<a href="/zh/docs/reference/">参考</a>部分提供了详细的
<a href="/docs/reference/generated/kubernetes-api/v1.22/">Kubernetes API</a> 文档
和命令行 (CLI) 接口的文档，例如<a href="/zh/docs/reference/kubectl/overview/"><code>kubectl</code></a>。</p>
<!--
## Help! My question isn't covered!  I need help now!
-->
<h2 id="求救-我的问题还没有解决-我现在需要帮助">求救！我的问题还没有解决！我现在需要帮助！</h2>
<!--
### Stack Overflow

Someone else from the community may have already asked a similar question or may
be able to help with your problem. The Kubernetes team will also monitor
[posts tagged Kubernetes](https://stackoverflow.com/questions/tagged/kubernetes).
If there aren't any existing questions that help, please
[ask a new one](https://stackoverflow.com/questions/ask?tags=kubernetes)!
-->
<h3 id="stack-overflow">Stack Overflow   </h3>
<p>社区中的其他人可能已经问过和你类似的问题，也可能能够帮助解决你的问题。
Kubernetes 团队还会监视<a href="https://stackoverflow.com/questions/tagged/kubernetes">带有 Kubernetes 标签的帖子</a>。
如果现有的问题对你没有帮助，请<a href="https://stackoverflow.com/questions/ask?tags=kubernetes">问一个新问题</a>!</p>
<!--
### Slack

Many people from the Kubernetes community hang out on Kubernetes Slack in the `#kubernetes-users` channel.
Slack requires registration; you can [request an invitation](https://slack.kubernetes.io),
and registration is open to everyone). Feel free to come and ask any and all questions.
Once registered, access the [Kubernetes organisation in Slack](https://kubernetes.slack.com)
via your web browser or via Slack's own dedicated app.
-->
<h3 id="slack">Slack</h3>
<p>Kubernetes 社区中有很多人在 <code>#kubernetes-users</code> 这一 Slack 频道聚集。
Slack 需要注册；你可以<a href="https://slack.kubernetes.io">请求一份邀请</a>，
并且注册是对所有人开放的。欢迎你随时来问任何问题。
一旦注册了，就可以访问通过 Web 浏览器或者 Slack 专用的应用访问
<a href="https://kubernetes.slack.com">Slack 上的 Kubernetes 组织</a>。</p>
<!--
Once you are registered, browse the growing list of channels for various subjects of
interest. For example, people new to Kubernetes may also want to join the
[`#kubernetes-novice`](https://kubernetes.slack.com/messages/kubernetes-novice) channel. As another example, developers should join the
[`#kubernetes-dev`](https://kubernetes.slack.com/messages/kubernetes-dev) channel.
-->
<p>一旦你完成了注册，就可以浏览各种感兴趣主题的频道列表（一直在增长）。
例如，Kubernetes 新人可能还想加入
<a href="https://kubernetes.slack.com/messages/kubernetes-novice"><code>#kubernetes-novice</code></a>
频道。又比如，开发人员应该加入
<a href="https://kubernetes.slack.com/messages/kubernetes-dev"><code>#kubernetes-dev</code></a>
频道。</p>
<!--
There are also many country specific/local language channels. Feel free to join
these channels for localized support and info:
-->
<p>还有许多国家/地区语言频道。请随时加入这些频道以获得本地化支持和信息：</p>





<!--
Country | Channels
:---------|:------------
China | [`#cn-users`](https://kubernetes.slack.com/messages/cn-users), [`#cn-events`](https://kubernetes.slack.com/messages/cn-events)
Finland | [`#fi-users`](https://kubernetes.slack.com/messages/fi-users)
France | [`#fr-users`](https://kubernetes.slack.com/messages/fr-users), [`#fr-events`](https://kubernetes.slack.com/messages/fr-events)
Germany | [`#de-users`](https://kubernetes.slack.com/messages/de-users), [`#de-events`](https://kubernetes.slack.com/messages/de-events)
India | [`#in-users`](https://kubernetes.slack.com/messages/in-users), [`#in-events`](https://kubernetes.slack.com/messages/in-events)
Italy | [`#it-users`](https://kubernetes.slack.com/messages/it-users), [`#it-events`](https://kubernetes.slack.com/messages/it-events)
Japan | [`#jp-users`](https://kubernetes.slack.com/messages/jp-users), [`#jp-events`](https://kubernetes.slack.com/messages/jp-events)
Korea | [`#kr-users`](https://kubernetes.slack.com/messages/kr-users)
Netherlands | [`#nl-users`](https://kubernetes.slack.com/messages/nl-users)
Norway | [`#norw-users`](https://kubernetes.slack.com/messages/norw-users)
Poland | [`#pl-users`](https://kubernetes.slack.com/messages/pl-users)
Russia | [`#ru-users`](https://kubernetes.slack.com/messages/ru-users)
Spain | [`#es-users`](https://kubernetes.slack.com/messages/es-users)
Sweden | [`#se-users`](https://kubernetes.slack.com/messages/se-users)
Turkey | [`#tr-users`](https://kubernetes.slack.com/messages/tr-users), [`#tr-events`](https://kubernetes.slack.com/messages/tr-events)
-->
<table><caption style="display: none;">Country / language specific Slack channels</caption>
<thead>
<tr>
<th style="text-align:left">国家</th>
<th style="text-align:left">频道</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">中国</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/cn-users"><code>#cn-users</code></a>, <a href="https://kubernetes.slack.com/messages/cn-events"><code>#cn-events</code></a></td>
</tr>
<tr>
<td style="text-align:left">芬兰</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/fi-users"><code>#fi-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">法国</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/fr-users"><code>#fr-users</code></a>, <a href="https://kubernetes.slack.com/messages/fr-events"><code>#fr-events</code></a></td>
</tr>
<tr>
<td style="text-align:left">德国</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/de-users"><code>#de-users</code></a>, <a href="https://kubernetes.slack.com/messages/de-events"><code>#de-events</code></a></td>
</tr>
<tr>
<td style="text-align:left">印度</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/in-users"><code>#in-users</code></a>, <a href="https://kubernetes.slack.com/messages/in-events"><code>#in-events</code></a></td>
</tr>
<tr>
<td style="text-align:left">意大利</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/it-users"><code>#it-users</code></a>, <a href="https://kubernetes.slack.com/messages/it-events"><code>#it-events</code></a></td>
</tr>
<tr>
<td style="text-align:left">日本</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/jp-users"><code>#jp-users</code></a>, <a href="https://kubernetes.slack.com/messages/jp-events"><code>#jp-events</code></a></td>
</tr>
<tr>
<td style="text-align:left">韩国</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/kr-users"><code>#kr-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">荷兰</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/nl-users"><code>#nl-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">挪威</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/norw-users"><code>#norw-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">波兰</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/pl-users"><code>#pl-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">俄罗斯</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/ru-users"><code>#ru-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">西班牙</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/es-users"><code>#es-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">瑞典</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/se-users"><code>#se-users</code></a></td>
</tr>
<tr>
<td style="text-align:left">土耳其</td>
<td style="text-align:left"><a href="https://kubernetes.slack.com/messages/tr-users"><code>#tr-users</code></a>, <a href="https://kubernetes.slack.com/messages/tr-events"><code>#tr-events</code></a></td>
</tr>
</tbody>
</table>

<!--
### Forum

You're welcome to join the official Kubernetes Forum: [discuss.kubernetes.io](https://discuss.kubernetes.io).
-->
<h3 id="forum">论坛 </h3>
<p>欢迎你加入 Kubernetes 官方论坛
<a href="https://discuss.kubernetes.io">discuss.kubernetes.io</a>。</p>
<!--
### Bugs and Feature requests

If you have what looks like a bug, or you would like to make a feature request,
please use the [Github issue tracking system](https://github.com/kubernetes/kubernetes/issues).
-->
<h3 id="bugs-and-feature-requests">Bugs 和功能请求  </h3>
<p>如果你发现一个看起来像 Bug 的问题，或者你想提出一个功能请求，请使用
<a href="https://github.com/kubernetes/kubernetes/issues">Github 问题跟踪系统</a>。</p>
<!--
Before you file an issue, please search existing issues to see if your issue is
already covered.

If filing a bug, please include detailed information about how to reproduce the
problem, such as:
-->
<p>在提交问题之前，请搜索现有问题列表以查看是否其中已涵盖你的问题。</p>
<p>如果提交 Bug，请提供如何重现问题的详细信息，例如：</p>
<!--
* Kubernetes version: `kubectl version`
* Cloud provider, OS distro, network configuration, and Docker version
* Steps to reproduce the problem
-->
<ul>
<li>Kubernetes 版本：<code>kubectl version</code></li>
<li>云平台、OS 发行版、网络配置和 Docker 版本</li>
<li>重现问题的步骤</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-ef360b1f8e65236251826db478cfcab3">7 - 确定 Pod 失败的原因</h1>
    
	<!--
title: Determine the Reason for Pod Failure
content_type: task
-->
<!-- overview -->
<!--
This page shows how to write and read a Container
termination message.
-->
<p>本文介绍如何编写和读取容器的终止消息。</p>
<!--
Termination messages provide a way for containers to write information about
fatal events to a location where it can be easily retrieved and surfaced by
tools like dashboards and monitoring software. In most cases, information that
you put in a termination message should also be written to the general
[Kubernetes logs](/docs/concepts/cluster-administration/logging/).
-->
<p>终止消息为容器提供了一种方法，可以将有关致命事件的信息写入某个位置，
在该位置可以通过仪表板和监控软件等工具轻松检索和显示致命事件。
在大多数情况下，您放入终止消息中的信息也应该写入
<a href="/zh/docs/concepts/cluster-administration/logging/">常规 Kubernetes 日志</a>。</p>
<h2 id="准备开始">准备开始</h2>
<p><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
如果你还没有集群，你可以通过 <a href="/zh/docs/tasks/tools/#minikube">Minikube</a> 构建一
个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. If you do not already have a
cluster, you can create one by using
[minikube](/docs/tasks/tools/#minikube)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 
 要获知版本信息，请输入 <code>kubectl version</code>.
</p>
<!-- steps -->
<!--
## Writing and reading a termination message

In this exercise, you create a Pod that runs one container.
The configuration file specifies a command that runs when
the container starts.
-->
<h2 id="读写终止消息">读写终止消息</h2>
<p>在本练习中，您将创建运行一个容器的 Pod。
配置文件指定在容器启动时要运行的命令。</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/debug/termination.yaml" download="debug/termination.yaml"><code>debug/termination.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('debug-termination-yaml')" title="Copy debug/termination.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="debug-termination-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>termination-demo<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>termination-demo-container<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>debian<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">command</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;/bin/sh&#34;</span>]<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">args</span>:<span style="color:#bbb"> </span>[<span style="color:#b44">&#34;-c&#34;</span>,<span style="color:#bbb"> </span><span style="color:#b44">&#34;sleep 10 &amp;&amp; echo Sleep expired &gt; /dev/termination-log&#34;</span>]<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<ol>
<li>
<!--Create a Pod based on the YAML configuration file:-->基于 YAML 配置文件创建 Pod：
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create -f https://k8s.io/examples/debug/termination.yaml
</code></pre></div><!--In the YAML file, in the `command` and `args` fields, you can see that the
container sleeps for 10 seconds and then writes "Sleep expired" to
the `/dev/termination-log` file. After the container writes
the "Sleep expired" message, it terminates.-->
<p>YAML 文件中，在 <code>command</code> 和 <code>args</code> 字段，你可以看到容器休眠 10 秒然后将 &quot;Sleep expired&quot;
写入 <code>/dev/termination-log</code> 文件。
容器写完 &quot;Sleep expired&quot; 消息后就终止了。</p>
</li>
<li>
<!--Display information about the Pod:-->显示 Pod 的信息：
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod termination-demo
</code></pre></div><!--Repeat the preceding command until the Pod is no longer running.-->
<p>重复前面的命令直到 Pod 不再运行。</p>
</li>
<li>
<!--Display detailed information about the Pod:-->
<p>显示 Pod 的详细信息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod --output<span style="color:#666">=</span>yaml
</code></pre></div><!--The output includes the "Sleep expired" message:-->输出结果包含 "Sleep expired" 消息：
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#00f;font-weight:bold">...</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">lastState</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">terminated</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">containerID</span>:<span style="color:#bbb"> </span>...<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">exitCode</span>:<span style="color:#bbb"> </span><span style="color:#666">0</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">finishedAt</span>:<span style="color:#bbb"> </span>...<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">message</span>:<span style="color:#bbb"> </span>|<span style="color:#b44;font-style:italic">
</span><span style="color:#b44;font-style:italic">          </span><span style="color:#bbb">          </span>Sleep expired<span style="color:#bbb">
</span><span style="color:#bbb">        </span>...<span style="color:#bbb">
</span></code></pre></div></li>
<li>
<!--Use a Go template to filter the output so that it includes only the termination message:-->
<p>使用 Go 模板过滤输出结果，使其只含有终止消息：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod termination-demo -o go-template<span style="color:#666">=</span><span style="color:#b44">&#34;{{range .status.containerStatuses}}{{.lastState.terminated.message}}{{end}}&#34;</span>
</code></pre></div></li>
</ol>
<!--
## Customizing the termination message

Kubernetes retrieves termination messages from the termination message file
specified in the `terminationMessagePath` field of a Container, which as a default
value of `/dev/termination-log`. By customizing this field, you can tell Kubernetes
to use a different file. Kubernetes use the contents from the specified file to
populate the Container's status message on both success and failure.
-->
<h2 id="定制终止消息">定制终止消息</h2>
<p>Kubernetes 从容器的 <code>terminationMessagePath</code> 字段中指定的终止消息文件中检索终止消息，
默认值为 <code>/dev/termination-log</code>。
通过定制这个字段，您可以告诉 Kubernetes 使用不同的文件。
Kubernetes 使用指定文件中的内容在成功和失败时填充容器的状态消息。</p>
<!--
In the following example, the container writes termination messages to
`/tmp/my-log` for Kubernetes to retrieve:
-->
<p>在下例中，容器将终止消息写入 <code>/tmp/my-log</code> 给 Kubernetes 来接收：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>msg-path-demo<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>msg-path-demo-container<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>debian<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">terminationMessagePath</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;/tmp/my-log&#34;</span><span style="color:#bbb">
</span></code></pre></div><!--
Moreover, users can set the `terminationMessagePolicy` field of a Container for
further customization. This field defaults to "`File`" which means the termination
messages are retrieved only from the termination message file. By setting the
`terminationMessagePolicy` to "`FallbackToLogsOnError`", you can tell Kubernetes
to use the last chunk of container log output if the termination message file
is empty and the container exited with an error. The log output is limited to
2048 bytes or 80 lines, whichever is smaller.
-->
<p>此外，用户可以设置容器的 <code>terminationMessagePolicy</code> 字段，以便进一步自定义。
此字段默认为 &quot;<code>File</code>&quot;，这意味着仅从终止消息文件中检索终止消息。
通过将 <code>terminationMessagePolicy</code> 设置为 &quot;<code>FallbackToLogsOnError</code>&quot;，你就可以告诉 Kubernetes，在容器因错误退出时，如果终止消息文件为空，则使用容器日志输出的最后一块作为终止消息。
日志输出限制为 2048 字节或 80 行，以较小者为准。</p>
<h2 id="接下来">接下来</h2>
<!--
* See the `terminationMessagePath` field in
  [Container](/docs/reference/generated/kubernetes-api/v1.22/#container-v1-core).
* Learn about [retrieving logs](/docs/concepts/cluster-administration/logging/).
* Learn about [Go templates](https://golang.org/pkg/text/template/).
-->
<ul>
<li>参考 <a href="/docs/reference/generated/kubernetes-api/v1.22/#container-v1-core">Container</a>
资源的 <code>terminationMessagePath</code> 字段。</li>
<li>了解<a href="/zh/docs/concepts/cluster-administration/logging/">接收日志</a>。</li>
<li>了解 <a href="https://golang.org/pkg/text/template/">Go 模版</a>。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-bc729eafe3688124d3a6f1110bd5a89c">8 - 节点健康监测</h1>
    
	<!-- 
title: Monitor Node Health
content_type: task
reviewers:
- Random-Liu
- dchen1107
-->
<!-- overview -->
<!-- 
*Node Problem Detector* is a daemon for monitoring and reporting about a node's health.
You can run Node Problem Detector as a `DaemonSet` or as a standalone daemon.
Node Problem Detector collects information about node problems from various daemons
and reports these conditions to the API server as [NodeCondition](/docs/concepts/architecture/nodes/#condition)
and [Event](/docs/reference/generated/kubernetes-api/v1.22/#event-v1-core). 

To learn how to install and use Node Problem Detector, see
[Node Problem Detector project documentation](https://github.com/kubernetes/node-problem-detector).
-->
<p><em>节点问题检测器（Node Problem Detector）</em> 是一个守护程序，用于监视和报告节点的健康状况。
你可以将节点问题探测器以 <code>DaemonSet</code> 或独立守护程序运行。
节点问题检测器从各种守护进程收集节点问题，并以
<a href="/zh/docs/concepts/architecture/nodes/#condition">NodeCondition</a> 和
<a href="/docs/reference/generated/kubernetes-api/v1.22/#event-v1-core">Event</a>
的形式报告给 API 服务器。</p>
<p>要了解如何安装和使用节点问题检测器，请参阅
<a href="https://github.com/kubernetes/node-problem-detector">节点问题探测器项目文档</a>。</p>
<h2 id="准备开始">准备开始</h2>
<p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
如果你还没有集群，你可以通过 <a href="/zh/docs/tasks/tools/#minikube">Minikube</a> 构建一
个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. If you do not already have a
cluster, you can create one by using
[minikube](/docs/tasks/tools/#minikube)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>

<!-- steps -->
<!-- 
## Limitations 

* Node Problem Detector only supports file based kernel log.
  Log tools such as `journald` are not supported.

* Node Problem Detector uses the kernel log format for reporting kernel issues.
  To learn how to extend the kernel log format, see [Add support for another log format](#support-other-log-format).
-->
<h2 id="limitations">局限性 </h2>
<ul>
<li>节点问题检测器只支持基于文件类型的内核日志。
它不支持像 journald 这样的命令行日志工具。</li>
<li>节点问题检测器使用内核日志格式来报告内核问题。
要了解如何扩展内核日志格式，请参阅<a href="#support-other-log-format">添加对另一个日志格式的支持</a>。</li>
</ul>
<!-- 
## Enabling Node Problem Detector

Some cloud providers enable Node Problem Detector as an <a class='glossary-tooltip' title='扩展 Kubernetes 功能的资源。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/cluster-administration/addons/' target='_blank' aria-label='Addon'>Addon</a>.
You can also enable Node Problem Detector with `kubectl` or by creating an Addon pod.
-->
<h2 id="启用节点问题检测器">启用节点问题检测器</h2>
<p>一些云供应商将节点问题检测器以<a class='glossary-tooltip' title='扩展 Kubernetes 功能的资源。' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/cluster-administration/addons/' target='_blank' aria-label='插件'>插件</a>形式启用。
你还可以使用 <code>kubectl</code> 或创建插件 Pod 来启用节点问题探测器。</p>
<!-- 
## Using kubectl to enable Node Problem Detector {#using-kubectl}

`kubectl` provides the most flexible management of Node Problem Detector.
You can overwrite the default configuration to fit it into your environment or
to detect customized node problems. For example:
-->
<h2 id="using-kubectl">使用 kubectl 启用节点问题检测器</h2>
<p><code>kubectl</code> 提供了节点问题探测器最灵活的管理。
你可以覆盖默认配置使其适合你的环境或检测自定义节点问题。例如：</p>
<!-- 
1. Create a Node Problem Detector configuration similar to `node-problem-detector.yaml`:

   

 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/debug/node-problem-detector.yaml" download="debug/node-problem-detector.yaml"><code>debug/node-problem-detector.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('debug-node-problem-detector-yaml')" title="Copy debug/node-problem-detector.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="debug-node-problem-detector-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>DaemonSet<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector-v0.1<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">namespace</span>:<span style="color:#bbb"> </span>kube-system<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector  <span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">hostNetwork</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>k8s.gcr.io/node-problem-detector:v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">securityContext</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">privileged</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;200m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;100Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span>/var/log/</code></pre></div>
    </div>
</div>



   <blockquote class="note callout">
  <div><strong>说明：</strong> You should verify that the system log directory is right for your operating system distribution.</div>
</blockquote>

1. Start node problem detector with `kubectl`:

   ```shell
   kubectl apply -f https://k8s.io/examples/debug/node-problem-detector.yaml
   ```
-->
<ol>
<li>
<p>创建类似于 <code>node-strought-detector.yaml</code> 的节点问题检测器配置：


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/debug/node-problem-detector.yaml" download="debug/node-problem-detector.yaml"><code>debug/node-problem-detector.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('debug-node-problem-detector-yaml')" title="Copy debug/node-problem-detector.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="debug-node-problem-detector-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>DaemonSet<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector-v0.1<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">namespace</span>:<span style="color:#bbb"> </span>kube-system<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector  <span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">hostNetwork</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>k8s.gcr.io/node-problem-detector:v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">securityContext</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">privileged</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;200m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;100Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span>/var/log/</code></pre></div>
    </div>
</div>

</p>
<blockquote class="note callout">
  <div><strong>说明：</strong> 你应该检查系统日志目录是否适用于操作系统发行版本。</div>
</blockquote>
</li>
<li>
<p>使用 <code>kubectl</code> 启动节点问题检测器：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://k8s.io/examples/debug/node-problem-detector.yaml
</code></pre></div></li>
</ol>
<!-- 
### Using an Addon pod to enable Node Problem Detector {#using-addon-pod}

If you are using a custom cluster bootstrap solution and don't need
to overwrite the default configuration, you can leverage the Addon pod to
further automate the deployment.

Create `node-problem-detector.yaml`, and save the configuration in the Addon pod's
directory `/etc/kubernetes/addons/node-problem-detector` on a control plane node.
-->
<h3 id="using-addon-pod">使用插件 pod 启用节点问题检测器</h3>
<p>如果你使用的是自定义集群引导解决方案，不需要覆盖默认配置，
可以利用插件 Pod 进一步自动化部署。</p>
<p>创建 <code>node-strick-detector.yaml</code>，并在控制平面节点上保存配置到插件 Pod 的目录
<code>/etc/kubernetes/addons/node-problem-detector</code>。</p>
<!-- 
## Overwrite the Configuration 

The [default configuration](https://github.com/kubernetes/node-problem-detector/tree/v0.1/config)
is embedded when building the Docker image of Node Problem Detector.
-->
<h2 id="覆盖配置文件">覆盖配置文件</h2>
<p>构建节点问题检测器的 docker 镜像时，会嵌入
<a href="https://github.com/kubernetes/node-problem-detector/tree/v0.1/config">默认配置</a>。</p>
<!-- 
However, you can use a [`ConfigMap`](/docs/tasks/configure-pod-container/configure-pod-configmap/)
to overwrite the configuration:
-->
<p>不过，你可以像下面这样使用 <a href="/zh/docs/tasks/configure-pod-container/configure-pod-configmap/"><code>ConfigMap</code></a>
将其覆盖：</p>
<!-- 
1. Change the configuration files in `config/`
1. Create the `ConfigMap` `node-problem-detector-config`:

   ```shell
   kubectl create configmap node-problem-detector-config --from-file=config/
   ```

1. Change the `node-problem-detector.yaml` to use the `ConfigMap`:

   

 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/debug/node-problem-detector-configmap.yaml" download="debug/node-problem-detector-configmap.yaml"><code>debug/node-problem-detector-configmap.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('debug-node-problem-detector-configmap-yaml')" title="Copy debug/node-problem-detector-configmap.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="debug-node-problem-detector-configmap-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>DaemonSet<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector-v0.1<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">namespace</span>:<span style="color:#bbb"> </span>kube-system<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector  <span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">hostNetwork</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>k8s.gcr.io/node-problem-detector:v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">securityContext</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">privileged</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;200m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;100Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>config<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Overwrite the config/ directory with ConfigMap volume</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/config<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span>/var/log/<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>config<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Define ConfigMap volume</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">configMap</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector-config</code></pre></div>
    </div>
</div>



1. Recreate the Node Problem Detector with the new configuration file:

   ```shell
   # If you have a node-problem-detector running, delete before recreating
   kubectl delete -f https://k8s.io/examples/debug/node-problem-detector.yaml
   kubectl apply -f https://k8s.io/examples/debug/node-problem-detector-configmap.yaml
   ```
 -->
<ol>
<li>
<p>更改 <code>config/</code> 中的配置文件</p>
</li>
<li>
<p>创建 <code>ConfigMap</code> <code>node-strick-detector-config</code>：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create configmap node-problem-detector-config --from-file<span style="color:#666">=</span>config/
</code></pre></div></li>
<li>
<p>更改 <code>node-problem-detector.yaml</code> 以使用 ConfigMap:</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/debug/node-problem-detector-configmap.yaml" download="debug/node-problem-detector-configmap.yaml"><code>debug/node-problem-detector-configmap.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('debug-node-problem-detector-configmap-yaml')" title="Copy debug/node-problem-detector-configmap.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="debug-node-problem-detector-configmap-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>DaemonSet<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector-v0.1<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">namespace</span>:<span style="color:#bbb"> </span>kube-system<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector  <span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">k8s-app</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">version</span>:<span style="color:#bbb"> </span>v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">kubernetes.io/cluster-service</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;true&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">hostNetwork</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>k8s.gcr.io/node-problem-detector:v0.1<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">securityContext</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">privileged</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">resources</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">limits</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;200m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;100Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">requests</span>:<span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">cpu</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20m&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">            </span><span style="color:#008000;font-weight:bold">memory</span>:<span style="color:#bbb"> </span><span style="color:#b44">&#34;20Mi&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/log<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>config<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Overwrite the config/ directory with ConfigMap volume</span><span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/config<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">readOnly</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>log<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">hostPath</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">path</span>:<span style="color:#bbb"> </span>/var/log/<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>config<span style="color:#bbb"> </span><span style="color:#080;font-style:italic"># Define ConfigMap volume</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">configMap</span>:<span style="color:#bbb">
</span><span style="color:#bbb">          </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>node-problem-detector-config</code></pre></div>
    </div>
</div>


</li>
<li>
<p>使用新的配置文件重新创建节点问题检测器：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#080;font-style:italic"># 如果你正在运行节点问题检测器，请先删除，然后再重新创建</span>
kubectl delete -f https://k8s.io/examples/debug/node-problem-detector.yaml
kubectl apply -f https://k8s.io/examples/debug/node-problem-detector-configmap.yaml
</code></pre></div></li>
</ol>
<!--  
<blockquote class="note callout">
  <div><strong>说明：</strong> This approach only applies to a Node Problem Detector started with <code>kubectl</code>.</div>
</blockquote>

Overwriting a configuration is not supported if a Node Problem Detector runs as a cluster Addon.
The Addon manager does not support `ConfigMap`.
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> 此方法仅适用于通过 <code>kubectl</code> 启动的节点问题检测器。</div>
</blockquote>
<p>如果节点问题检测器作为集群插件运行，则不支持覆盖配置。
插件管理器不支持 <code>ConfigMap</code>。</p>
<!-- 
## Kernel Monitor 

*Kernel Monitor* is a system log monitor daemon supported in the Node Problem Detector.
Kernel monitor watches the kernel log and detects known kernel issues following predefined rules.
-->
<h2 id="内核监视器">内核监视器</h2>
<p><em>内核监视器（Kernel Monitor）</em> 是节点问题检测器中支持的系统日志监视器守护进程。
内核监视器观察内核日志并根据预定义规则检测已知的内核问题。</p>
<!-- 
The Kernel Monitor matches kernel issues according to a set of predefined rule list in
[`config/kernel-monitor.json`](https://github.com/kubernetes/node-problem-detector/blob/v0.1/config/kernel-monitor.json). The rule list is extensible. You can expand the rule list by overwriting the
configuration.
-->
<p>内核监视器根据 <a href="https://github.com/kubernetes/node-problem-detector/blob/v0.1/config/kernel-monitor.json"><code>config/kernel-monitor.json</code></a>
中的一组预定义规则列表匹配内核问题。
规则列表是可扩展的，你始终可以通过覆盖配置来扩展它。</p>
<!-- 
### Add new NodeConditions 

To support a new `NodeCondition`, create a condition definition within the `conditions` field in
`config/kernel-monitor.json`, for example:
```
-->
<h3 id="添加新的-nodecondition">添加新的 NodeCondition</h3>
<p>要支持新的 <code>NodeCondition</code>，请在 <code>config/kernel-monitor.json</code> 中的
<code>conditions</code> 字段中创建一个条件定义：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
  <span style="color:#008000;font-weight:bold">&#34;type&#34;</span>: <span style="color:#b44">&#34;NodeConditionType&#34;</span>,
  <span style="color:#008000;font-weight:bold">&#34;reason&#34;</span>: <span style="color:#b44">&#34;CamelCaseDefaultNodeConditionReason&#34;</span>,
  <span style="color:#008000;font-weight:bold">&#34;message&#34;</span>: <span style="color:#b44">&#34;arbitrary default node condition message&#34;</span>
}
</code></pre></div><!-- 
### Detect new problems 

To detect new problems, you can extend the `rules` field in `config/kernel-monitor.json`
with a new rule definition:
-->
<h3 id="检测新的问题">检测新的问题</h3>
<p>你可以使用新的规则描述来扩展 <code>config/kernel-monitor.json</code> 中的 <code>rules</code> 字段以检测新问题：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
  <span style="color:#008000;font-weight:bold">&#34;type&#34;</span>: <span style="color:#b44">&#34;temporary/permanent&#34;</span>,
  <span style="color:#008000;font-weight:bold">&#34;condition&#34;</span>: <span style="color:#b44">&#34;NodeConditionOfPermanentIssue&#34;</span>,
  <span style="color:#008000;font-weight:bold">&#34;reason&#34;</span>: <span style="color:#b44">&#34;CamelCaseShortReason&#34;</span>,
  <span style="color:#008000;font-weight:bold">&#34;message&#34;</span>: <span style="color:#b44">&#34;regexp matching the issue in the kernel log&#34;</span>
}
</code></pre></div><!-- 
### Configure path for the kernel log device {#kernel-log-device-path}

Check your kernel log path location in your operating system (OS) distribution.
The Linux kernel [log device](https://www.kernel.org/doc/Documentation/ABI/testing/dev-kmsg) is usually presented as `/dev/kmsg`. However, the log path location varies by OS distribution.
The `log` field in `config/kernel-monitor.json` represents the log path inside the container.
You can configure the `log` field to match the device path as seen by the Node Problem Detector.
-->
<h3 id="kernel-log-device-path">配置内核日志设备的路径</h3>
<p>检查你的操作系统（OS）发行版本中的内核日志路径位置。
Linux 内核<a href="https://www.kernel.org/doc/documentation/abi/testing/dev-kmsg">日志设备</a>
通常呈现为 <code>/dev/kmsg</code>。
但是，日志路径位置因 OS 发行版本而异。
<code>config/kernel-monitor.json</code> 中的 <code>log</code> 字段表示容器内的日志路径。
你可以配置 <code>log</code> 字段以匹配节点问题检测器所示的设备路径。</p>
<!-- 
### Add support for another log format {#support-other-log-format}

Kernel monitor uses the
[`Translator`](https://github.com/kubernetes/node-problem-detector/blob/v0.1/pkg/kernelmonitor/translator/translator.go) plugin to translate the internal data structure of the kernel log.
You can implement a new translator for a new log format.
-->
<h3 id="support-other-log-format">添加对其它日志格式的支持 </h3>
<p>内核监视器使用
<a href="https://github.com/kubernetes/node-problem-detector/blob/v0.1/pkg/kernelmonitor/translator.go"><code>Translator</code></a>
插件转换内核日志的内部数据结构。
你可以为新的日志格式实现新的转换器。</p>
<!-- discussion -->
<!-- 
## Recommendations and restrictions

It is recommended to run the Node Problem Detector in your cluster to monitor node health.
When running the Node Problem Detector, you can expect extra resource overhead on each node.
Usually this is fine, because:

* The kernel log grows relatively slowly.
* A resource limit is set for the Node Problem Detector.
* Even under high load, the resource usage is acceptable. For more information, see the Node Problem Detector
[benchmark result](https://github.com/kubernetes/node-problem-detector/issues/2#issuecomment-220255629).
-->
<h2 id="建议和限制">建议和限制</h2>
<p>建议在集群中运行节点问题检测器以监控节点运行状况。
运行节点问题检测器时，你可以预期每个节点上的额外资源开销。
通常这是可接受的，因为：</p>
<ul>
<li>内核日志增长相对缓慢。</li>
<li>已经为节点问题检测器设置了资源限制。</li>
<li>即使在高负载下，资源使用也是可接受的。有关更多信息，请参阅节点问题检测器
<a href="https://github.com/kubernetes/node-problem-detector/issues/2.suecomment-220255629">基准结果</a>。</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-9713ac27b6d9e3034033200d968221f2">9 - 获取正在运行容器的 Shell</h1>
    
	<!--
---
reviewers:
- caesarxuchao
- mikedanese
title: Get a Shell to a Running Container
content_type: task
---
-->
<!-- overview -->
<!--
This page shows how to use `kubectl exec` to get a shell to a
running Container.
-->
<p>本文介绍怎样使用 <code>kubectl exec</code> 命令获取正在运行容器的 Shell。</p>
<h2 id="准备开始">准备开始</h2>
<p><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
如果你还没有集群，你可以通过 <a href="/zh/docs/tasks/tools/#minikube">Minikube</a> 构建一
个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. If you do not already have a
cluster, you can create one by using
[minikube](/docs/tasks/tools/#minikube)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 
 要获知版本信息，请输入 <code>kubectl version</code>.
</p>
<!-- steps -->
<!--
## Getting a shell to a Container
-->
<h2 id="获取容器的-shell">获取容器的 Shell</h2>
<!--
In this exercise, you create a Pod that has one Container. The Container
runs the nginx image. Here is the configuration file for the Pod:
-->
<p>在本练习中，你将创建包含一个容器的 Pod。容器运行 nginx 镜像。下面是 Pod 的配置文件：</p>


 













<div class="highlight">
    <div class="copy-code-icon" style="text-align:right">
    <a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/application/shell-demo.yaml" download="application/shell-demo.yaml"><code>application/shell-demo.yaml</code>
    </a>
    <img src="/images/copycode.svg" style="max-height:24px; cursor: pointer" onclick="copyCode('application-shell-demo-yaml')" title="Copy application/shell-demo.yaml to clipboard">
    </img>
    </div>
    <div class="includecode" id="application-shell-demo-yaml">
    <div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Pod<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>shell-demo<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">volumes</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>shared-data<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">emptyDir</span>:<span style="color:#bbb"> </span>{}<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>nginx<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">volumeMounts</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>shared-data<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">mountPath</span>:<span style="color:#bbb"> </span>/usr/share/nginx/html<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">hostNetwork</span>:<span style="color:#bbb"> </span><span style="color:#a2f;font-weight:bold">true</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">dnsPolicy</span>:<span style="color:#bbb"> </span>Default<span style="color:#bbb">
</span></code></pre></div>
    </div>
</div>


<!--
Create the Pod:
-->
<p>创建 Pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create -f https://k8s.io/examples/application/shell-demo.yaml
</code></pre></div><!--
Verify that the Container is running:
-->
<p>检查容器是否运行正常：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod shell-demo
</code></pre></div><!--
Get a shell to the running Container:
-->
<p>获取正在运行容器的 Shell：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> -it shell-demo -- /bin/bash
</code></pre></div><blockquote class="note callout">
  <div><strong>说明：</strong> <!--
The double dash symbol "--" is used to separate the arguments you want to pass to the command from the kubectl arguments.
-->
<p>双破折号 &quot;--&quot; 用于将要传递给命令的参数与 kubectl 的参数分开。</div>
</blockquote>
<!--
In your shell, list the root directory:
-->
<p>在 shell 中，打印根目录：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">root@shell-demo:/# ls /
</code></pre></div><!--
In your shell, experiment with other commands. Here are
some examples:
-->
<p>在 shell 中，实验其他命令。下面是一些示例：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">root@shell-demo:/# ls /
root@shell-demo:/# cat /proc/mounts
root@shell-demo:/# cat /proc/1/maps
root@shell-demo:/# apt-get update
root@shell-demo:/# apt-get install -y tcpdump
root@shell-demo:/# tcpdump
root@shell-demo:/# apt-get install -y lsof
root@shell-demo:/# lsof
root@shell-demo:/# apt-get install -y procps
root@shell-demo:/# ps aux
root@shell-demo:/# ps aux | grep nginx
</code></pre></div><!--
## Writing the root page for nginx
-->
<h2 id="编写-nginx-的-根页面">编写 nginx 的 根页面</h2>
<!--
Look again at the configuration file for your Pod. The Pod
has an `emptyDir` volume, and the Container mounts the volume
at `/usr/share/nginx/html`.
-->
<p>在看一下 Pod 的配置文件。该 Pod 有个 <code>emptyDir</code> 卷，容器将该卷挂载到了 <code>/usr/share/nginx/html</code>。</p>
<!--
In your shell, create an `index.html` file in the `/usr/share/nginx/html`
directory:
-->
<p>在 shell 中，在 <code>/usr/share/nginx/html</code> 目录创建一个 <code>index.html</code> 文件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">root@shell-demo:/# <span style="color:#a2f">echo</span> Hello shell demo &gt; /usr/share/nginx/html/index.html
</code></pre></div><!--
In your shell, send a GET request to the nginx server:
-->
<p>在 shell 中，向 nginx 服务器发送 GET 请求：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">root@shell-demo:/# apt-get update
root@shell-demo:/# apt-get install curl
root@shell-demo:/# curl localhost
</code></pre></div><!--
The output shows the text that you wrote to the `index.html` file:
-->
<p>输出结果显示了你在 <code>index.html</code> 中写入的文本。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">Hello shell demo
</code></pre></div><!--
When you are finished with your shell, enter `exit`.
-->
<p>当用完 shell 后，输入 <code>exit</code> 退出。</p>
<!--
## Running individual commands in a Container
-->
<h2 id="在容器中运行单个命令">在容器中运行单个命令</h2>
<!--
In an ordinary command window, not your shell, list the environment
variables in the running Container:
-->
<p>在普通的命令窗口（而不是 shell）中，打印环境运行容器中的变量：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> shell-demo env
</code></pre></div><!--
Experiment running other commands. Here are some examples:
-->
<p>实验运行其他命令。下面是一些示例：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> shell-demo ps aux
kubectl <span style="color:#a2f">exec</span> shell-demo ls /
kubectl <span style="color:#a2f">exec</span> shell-demo cat /proc/1/mounts
</code></pre></div><!-- discussion -->
<!--
## Opening a shell when a Pod has more than one Container
-->
<h2 id="当-pod-包含多个容器时打开-shell">当 Pod 包含多个容器时打开 shell</h2>
<!--
If a Pod has more than one Container, use `--container` or `-c` to
specify a Container in the `kubectl exec` command. For example,
suppose you have a Pod named my-pod, and the Pod has two containers
named main-app and helper-app. The following command would open a
shell to the main-app Container.
-->
<p>如果 Pod 有多个容器，<code>--container</code> 或者 <code>-c</code> 可以在 <code>kubectl exec</code> 命令中指定容器。
例如，您有个名为 my-pod 的容器，该 Pod 有两个容器分别为 main-app 和 healper-app。
下面的命令将会打开一个 shell 访问 main-app 容器。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> -it my-pod --container main-app -- /bin/bash
</code></pre></div><h2 id="接下来">接下来</h2>
<ul>
<li><a href="/docs/reference/generated/kubectl/kubectl-commands/#exec">kubectl exec</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-06bb252f25983de12f635c806d180d30">10 - 调试 Init 容器</h1>
    
	<!--
reviewers:
- bprashanth
- enisoc
- erictune
- foxish
- janetkuo
- kow3ns
- smarterclayton
title: Debug Init Containers
content_type: task
-->
<!-- overview -->
<!--
This page shows how to investigate problems related to the execution of
Init Containers. The example command lines below refer to the Pod as
`<pod-name>` and the Init Containers as `<init-container-1>` and
`<init-container-2>`.
-->
<p>此页显示如何核查与 Init 容器执行相关的问题。
下面的示例命令行将 Pod 称为 <code>&lt;pod-name&gt;</code>，而 Init 容器称为 <code>&lt;init-container-1&gt;</code> 和
<code>&lt;init-container-2&gt;</code>。</p>
<h2 id="准备开始">准备开始</h2>
<p><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
如果你还没有集群，你可以通过 <a href="/zh/docs/tasks/tools/#minikube">Minikube</a> 构建一
个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. If you do not already have a
cluster, you can create one by using
[minikube](/docs/tasks/tools/#minikube)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 
 要获知版本信息，请输入 <code>kubectl version</code>.
</p>
<!--
* You should be familiar with the basics of
  [Init Containers](/docs/concepts/workloads/pods/init-containers/).
* You should have [Configured an Init Container](/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container/).
-->
<ul>
<li>你应该熟悉 <a href="/zh/docs/concepts/workloads/pods/init-containers/">Init 容器</a>的基础知识。</li>
<li>你应该已经<a href="/zh/docs/tasks/configure-pod-container/configure-pod-initialization/#creating-a-pod-that-has-an-init-container/">配置好一个 Init 容器</a>。</li>
</ul>
<!-- steps -->
<!--
## Checking the status of Init Containers

Display the status of your pod:
-->
<h2 id="检查-init-容器的状态">检查 Init 容器的状态</h2>
<p>显示你的 Pod 的状态：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod &lt;pod-name&gt;
</code></pre></div><!--
For example, a status of `Init:1/2` indicates that one of two Init Containers
has completed successfully:
-->
<p>例如，状态 <code>Init:1/2</code> 表明两个 Init 容器中的一个已经成功完成：</p>
<pre tabindex="0"><code>NAME         READY     STATUS     RESTARTS   AGE
&lt;pod-name&gt;   0/1       Init:1/2   0          7s
</code></pre><!--
See [Understanding Pod status](#understanding-pod-status) for more examples of
status values and their meanings.
-->
<p>更多状态值及其含义请参考<a href="#understanding-pod-status">理解 Pod 的状态</a>。</p>
<!--
## Getting details about Init Containers

View more detailed information about Init Container execution:
-->
<h2 id="getting-details-about-init-containers">获取 Init 容器详情  </h2>
<p>查看 Init 容器运行的更多详情：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pod &lt;pod-name&gt;
</code></pre></div><!--
For example, a Pod with two Init Containers might show the following:
-->
<p>例如，对于包含两个 Init 容器的 Pod 可能显示如下信息：</p>
<pre tabindex="0"><code>Init Containers:
  &lt;init-container-1&gt;:
    Container ID:    ...
    ...
    State:           Terminated
      Reason:        Completed
      Exit Code:     0
      Started:       ...
      Finished:      ...
    Ready:           True
    Restart Count:   0
    ...
  &lt;init-container-2&gt;:
    Container ID:    ...
    ...
    State:           Waiting
      Reason:        CrashLoopBackOff
    Last State:      Terminated
      Reason:        Error
      Exit Code:     1
      Started:       ...
      Finished:      ...
    Ready:           False
    Restart Count:   3
    ...
</code></pre><!--
You can also access the Init Container statuses programmatically by reading the
`status.initContainerStatuses` field on the Pod Spec:
-->
<p>你还可以通过编程方式读取 Pod Spec 上的 <code>status.initContainerStatuses</code> 字段，了解 Init 容器的状态：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod nginx --template <span style="color:#b44">&#39;{{.status.initContainerStatuses}}&#39;</span>
</code></pre></div><!--
This command will return the same information as above in raw JSON.
-->
<p>此命令将返回与原始 JSON 中相同的信息.</p>
<!--
## Accessing logs from Init Containers

Pass the Init Container name along with the Pod name
to access its logs.
-->
<h2 id="accessing-logs-from-init-containers">通过 Init 容器访问日志  </h2>
<p>与 Pod 名称一起传递 Init 容器名称，以访问容器的日志。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl logs &lt;pod-name&gt; -c &lt;init-container-2&gt;
</code></pre></div><!--
Init Containers that run a shell script print
commands as they're executed. For example, you can do this in Bash by running
`set -x` at the beginning of the script.
-->
<p>运行 Shell 脚本的 Init 容器在执行 Shell 脚本时输出命令本身。
例如，你可以在 Bash 中通过在脚本的开头运行 <code>set -x</code> 来实现。</p>
<!-- discussion -->
<!--
## Understanding Pod status

A Pod status beginning with `Init:` summarizes the status of Init Container
execution. The table below describes some example status values that you might
see while debugging Init Containers.
-->
<h2 id="understanding-pod-status">理解 Pod 的状态  </h2>
<p>以 <code>Init:</code> 开头的 Pod 状态汇总了 Init 容器执行的状态。
下表介绍调试 Init 容器时可能看到的一些状态值示例。</p>
<!--
Status | Meaning
------ | -------
`Init:N/M` | The Pod has `M` Init Containers, and `N` have completed so far.
`Init:Error` | An Init Container has failed to execute.
`Init:CrashLoopBackOff` | An Init Container has failed repeatedly.
`Pending` | The Pod has not yet begun executing Init Containers.
`PodInitializing` or `Running` | The Pod has already finished executing Init Containers.
-->
<table>
<thead>
<tr>
<th>状态</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Init:N/M</code></td>
<td>Pod 包含 <code>M</code> 个 Init 容器，其中 <code>N</code> 个已经运行完成。</td>
</tr>
<tr>
<td><code>Init:Error</code></td>
<td>Init 容器已执行失败。</td>
</tr>
<tr>
<td><code>Init:CrashLoopBackOff</code></td>
<td>Init 容器执行总是失败。</td>
</tr>
<tr>
<td><code>Pending</code></td>
<td>Pod 还没有开始执行 Init 容器。</td>
</tr>
<tr>
<td><code>PodInitializing</code> or <code>Running</code></td>
<td>Pod 已经完成执行 Init 容器。</td>
</tr>
</tbody>
</table>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-858517cd46a1b5a1fd2e650edd785cea">11 - 调试 Pods 和 ReplicationControllers</h1>
    
	<!-- 
reviewers:
- bprashanth
title: Debug Pods and ReplicationControllers
content_type: task
-->
<!-- overview -->
<!-- 
This page shows how to debug Pods and ReplicationControllers. 
-->
<p>此页面展示如何调试 Pod 和 ReplicationController。</p>
<h2 id="准备开始">准备开始</h2>
<p><p>你必须拥有一个 Kubernetes 的集群，同时你的 Kubernetes 集群必须带有 kubectl 命令行工具。
如果你还没有集群，你可以通过 <a href="/zh/docs/tasks/tools/#minikube">Minikube</a> 构建一
个你自己的集群，或者你可以使用下面任意一个 Kubernetes 工具构建：</p>
<!--
You need to have a Kubernetes cluster, and the kubectl command-line tool must
be configured to communicate with your cluster. If you do not already have a
cluster, you can create one by using
[minikube](/docs/tasks/tools/#minikube)
or you can use one of these Kubernetes playgrounds:
-->
<ul>
<li><a href="https://www.katacoda.com/courses/kubernetes/playground">Katacoda</a></li>
<li><a href="http://labs.play-with-k8s.com/">玩转 Kubernetes</a></li>
</ul>
 
 要获知版本信息，请输入 <code>kubectl version</code>.
</p>
<!-- 
* You should be familiar with the basics of
  [Pods](/docs/concepts/workloads/pods/) and [Pod Lifecycle](/docs/concepts/workloads/pods/pod-lifecycle/). 
-->
<ul>
<li>你应该先熟悉 <a href="/zh/docs/concepts/workloads/pods/">Pods</a> 和
<a href="/zh/docs/concepts/workloads/pods/pod-lifecycle/">Pod 生命周期</a> 的基础概念。</li>
</ul>
<!-- steps -->
<!-- 
## Debugging Pods 

The first step in debugging a pod is taking a look at it. Check the current
state of the pod and recent events with the following command: 
-->
<h2 id="debugging-pods">调试 Pod </h2>
<p>调试一个 pod 的第一步是观察它。使用下面的命令检查 Pod 的当前状态和最近事件：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pods <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">POD_NAME</span><span style="color:#b68;font-weight:bold">}</span>
</code></pre></div><!-- 
Look at the state of the containers in the pod. Are they all `Running`?  Have
there been recent restarts?

Continue debugging depending on the state of the pods. 
-->
<p>看看 Pod 中的容器的状态。它们都是 <code>Running</code> 吗？最近有重启吗？</p>
<p>根据 Pod 的状态继续调试。</p>
<!-- 
### My pod stays pending 
-->
<!-- 
If a pod is stuck in `Pending` it means that it can not be scheduled onto a
node. Generally this is because there are insufficient resources of one type or
another that prevent scheduling. Look at the output of the `kubectl describe
...` command above. There should be messages from the scheduler about why it
can not schedule your pod. Reasons include: 
-->
<h3 id="我的-pod-停滞在-pending-状态">我的 Pod 停滞在 Pending 状态</h3>
<p>如果 Pod 被卡在 <code>Pending</code> 状态，就意味着它不能调度在某个节点上。一般来说，这是因为某种类型的资源不足而
导致无法调度。 查看上面的命令 <code>kubectl describe ...</code> 的输出。调度器的消息中应该会包含无法调度 Pod 的原因。
原因包括：</p>
<!-- 
#### Insufficient resources 

You may have exhausted the supply of CPU or Memory in your cluster. In this
case you can try several things:

* Add more nodes to the cluster.

* [Terminate unneeded pods](/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination)
  to make room for pending pods.

* Check that the pod is not larger than your nodes. For example, if all
  nodes have a capacity of `cpu:1`, then a pod with a request of `cpu: 1.1`
  will never be scheduled.

    You can check node capacities with the `kubectl get nodes -o <format>`
    command. Here are some example command lines that extract the necessary
    information: 
-->
<h4 id="资源不足">资源不足</h4>
<p>你可能已经耗尽了集群中供应的 CPU 或内存。在这个情况下你可以尝试几件事情：</p>
<ul>
<li>
<p>向集群中添加节点。</p>
</li>
<li>
<p><a href="/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination">终止不需要的 Pod</a>
为 Pending 状态的 Pod 提供空间。</p>
</li>
<li>
<p>检查该 Pod 是否不大于你的节点。例如，如果全部节点具有 <code>cpu:1</code> 容量，那么具有
请求为 <code>cpu: 1.1</code> 的 Pod 永远不会被调度。</p>
<p>你可以使用 <code>kubectl get nodes -o &lt;format&gt;</code> 命令来检查节点容量。
下面是一些能够提取必要信息的命令示例：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get nodes -o yaml | egrep <span style="color:#b44">&#39;\sname:|cpu:|memory:&#39;</span>
kubectl get nodes -o json | jq <span style="color:#b44">&#39;.items[] | {name: .metadata.name, cap: .status.capacity}&#39;</span>
</code></pre></div></li>
</ul>
<!-- 
  The [resource quota](/docs/concepts/policy/resource-quotas/)
  feature can be configured to limit the total amount of
  resources that can be consumed. If used in conjunction with namespaces, it can
  prevent one team from hogging all the resources. 
-->
<p>可以考虑配置<a href="/zh/docs/concepts/policy/resource-quotas/">资源配额</a> 来限制可耗用的资源总量。
如果与命名空间一起使用，它可以防止一个团队吞噬所有的资源。</p>
<!-- 
#### Using hostPort 

When you bind a pod to a `hostPort` there are a limited number of places that
the pod can be scheduled. In most cases, `hostPort` is unnecessary; try using a
service object to expose your pod. If you do require `hostPort` then you can
only schedule as many pods as there are nodes in your container cluster. 
-->
<h4 id="使用hostport">使用hostPort</h4>
<p>当你将一个 Pod 绑定到某 <code>hostPort</code> 时，这个 Pod 能被调度的位置数量有限。
在大多数情况下，<code>hostPort</code> 是不必要的; 尝试使用服务对象来暴露你的 Pod。
如果你需要 <code>hostPort</code>，那么你可以调度的 Pod 数量不能超过集群的节点个数。</p>
<!-- 
### My pod stays waiting 

If a pod is stuck in the `Waiting` state, then it has been scheduled to a
worker node, but it can't run on that machine. Again, the information from
`kubectl describe ...` should be informative. The most common cause of
`Waiting` pods is a failure to pull the image. There are three things to check: 

* Make sure that you have the name of the image correct.
* Have you pushed the image to the repository?
* Run a manual `docker pull <image>` on your machine to see if the image can be
  pulled.
-->
<h3 id="我的-pod-一直在-waiting">我的 Pod 一直在 Waiting</h3>
<p>如果 Pod 一直停滞在 <code>Waiting</code> 状态，那么它已被调度在某个工作节点，但它不能在该机器上运行。
再次，来自 <code>kubectl describe ...</code> 的内容应该是可以是很有用的。
最常见的原因 <code>Waiting</code> 的 Pod 是无法拉取镜像。有三件事要检查：</p>
<ul>
<li>确保你的镜像的名称正确。</li>
<li>你是否将镜像推送到存储库？</li>
<li>在你的机器上手动运行 <code>docker pull &lt;image&gt;</code>，看看是否可以拉取镜像。</li>
</ul>
<!-- 
### My pod is crashing or otherwise unhealthy 

Once your pod has been scheduled, the methods described in [Debug Running Pods](
/docs/tasks/debug-application-cluster/debug-running-pod/) are available for debugging.
-->
<h3 id="我的-pod-一直-crashing-或者其他不健康状态">我的 Pod 一直 Crashing 或者其他不健康状态</h3>
<p>一旦 Pod 已经被调度，就可以依据
<a href="/zh/docs/tasks/debug-application-cluster/debug-running-pod/">调试运行中的 Pod</a>
展开进一步的调试工作。</p>
<!-- 
## Debugging ReplicationControllers 

ReplicationControllers are fairly straightforward. They can either create pods
or they can't. If they can't create pods, then please refer to the
[instructions above](#debugging-pods) to debug your pods. 
-->
<h2 id="调试-replication-controller">调试 Replication Controller</h2>
<p>Replication Controller 相当简单。它们或者能或者不能创建 Pod。如果它们无法创建 Pod，
请参考<a href="#debugging_pods">上面的说明</a> 来调试你的 Pod。</p>
<!-- 
You can also use `kubectl describe rc ${CONTROLLER_NAME}` to inspect events
related to the replication controller. 
-->
<p>你也可以使用 <code>kubectl describe rc ${CONTROLLER_NAME}</code> 来检查和副本控制器有关的事件。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-f79645981e310858111bd5673614cab6">12 - 调试 Service</h1>
    
	<!--
reviewers:
- thockin
- bowei
content_type: concept
title: Debug Services
-->
<!-- overview -->
<!--
An issue that comes up rather frequently for new installations of Kubernetes is
that a Service is not working properly.  You've run your Pods through a
Deployment (or other workload controller) and created a Service, but you
get no response when you try to access it.  This document will hopefully help
you to figure out what's going wrong.
-->
<p>对于新安装的 Kubernetes，经常出现的问题是 Service 无法正常运行。 你已经通过
Deployment（或其他工作负载控制器）运行了 Pod，并创建 Service ，但是
当你尝试访问它时，没有任何响应。此文档有望对你有所帮助并找出问题所在。</p>
<!-- body -->
<!--
## Running commands in a Pod

For many steps here you will want to see what a Pod running in the cluster
sees.  The simplest way to do this is to run an interactive busybox Pod:
-->
<h2 id="在-pod-中运行命令">在 Pod 中运行命令</h2>
<p>对于这里的许多步骤，你可能希望知道运行在集群中的 Pod 看起来是什么样的。
最简单的方法是运行一个交互式的 busybox Pod：</p>
<pre tabindex="0"><code class="language-none" data-lang="none">kubectl run -it --rm --restart=Never busybox --image=gcr.io/google-containers/busybox sh
</code></pre><!--
<blockquote class="note callout">
  <div><strong>说明：</strong> If you don't see a command prompt, try pressing enter.</div>
</blockquote>
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> 如果没有看到命令提示符，请按回车。</div>
</blockquote>
<!--
If you already have a running Pod that you prefer to use, you can run a
command in it using:
-->
<p>如果你已经有了你想使用的正在运行的 Pod，则可以运行以下命令去进入：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> &lt;POD-NAME&gt; -c &lt;CONTAINER-NAME&gt; -- &lt;COMMAND&gt;
</code></pre></div><!--
## Setup

For the purposes of this walk-through, let's run some Pods.  Since you're
probably debugging your own Service you can substitute your own details, or you
can follow along and get a second data point.
-->
<h2 id="setup">设置 </h2>
<p>为了完成本次实践的任务，我们先运行几个 Pod。
由于你可能正在调试自己的 Service，所以，你可以使用自己的信息进行替换，
或者你也可以跟着教程并开始下面的步骤来获得第二个数据点。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl  create deployment hostnames --image<span style="color:#666">=</span>k8s.gcr.io/serve_hostname 
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">deployment.apps/hostnames created
</code></pre><!--
`kubectl` commands will print the type and name of the resource created or mutated, which can then be used in subsequent commands.

Let's scale the deployment to 3 replicas.
-->
<p><code>kubectl</code> 命令将打印创建或变更的资源的类型和名称，它们可以在后续命令中使用。
让我们将这个 deployment 的副本数扩至 3。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl scale deployment hostnames --replicas<span style="color:#666">=</span><span style="color:#666">3</span>
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">deployment.apps/hostnames scaled
</code></pre><!--
Note that this is the same as if you had the Deployment with the following YAML:
-->
<p>请注意这与你使用以下 YAML 方式启动 Deployment 类似：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>apps/v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Deployment<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">matchLabels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">replicas</span>:<span style="color:#bbb"> </span><span style="color:#666">3</span><span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">template</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">labels</span>:<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span><span style="color:#008000;font-weight:bold">containers</span>:<span style="color:#bbb">
</span><span style="color:#bbb">      </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#008000;font-weight:bold">image</span>:<span style="color:#bbb"> </span>k8s.gcr.io/serve_hostname<span style="color:#bbb">
</span></code></pre></div><!--
The label "app" is automatically set by `kubectl create deployment` to the name of the Deployment.

You can confirm your Pods are running:
-->
<p>&quot;app&quot; 标签是 <code>kubectl create deployment</code> 根据 Deployment 名称自动设置的。</p>
<p>确认你的 Pods 是运行状态:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">NAME                        READY     STATUS    RESTARTS   AGE
hostnames-632524106-bbpiw   1/1       Running   0          2m
hostnames-632524106-ly40y   1/1       Running   0          2m
hostnames-632524106-tlaok   1/1       Running   0          2m
</code></pre><!--
You can also confirm that your Pods are serving.  You can get the list of
Pod IP addresses and test them directly.
-->
<p>你还可以确认你的 Pod 是否正在提供服务。你可以获取 Pod IP 地址列表并直接对其进行测试。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>hostnames <span style="color:#b62;font-weight:bold">\
</span><span style="color:#b62;font-weight:bold"></span>    -o go-template<span style="color:#666">=</span><span style="color:#b44">&#39;{{range .items}}{{.status.podIP}}{{&#34;\n&#34;}}{{end}}&#39;</span>
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">10.244.0.5
10.244.0.6
10.244.0.7
</code></pre><!--
The example container used for this walk-through serves its own hostname
via HTTP on port 9376, but if you are debugging your own app, you'll want to
use whatever port number your Pods are listening on.

From within a pod:
-->
<p>用于本教程的示例容器通过 HTTP 在端口 9376 上提供其自己的主机名，
但是如果要调试自己的应用程序，则需要使用你的 Pod 正在侦听的端口号。</p>
<p>在 Pod 内运行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#a2f;font-weight:bold">for</span> ep in 10.244.0.5:9376 10.244.0.6:9376 10.244.0.7:9376; <span style="color:#a2f;font-weight:bold">do</span>
    wget -qO- <span style="color:#b8860b">$ep</span>
<span style="color:#a2f;font-weight:bold">done</span>
</code></pre></div><!--
This should produce something like:
-->
<p>输出类似这样：</p>
<pre tabindex="0"><code>hostnames-632524106-bbpiw
hostnames-632524106-ly40y
hostnames-632524106-tlaok
</code></pre><!--
If you are not getting the responses you expect at this point, your Pods
might not be healthy or might not be listening on the port you think they are.
You might find `kubectl logs` to be useful for seeing what is happening, or
perhaps you need to `kubectl exec` directly into your Pods and debug from
there.

Assuming everything has gone to plan so far, you can start to investigate why
your Service doesn't work.
-->
<p>如果此时你没有收到期望的响应，则你的 Pod 状态可能不健康，或者可能没有在你认为正确的端口上进行监听。
你可能会发现 <code>kubectl logs</code> 命令对于查看正在发生的事情很有用，
或者你可能需要通过<code>kubectl exec</code> 直接进入 Pod 中并从那里进行调试。</p>
<p>假设到目前为止一切都已按计划进行，那么你可以开始调查为何你的 Service 无法正常工作。</p>
<!--
## Does the Service exist?

The astute reader will have noticed that you did not actually create a Service
yet - that is intentional.  This is a step that sometimes gets forgotten, and
is the first thing to check.

What would happen if you tried to access a non-existent Service?  If
you have another Pod that consumes this Service by name you would get
something like:
-->
<h2 id="service-是否存在">Service 是否存在？</h2>
<p>细心的读者会注意到我们实际上尚未创建 Service -这是有意而为之。 这一步有时会被遗忘，这是首先要检查的步骤。</p>
<p>那么，如果我尝试访问不存在的 Service 会怎样？ 假设你有另一个 Pod 通过名称匹配到 Service ，你将得到类似结果：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">wget -O- hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Resolving hostnames (hostnames)... failed: Name or service not known.
wget: unable to resolve host address 'hostnames'
</code></pre><!--
The first thing to check is whether that Service actually exists:
-->
<p>首先要检查的是该 Service 是否真实存在：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get svc hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">No resources found.
Error from server (NotFound): services &quot;hostnames&quot; not found
</code></pre><!--
Let's create the Service.  As before, this is for the walk-through - you can
use your own Service's details here.
-->
<p>让我们创建 Service。 和以前一样，在这次实践中 - 你可以在此处使用自己的 Service 的内容。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl expose deployment hostnames --port<span style="color:#666">=</span><span style="color:#666">80</span> --target-port<span style="color:#666">=</span><span style="color:#666">9376</span>
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">service/hostnames exposed
</code></pre><!--
And read it back:
-->
<p>重新运行查询命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get svc hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">NAME        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
hostnames   ClusterIP   10.0.1.175   &lt;none&gt;        80/TCP    5s
</code></pre><!--
Now you know that the Service exists.

As before, this is the same as if you had started the `Service` with YAML:
-->
<p>现在你知道了 Service 确实存在。</p>
<p>同前，此步骤效果与通过 YAML 方式启动 'Service' 一样：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#008000;font-weight:bold">apiVersion</span>:<span style="color:#bbb"> </span>v1<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">kind</span>:<span style="color:#bbb"> </span>Service<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">metadata</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#008000;font-weight:bold">spec</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">selector</span>:<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">app</span>:<span style="color:#bbb"> </span>hostnames<span style="color:#bbb">
</span><span style="color:#bbb">  </span><span style="color:#008000;font-weight:bold">ports</span>:<span style="color:#bbb">
</span><span style="color:#bbb">  </span>- <span style="color:#008000;font-weight:bold">name</span>:<span style="color:#bbb"> </span>default<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">protocol</span>:<span style="color:#bbb"> </span>TCP<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">port</span>:<span style="color:#bbb"> </span><span style="color:#666">80</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#008000;font-weight:bold">targetPort</span>:<span style="color:#bbb"> </span><span style="color:#666">9376</span><span style="color:#bbb">
</span></code></pre></div><!--
In order to highlight the full range of configuration, the Service you created
here uses a different port number than the Pods.  For many real-world
Services, these values might be the same.
-->
<p>为了突出配置范围的完整性，你在此处创建的 Service 使用的端口号与 Pods 不同。
对于许多真实的 Service，这些值可以是相同的。</p>
<!--
## Does the Service work by DNS name?

One of the most common ways that clients consume a Service is through a DNS
name.

From a Pod in the same Namespace:
-->
<h2 id="service-是否可通过-dns-名字访问">Service 是否可通过 DNS 名字访问？</h2>
<p>通常客户端通过 DNS 名称来匹配到 Service。</p>
<p>从相同命名空间下的 Pod 中运行以下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">nslookup hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      hostnames
Address 1: 10.0.1.175 hostnames.default.svc.cluster.local
</code></pre><!--
If this fails, perhaps your Pod and Service are in different
Namespaces, try a namespace-qualified name (again, from within a Pod):
-->
<p>如果失败，那么你的 Pod 和 Service 可能位于不同的命名空间中，
请尝试使用限定命名空间的名称（同样在 Pod 内运行）：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">nslookup hostnames.default
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      hostnames.default
Address 1: 10.0.1.175 hostnames.default.svc.cluster.local
</code></pre><!--
If this works, you'll need to adjust your app to use a cross-namespace name, or
run your app and Service in the same Namespace.  If this still fails, try a
fully-qualified name:
-->
<p>如果成功，那么需要调整你的应用，使用跨命名空间的名称去访问它，
或者在相同的命名空间中运行应用和 Service。如果仍然失败，请尝试一个完全限定的名称：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">nslookup hostnames.default.svc.cluster.local
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      hostnames.default.svc.cluster.local
Address 1: 10.0.1.175 hostnames.default.svc.cluster.local
</code></pre><!--
Note the suffix here: "default.svc.cluster.local".  The "default" is the
Namespace you're operating in.  The "svc" denotes that this is a Service.
The "cluster.local" is your cluster domain, which COULD be different in your
own cluster.

You can also try this from a `Node` in the cluster:

<blockquote class="note callout">
  <div><strong>说明：</strong> 10.0.0.10 is the cluster's DNS Service IP, yours might be different.</div>
</blockquote>
-->
<p>注意这里的后缀：&quot;default.svc.cluster.local&quot;。&quot;default&quot; 是我们正在操作的命名空间。
&quot;svc&quot; 表示这是一个 Service。&quot;cluster.local&quot; 是你的集群域，在你自己的集群中可能会有所不同。</p>
<p>你也可以在集群中的节点上尝试此操作：</p>
<blockquote class="note callout">
  <div><strong>说明：</strong> 10.0.0.10 是集群的 DNS 服务 IP，你的可能有所不同。</div>
</blockquote>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">nslookup hostnames.default.svc.cluster.local 10.0.0.10
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Server:         10.0.0.10
Address:        10.0.0.10#53

Name:   hostnames.default.svc.cluster.local
Address: 10.0.1.175
</code></pre><!--
If you are able to do a fully-qualified name lookup but not a relative one, you
need to check that your `/etc/resolv.conf` file in your Pod is correct.  From
within a Pod:
-->
<p>如果你能够使用完全限定的名称查找，但不能使用相对名称，则需要检查你 Pod 中的
<code>/etc/resolv.conf</code> 文件是否正确。在 Pod 中运行以下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">cat /etc/resolv.conf
</code></pre></div><!--
You should see something like:
-->
<p>你应该可以看到类似这样的输出：</p>
<pre tabindex="0"><code>nameserver 10.0.0.10
search default.svc.cluster.local svc.cluster.local cluster.local example.com
options ndots:5
</code></pre><!--
The `nameserver` line must indicate your cluster's DNS `Service`.  This is
passed into `kubelet` with the `--cluster-dns` flag.

The `search` line must include an appropriate suffix for you to find the
Service name.  In this case it is looking for Services in the local
Namespace ("default.svc.cluster.local"), Services in all Namespaces
("svc.cluster.local"), and lastly for names in the cluster ("cluster.local").
Depending on your own install you might have additional records after that (up
to 6 total).  The cluster suffix is passed into `kubelet` with the
`--cluster-domain` flag.  Throughout this document, the cluster suffix is
assumed to be "cluster.local".  Your own clusters might be configured
differently, in which case you should change that in all of the previous
commands.

The `options` line must set `ndots` high enough that your DNS client library
considers search paths at all.  Kubernetes sets this to 5 by default, which is
high enough to cover all of the DNS names it generates.
-->
<p><code>nameserver</code> 行必须指示你的集群的 DNS Service，
它是通过 <code>--cluster-dns</code> 标志传递到 kubelet 的。</p>
<p><code>search</code> 行必须包含一个适当的后缀，以便查找 Service 名称。
在本例中，它查找本地命名空间（<code>default.svc.cluster.local</code>）中的服务和
所有命名空间（<code>svc.cluster.local</code>）中的服务，最后在集群（<code>cluster.local</code>）中查找
服务的名称。根据你自己的安装情况，可能会有额外的记录（最多 6 条）。
集群后缀是通过 <code>--cluster-domain</code> 标志传递给 <code>kubelet</code> 的。
本文中，我们假定后缀是 “cluster.local”。
你的集群配置可能不同，这种情况下，你应该在上面的所有命令中更改它。</p>
<p><code>options</code> 行必须设置足够高的 <code>ndots</code>，以便 DNS 客户端库考虑搜索路径。
在默认情况下，Kubernetes 将这个值设置为 5，这个值足够高，足以覆盖它生成的所有 DNS 名称。</p>
<!--
### Does any Service work by DNS name? {#does-any-service-exist-in-dns}

If the above still fails, DNS lookups are not working for your Service.  You
can take a step back and see what else is not working.  The Kubernetes master
Service should always work.  From within a Pod:
-->
<h3 id="does-any-service-exist-in-dns">是否存在 Service 能通过 DNS 名称访问？</h3>
<p>如果上面的方式仍然失败，DNS 查找不到你需要的 Service ，你可以后退一步，
看看还有什么其它东西没有正常工作。
Kubernetes 主 Service 应该一直是工作的。在 Pod 中运行如下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">nslookup kubernetes.default
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Server:    10.0.0.10
Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local
</code></pre><!--
If this fails, please see the [kube-proxy](#is-the-kube-proxy-working) section
of this document, or even go back to the top of this document and start over,
but instead of debugging your own Service, debug the DNS Service.
-->
<p>如果失败，你可能需要转到本文的 <a href="#is-the-kube-proxy-working">kube-proxy</a> 节，
或者甚至回到文档的顶部重新开始，但不是调试你自己的 Service ，而是调试 DNS Service。</p>
<!--
## Does the Service work by IP?

Assuming you have confirmed that DNS works, the next thing to test is whether your
Service works by its IP address.  From a Pod in your cluster, access the
Service's IP (from `kubectl get` above).
-->
<h3 id="service-能够通过-ip-访问么">Service 能够通过 IP 访问么？</h3>
<p>假设你已经确认 DNS 工作正常，那么接下来要测试的是你的 Service 能否通过它的 IP 正常访问。
从集群中的一个 Pod，尝试访问 Service 的 IP（从上面的 <code>kubectl get</code> 命令获取）。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#a2f;font-weight:bold">for</span> i in <span style="color:#a2f;font-weight:bold">$(</span>seq <span style="color:#666">1</span> 3<span style="color:#a2f;font-weight:bold">)</span>; <span style="color:#a2f;font-weight:bold">do</span> 
    wget -qO- 10.0.1.175:80
<span style="color:#a2f;font-weight:bold">done</span>
</code></pre></div><!--
This should produce something like:
-->
<p>输出应该类似这样：</p>
<pre tabindex="0"><code>hostnames-632524106-bbpiw
hostnames-632524106-ly40y
hostnames-632524106-tlaok
</code></pre><!--
If your Service is working, you should get correct responses.  If not, there
are a number of things that could be going wrong.  Read on.
-->
<p>如果 Service 状态是正常的，你应该得到正确的响应。如果没有，有很多可能出错的地方，请继续阅读。</p>
<!--
## Is the Service defined correctly?

It might sound silly, but you should really double and triple check that your
`Service` is correct and matches your `Pod`'s port.  Read back your `Service`
and verify it:
-->
<h2 id="service-的配置是否正确">Service 的配置是否正确？</h2>
<p>这听起来可能很愚蠢，但你应该两次甚至三次检查你的 Service 配置是否正确，并且与你的 Pod 匹配。
查看你的 Service 配置并验证它：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get service hostnames -o json
</code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">{
    <span style="color:#008000;font-weight:bold">&#34;kind&#34;</span>: <span style="color:#b44">&#34;Service&#34;</span>,
    <span style="color:#008000;font-weight:bold">&#34;apiVersion&#34;</span>: <span style="color:#b44">&#34;v1&#34;</span>,
    <span style="color:#008000;font-weight:bold">&#34;metadata&#34;</span>: {
        <span style="color:#008000;font-weight:bold">&#34;name&#34;</span>: <span style="color:#b44">&#34;hostnames&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;namespace&#34;</span>: <span style="color:#b44">&#34;default&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;uid&#34;</span>: <span style="color:#b44">&#34;428c8b6c-24bc-11e5-936d-42010af0a9bc&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;resourceVersion&#34;</span>: <span style="color:#b44">&#34;347189&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;creationTimestamp&#34;</span>: <span style="color:#b44">&#34;2015-07-07T15:24:29Z&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;labels&#34;</span>: {
            <span style="color:#008000;font-weight:bold">&#34;app&#34;</span>: <span style="color:#b44">&#34;hostnames&#34;</span>
        }
    },
    <span style="color:#008000;font-weight:bold">&#34;spec&#34;</span>: {
        <span style="color:#008000;font-weight:bold">&#34;ports&#34;</span>: [
            {
                <span style="color:#008000;font-weight:bold">&#34;name&#34;</span>: <span style="color:#b44">&#34;default&#34;</span>,
                <span style="color:#008000;font-weight:bold">&#34;protocol&#34;</span>: <span style="color:#b44">&#34;TCP&#34;</span>,
                <span style="color:#008000;font-weight:bold">&#34;port&#34;</span>: <span style="color:#666">80</span>,
                <span style="color:#008000;font-weight:bold">&#34;targetPort&#34;</span>: <span style="color:#666">9376</span>,
                <span style="color:#008000;font-weight:bold">&#34;nodePort&#34;</span>: <span style="color:#666">0</span>
            }
        ],
        <span style="color:#008000;font-weight:bold">&#34;selector&#34;</span>: {
            <span style="color:#008000;font-weight:bold">&#34;app&#34;</span>: <span style="color:#b44">&#34;hostnames&#34;</span>
        },
        <span style="color:#008000;font-weight:bold">&#34;clusterIP&#34;</span>: <span style="color:#b44">&#34;10.0.1.175&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;type&#34;</span>: <span style="color:#b44">&#34;ClusterIP&#34;</span>,
        <span style="color:#008000;font-weight:bold">&#34;sessionAffinity&#34;</span>: <span style="color:#b44">&#34;None&#34;</span>
    },
    <span style="color:#008000;font-weight:bold">&#34;status&#34;</span>: {
        <span style="color:#008000;font-weight:bold">&#34;loadBalancer&#34;</span>: {}
    }
}
</code></pre></div><!--
* Is the Service port you are trying to access listed in `spec.ports[]`?
* Is the `targetPort` correct for your Pods (some Pods use a different port than the Service)?
* If you meant to use a numeric port, is it a number (9376) or a string "9376"?
* If you meant to use a named port, do your Pods expose a port with the same name?
* Is the port's `protocol` correct for your Pods?
-->
<ul>
<li>你想要访问的 Service 端口是否在 <code>spec.ports[]</code> 中列出？</li>
<li><code>targetPort</code> 对你的 Pod 来说正确吗（许多 Pod 使用与 Service 不同的端口）？</li>
<li>如果你想使用数值型端口，那么它的类型是一个数值（9376）还是字符串 “9376”？</li>
<li>如果你想使用名称型端口，那么你的 Pod 是否暴露了一个同名端口？</li>
<li>端口的 <code>protocol</code> 和 Pod 的是否对应？</li>
</ul>
<!--
## Does the Service have any Endpoints?

If you got this far, you have confirmed that your Service is correctly
defined and is resolved by DNS.  Now let's check that the Pods you ran are
actually being selected by the Service.

Earlier you saw that the Pods were running.  You can re-check that:
-->
<h2 id="service-有-endpoints-吗">Service 有 Endpoints 吗？</h2>
<p>如果你已经走到了这一步，你已经确认你的 Service 被正确定义，并能通过 DNS 解析。
现在，让我们检查一下，你运行的 Pod 确实是被 Service 选中的。</p>
<p>早些时候，我们已经看到 Pod 是运行状态。我们可以再检查一下：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">NAME                        READY     STATUS    RESTARTS   AGE
hostnames-632524106-bbpiw   1/1       Running   0          1h
hostnames-632524106-ly40y   1/1       Running   0          1h
hostnames-632524106-tlaok   1/1       Running   0          1h
</code></pre><!--
The `-l app=hostnames` argument is a label selector configured on the Service.

The "AGE" column says that these Pods are about an hour old, which implies that
they are running fine and not crashing.

The "RESTARTS" column says that these pods are not crashing frequently or being
restarted.  Frequent restarts could lead to intermittent connectivity issues.
If the restart count is high, read more about how to [debug pods](/docs/tasks/debug-application-cluster/debug-pod-replication-controller/#debugging-pods).

Inside the Kubernetes system is a control loop which evaluates the selector of
every Service and saves the results into a corresponding Endpoints object.
-->
<p><code>-l app=hostnames</code> 参数是在 Service 上配置的标签选择器。</p>
<p>&quot;AGE&quot; 列表明这些 Pod 已经启动一个小时了，这意味着它们运行良好，而未崩溃。</p>
<p>&quot;RESTARTS&quot; 列表明 Pod 没有经常崩溃或重启。经常性崩溃可能导致间歇性连接问题。
如果重启次数过大，通过<a href="/zh/docs/tasks/debug-application-cluster/debug-application/#debugging-pods">调试 pod</a>
了解相关技术。</p>
<p>在 Kubernetes 系统中有一个控制回路，它评估每个 Service 的选择算符，并将结果保存到 Endpoints 对象中。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get endpoints hostnames
</code></pre></div><pre tabindex="0"><code>NAME        ENDPOINTS
hostnames   10.244.0.5:9376,10.244.0.6:9376,10.244.0.7:9376
</code></pre><!--
This confirms that the endpoints controller has found the correct Pods for
your Service.  If the `ENDPOINTS` column is `<none>`, you should check that
the `spec.selector` field of your Service actually selects for
`metadata.labels` values on your Pods.  A common mistake is to have a typo or
other error, such as the Service selecting for `app=hostnames`, but the
Deployment specifying `run=hostnames`, as in versions previous to 1.18, where
the `kubectl run` command could have been also used to create a Deployment.
-->
<p>这证实 Endpoints 控制器已经为你的 Service 找到了正确的 Pods。
如果 <code>ENDPOINTS</code> 列的值为 <code>&lt;none&gt;</code>，则应检查 Service 的 <code>spec.selector</code> 字段，
以及你实际想选择的 Pod 的 <code>metadata.labels</code> 的值。
常见的错误是输入错误或其他错误，例如 Service 想选择 <code>app=hostnames</code>，但是
Deployment 指定的是 <code>run=hostnames</code>。在 1.18之前的版本中 <code>kubectl run</code>
也可以被用来创建 Deployment。</p>
<!--
## Are the Pods working?

At this point, you know that your Service exists and has selected your Pods.
At the beginning of this walk-through, you verified the Pods themselves.
Let's check again that the Pods are actually working - you can bypass the
Service mechanism and go straight to the Pods, as listed by the Endpoints
above.

<blockquote class="note callout">
  <div><strong>说明：</strong> These commands use the Pod port (9376), rather than the Service port (80).</div>
</blockquote>

From within a Pod:
-->
<h2 id="pod-正常工作吗">Pod 正常工作吗？</h2>
<p>至此，你知道你的 Service 已存在，并且已匹配到你的Pod。在本实验的开始，你已经检查了 Pod 本身。
让我们再次检查 Pod 是否确实在工作 - 你可以绕过 Service 机制并直接转到 Pod，如上面的 Endpoint 所示。</p>
<blockquote class="note callout">
  <div><strong>说明：</strong> 这些命令使用的是 Pod 端口（9376），而不是 Service 端口（80）。</div>
</blockquote>
<p>在 Pod 中运行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#a2f;font-weight:bold">for</span> ep in 10.244.0.5:9376 10.244.0.6:9376 10.244.0.7:9376; <span style="color:#a2f;font-weight:bold">do</span>
    wget -qO- <span style="color:#b8860b">$ep</span>
<span style="color:#a2f;font-weight:bold">done</span>
</code></pre></div><!--
This should produce something like:
-->
<p>输出应该类似这样：</p>
<pre tabindex="0"><code>hostnames-632524106-bbpiw
hostnames-632524106-ly40y
hostnames-632524106-tlaok
</code></pre><!--
You expect each Pod in the Endpoints list to return its own hostname.  If
this is not what happens (or whatever the correct behavior is for your own
Pods), you should investigate what's happening there.
-->
<p>你希望 Endpoint 列表中的每个 Pod 都返回自己的主机名。
如果情况并非如此（或你自己的 Pod 的正确行为是什么），你应调查发生了什么事情。</p>
<!--
## Is the kube-proxy working?

If you get here, your Service is running, has Endpoints, and your Pods
are actually serving.  At this point, the whole Service proxy mechanism is
suspect.  Let's confirm it, piece by piece.

The default implementation of Services, and the one used on most clusters, is
kube-proxy.  This is a program that runs on every node and configures one of a
small set of mechanisms for providing the Service abstraction.  If your
cluster does not use kube-proxy, the following sections will not apply, and you
will have to investigate whatever implementation of Services you are using.
-->
<h2 id="kube-proxy-正常工作吗">kube-proxy 正常工作吗？</h2>
<p>如果你到达这里，则说明你的 Service 正在运行，拥有 Endpoints，Pod 真正在提供服务。
此时，整个 Service 代理机制是可疑的。让我们一步一步地确认它没问题。</p>
<p>Service 的默认实现（在大多数集群上应用的）是 kube-proxy。
这是一个在每个节点上运行的程序，负责配置用于提供 Service 抽象的机制之一。
如果你的集群不使用 kube-proxy，则以下各节将不适用，你将必须检查你正在使用的 Service 的实现方式。</p>
<!--
## Is the kube-proxy working?

Confirm that `kube-proxy` is running on your Nodes.  Running directly on a
Node, you should get something like the below:
-->
<h3 id="kube-proxy-正常运行吗">kube-proxy 正常运行吗？</h3>
<p>确认 <code>kube-proxy</code> 正在节点上运行。 在节点上直接运行，你将会得到类似以下的输出：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">ps auxw | grep kube-proxy
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">root  4194  0.4  0.1 101864 17696 ?    Sl Jul04  25:43 /usr/local/bin/kube-proxy --master=https://kubernetes-master --kubeconfig=/var/lib/kube-proxy/kubeconfig --v=2
</code></pre><!--
Next, confirm that it is not failing something obvious, like contacting the
master.  To do this, you'll have to look at the logs.  Accessing the logs
depends on your Node OS.  On some OSes it is a file, such as
/var/log/kube-proxy.log, while other OSes use `journalctl` to access logs.  You
should see something like:
-->
<p>下一步，确认它并没有出现明显的失败，比如连接主节点失败。要做到这一点，你必须查看日志。
访问日志的方式取决于你节点的操作系统。
在某些操作系统上日志是一个文件，如 /var/log/messages kube-proxy.log，
而其他操作系统使用 <code>journalctl</code> 访问日志。你应该看到输出类似于：</p>
<pre tabindex="0"><code class="language-none" data-lang="none">I1027 22:14:53.995134    5063 server.go:200] Running in resource-only container &quot;/kube-proxy&quot;
I1027 22:14:53.998163    5063 server.go:247] Using iptables Proxier.
I1027 22:14:53.999055    5063 server.go:255] Tearing down userspace rules. Errors here are acceptable.
I1027 22:14:54.038140    5063 proxier.go:352] Setting endpoints for &quot;kube-system/kube-dns:dns-tcp&quot; to [10.244.1.3:53]
I1027 22:14:54.038164    5063 proxier.go:352] Setting endpoints for &quot;kube-system/kube-dns:dns&quot; to [10.244.1.3:53]
I1027 22:14:54.038209    5063 proxier.go:352] Setting endpoints for &quot;default/kubernetes:https&quot; to [10.240.0.2:443]
I1027 22:14:54.038238    5063 proxier.go:429] Not syncing iptables until Services and Endpoints have been received from master
I1027 22:14:54.040048    5063 proxier.go:294] Adding new service &quot;default/kubernetes:https&quot; at 10.0.0.1:443/TCP
I1027 22:14:54.040154    5063 proxier.go:294] Adding new service &quot;kube-system/kube-dns:dns&quot; at 10.0.0.10:53/UDP
I1027 22:14:54.040223    5063 proxier.go:294] Adding new service &quot;kube-system/kube-dns:dns-tcp&quot; at 10.0.0.10:53/TCP
</code></pre><!--
If you see error messages about not being able to contact the master, you
should double-check your Node configuration and installation steps.

One of the possible reasons that `kube-proxy` cannot run correctly is that the
required `conntrack` binary cannot be found. This may happen on some Linux
systems, depending on how you are installing the cluster, for example, you are
installing Kubernetes from scratch. If this is the case, you need to manually
install the `conntrack` package (e.g. `sudo apt install conntrack` on Ubuntu)
and then retry.
-->
<p>如果你看到有关无法连接主节点的错误消息，则应再次检查节点配置和安装步骤。</p>
<p><code>kube-proxy</code> 无法正确运行的可能原因之一是找不到所需的 <code>conntrack</code> 二进制文件。
在一些 Linux 系统上，这也是可能发生的，这取决于你如何安装集群，
例如，你是手动开始一步步安装 Kubernetes。如果是这样的话，你需要手动安装
<code>conntrack</code> 包（例如，在 Ubuntu 上使用 <code>sudo apt install conntrack</code>），然后重试。</p>
<!--
Kube-proxy can run in one of a few modes.  In the log listed above, the
line `Using iptables Proxier` indicates that kube-proxy is running in
"iptables" mode.  The most common other mode is "ipvs".  The older "userspace"
mode has largely been replaced by these.

-->
<p>Kube-proxy 可以以若干模式之一运行。在上述日志中，<code>Using iptables Proxier</code>
行表示 kube-proxy 在 &quot;iptables&quot; 模式下运行。
最常见的另一种模式是 &quot;ipvs&quot;。先前的 &quot;userspace&quot; 模式已经被这些所代替。</p>
<!--
#### Iptables mode

In "iptables" mode, you should see something like the following on a Node:
-->
<h4 id="iptables-模式">Iptables 模式</h4>
<p>在 &quot;iptables&quot; 模式中, 你应该可以在节点上看到如下输出:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">iptables-save | grep hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">-A KUBE-SEP-57KPRZ3JQVENLNBR -s 10.244.3.6/32 -m comment --comment &quot;default/hostnames:&quot; -j MARK --set-xmark 0x00004000/0x00004000
-A KUBE-SEP-57KPRZ3JQVENLNBR -p tcp -m comment --comment &quot;default/hostnames:&quot; -m tcp -j DNAT --to-destination 10.244.3.6:9376
-A KUBE-SEP-WNBA2IHDGP2BOBGZ -s 10.244.1.7/32 -m comment --comment &quot;default/hostnames:&quot; -j MARK --set-xmark 0x00004000/0x00004000
-A KUBE-SEP-WNBA2IHDGP2BOBGZ -p tcp -m comment --comment &quot;default/hostnames:&quot; -m tcp -j DNAT --to-destination 10.244.1.7:9376
-A KUBE-SEP-X3P2623AGDH6CDF3 -s 10.244.2.3/32 -m comment --comment &quot;default/hostnames:&quot; -j MARK --set-xmark 0x00004000/0x00004000
-A KUBE-SEP-X3P2623AGDH6CDF3 -p tcp -m comment --comment &quot;default/hostnames:&quot; -m tcp -j DNAT --to-destination 10.244.2.3:9376
-A KUBE-SERVICES -d 10.0.1.175/32 -p tcp -m comment --comment &quot;default/hostnames: cluster IP&quot; -m tcp --dport 80 -j KUBE-SVC-NWV5X2332I4OT4T3
-A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment &quot;default/hostnames:&quot; -m statistic --mode random --probability 0.33332999982 -j KUBE-SEP-WNBA2IHDGP2BOBGZ
-A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment &quot;default/hostnames:&quot; -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-X3P2623AGDH6CDF3
-A KUBE-SVC-NWV5X2332I4OT4T3 -m comment --comment &quot;default/hostnames:&quot; -j KUBE-SEP-57KPRZ3JQVENLNBR
</code></pre><!--
For each port of each Service, there should be 1 rule in `KUBE-SERVICES` and
one `KUBE-SVC-<hash>` chain.  For each Pod endpoint, there should be a small
number of rules in that `KUBE-SVC-<hash>` and one `KUBE-SEP-<hash>` chain with
a small number of rules in it.  The exact rules will vary based on your exact
config (including node-ports and load-balancers).
-->
<p>对于每个 Service 的每个端口，应有 1 条 <code>KUBE-SERVICES</code> 规则、一个 <code>KUBE-SVC-&lt;hash&gt;</code> 链。
对于每个 Pod 末端，在那个 <code>KUBE-SVC-&lt;hash&gt;</code> 链中应该有一些规则与之对应，还应该
有一个 <code>KUBE-SEP-&lt;hash&gt;</code> 链与之对应，其中包含为数不多的几条规则。
实际的规则数量可能会根据你实际的配置（包括 NodePort 和 LoadBalancer 服务）有所不同。</p>
<!--
#### IPVS mode

In "ipvs" mode, you should see something like the following on a Node:
-->
<h4 id="ipvs-模式">IPVS 模式</h4>
<p>在 &quot;ipvs&quot; 模式中, 你应该在节点下看到如下输出：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">ipvsadm -ln
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">Prot LocalAddress:Port Scheduler Flags
  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
...
TCP  10.0.1.175:80 rr
  -&gt; 10.244.0.5:9376               Masq    1      0          0
  -&gt; 10.244.0.6:9376               Masq    1      0          0
  -&gt; 10.244.0.7:9376               Masq    1      0          0
...
</code></pre><!--
For each port of each Service, plus any NodePorts, external IPs, and
load-balancer IPs, kube-proxy will create a virtual server.  For each Pod
endpoint, it will create corresponding real servers. In this example, service
hostnames(`10.0.1.175:80`) has 3 endpoints(`10.244.0.5:9376`,
`10.244.0.6:9376`, `10.244.0.7:9376`).
-->
<p>对于每个 Service 的每个端口，还有 NodePort，External IP 和 LoadBalancer 类型服务
的 IP，kube-proxy 将创建一个虚拟服务器。
对于每个 Pod 末端，它将创建相应的真实服务器。
在此示例中，服务主机名（<code>10.0.1.175:80</code>）拥有 3 个末端（<code>10.244.0.5:9376</code>、
<code>10.244.0.6:9376</code> 和 <code>10.244.0.7:9376</code>）。</p>
<!--
#### Userspace mode

In rare cases, you may be using "userspace" mode.  From your Node:
-->
<h4 id="userspace-模式">Userspace 模式</h4>
<p>在极少数情况下，你可能会用到 &quot;userspace&quot; 模式。在你的节点上运行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">iptables-save | grep hostnames
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">-A KUBE-PORTALS-CONTAINER -d 10.0.1.175/32 -p tcp -m comment --comment &quot;default/hostnames:default&quot; -m tcp --dport 80 -j REDIRECT --to-ports 48577
-A KUBE-PORTALS-HOST -d 10.0.1.175/32 -p tcp -m comment --comment &quot;default/hostnames:default&quot; -m tcp --dport 80 -j DNAT --to-destination 10.240.115.247:48577
</code></pre><!--
There should be 2 rules for each port of your Service (only one in this
example) - a "KUBE-PORTALS-CONTAINER" and a "KUBE-PORTALS-HOST".

Almost nobody should be using the "userspace" mode any more, so you won't spend
more time on it here.
-->
<p>对于 Service （本例中只有一个）的每个端口，应当有 2 条规则：
一条 &quot;KUBE-PORTALS-CONTAINER&quot; 和一条 &quot;KUBE-PORTALS-HOST&quot; 规则。</p>
<p>几乎没有人应该再使用 &quot;userspace&quot; 模式，因此你在这里不会花更多的时间。</p>
<!--
### Is kube-proxy proxying?

Assuming you do see one the above cases, try again to access your Service by
IP from one of your Nodes:
-->
<h3 id="kube-proxy-是否在运行">kube-proxy 是否在运行?</h3>
<p>假设你确实遇到上述情况之一，请重试从节点上通过 IP 访问你的 Service ：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl 10.0.1.175:80
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">hostnames-632524106-bbpiw
</code></pre><!--
If this fails and you are using the userspace proxy, you can try accessing the
proxy directly.  If you are using the iptables proxy, skip this section.

Look back at the `iptables-save` output above, and extract the
port number that `kube-proxy` is using for your Service.  In the above
examples it is "48577".  Now connect to that:
-->
<p>如果失败，并且你正在使用用户空间代理，则可以尝试直接访问代理。
如果你使用的是 iptables 代理，请跳过本节。</p>
<p>回顾上面的 <code>iptables-save</code> 输出，并提取 <code>kube-proxy</code> 为你的 Service 所使用的端口号。
在上面的例子中，端口号是 “48577”。现在试着连接它：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl localhost:48577
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">hostnames-632524106-tlaok
</code></pre><!--
If this still fails, look at the `kube-proxy` logs for specific lines like:
-->
<p>如果这步操作仍然失败，请查看 <code>kube-proxy</code> 日志中的特定行，如：</p>
<pre tabindex="0"><code class="language-none" data-lang="none">Setting endpoints for default/hostnames:default to [10.244.0.5:9376 10.244.0.6:9376 10.244.0.7:9376]
</code></pre><!--
If you don't see those, try restarting `kube-proxy` with the `-v` flag set to 4, and
then look at the logs again.
-->
<p>如果你没有看到这些，请尝试将 <code>-V</code> 标志设置为 4 并重新启动 <code>kube-proxy</code>，然后再查看日志。</p>
<!--
### Edge case: A Pod fails to reach itself via the Service IP {#a-pod-fails-to-reach-itself-via-the-service-ip}

This might sound unlikely, but it does happen and it is supposed to work.

This can happen when the network is not properly configured for "hairpin"
traffic, usually when `kube-proxy` is running in `iptables` mode and Pods
are connected with bridge network. The `Kubelet` exposes a `hairpin-mode`
[flag](/docs/reference/command-line-tools-reference/kubelet/) that allows endpoints of a Service to loadbalance
back to themselves if they try to access their own Service VIP. The
`hairpin-mode` flag must either be set to `hairpin-veth` or
`promiscuous-bridge`.

-->
<h3 id="a-pod-fails-to-reach-itself-via-the-service-ip">边缘案例: Pod 无法通过 Service IP 连接到它本身      </h3>
<p>这听起来似乎不太可能，但是确实可能发生，并且应该可行。</p>
<p>如果网络没有为“发夹模式（Hairpin）”流量生成正确配置，
通常当 <code>kube-proxy</code> 以 <code>iptables</code> 模式运行，并且 Pod 与桥接网络连接时，就会发生这种情况。
<code>kubelet</code> 提供了 <code>hairpin-mode</code>
<a href="/zh/docs/reference/command-line-tools-reference/kubelet/">标志</a>。
如果 Service 的末端尝试访问自己的 Service VIP，则该端点可以把流量负载均衡回来到它们自身。
<code>hairpin-mode</code> 标志必须被设置为 <code>hairpin-veth</code> 或者 <code>promiscuous-bridge</code>。</p>
<!--
The common steps to trouble shoot this are as follows:

* Confirm `hairpin-mode` is set to `hairpin-veth` or `promiscuous-bridge`.
You should see something like the below. `hairpin-mode` is set to
`promiscuous-bridge` in the following example.
-->
<p>诊断此类问题的常见步骤如下：</p>
<ul>
<li>
<p>确认 <code>hairpin-mode</code> 被设置为 <code>hairpin-veth</code> 或 <code>promiscuous-bridge</code>。
你应该可以看到下面这样。本例中 <code>hairpin-mode</code> 被设置为 <code>promiscuous-bridge</code>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">ps auxw | grep kubelet
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">root      3392  1.1  0.8 186804 65208 ?        Sl   00:51  11:11 /usr/local/bin/kubelet --enable-debugging-handlers=true --config=/etc/kubernetes/manifests --allow-privileged=True --v=4 --cluster-dns=10.0.0.10 --cluster-domain=cluster.local --configure-cbr0=true --cgroup-root=/ --system-cgroups=/system --hairpin-mode=promiscuous-bridge --runtime-cgroups=/docker-daemon --kubelet-cgroups=/kubelet --babysit-daemons=true --max-pods=110 --serialize-image-pulls=false --outofdisk-transition-frequency=0
</code></pre></li>
</ul>
<!--
* Confirm the effective `hairpin-mode`. To do this, you'll have to look at
kubelet log. Accessing the logs depends on your Node OS. On some OSes it
is a file, such as /var/log/kubelet.log, while other OSes use `journalctl`
to access logs. Please be noted that the effective hairpin mode may not
match `--hairpin-mode` flag due to compatibility. Check if there is any log
lines with key word `hairpin` in kubelet.log. There should be log lines
indicating the effective hairpin mode, like something below.
-->
<ul>
<li>
<p>确认有效的 <code>hairpin-mode</code>。要做到这一点，你必须查看 kubelet 日志。
访问日志取决于节点的操作系统。在一些操作系统上，它是一个文件，如 /var/log/kubelet.log，
而其他操作系统则使用 <code>journalctl</code> 访问日志。请注意，由于兼容性，
有效的 <code>hairpin-mode</code> 可能不匹配 <code>--hairpin-mode</code> 标志。在 kubelet.log
中检查是否有带有关键字 <code>hairpin</code> 的日志行。应该有日志行指示有效的
<code>hairpin-mode</code>，就像下面这样。</p>
<pre tabindex="0"><code class="language-none" data-lang="none">I0629 00:51:43.648698    3252 kubelet.go:380] Hairpin mode set to &quot;promiscuous-bridge&quot;
</code></pre></li>
</ul>
<!--
* If the effective hairpin mode is `hairpin-veth`, ensure the `Kubelet` has
the permission to operate in `/sys` on node. If everything works properly,
you should see something like:
-->
<ul>
<li>
<p>如果有效的发夹模式是 <code>hairpin-veth</code>, 要保证 <code>Kubelet</code> 有操作节点上 <code>/sys</code> 的权限。
如果一切正常，你将会看到如下输出:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#a2f;font-weight:bold">for</span> intf in /sys/devices/virtual/net/cbr0/brif/*; <span style="color:#a2f;font-weight:bold">do</span> cat <span style="color:#b8860b">$intf</span>/hairpin_mode; <span style="color:#a2f;font-weight:bold">done</span>
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">1
1
1
1
</code></pre></li>
</ul>
<!--
* If the effective hairpin mode is `promiscuous-bridge`, ensure `Kubelet`
has the permission to manipulate linux bridge on node. If `cbr0` bridge is
used and configured properly, you should see:
-->
<ul>
<li>
<p>如果有效的发卡模式是 <code>promiscuous-bridge</code>, 要保证 <code>Kubelet</code> 有操作节点上
Linux 网桥的权限。如果 <code>cbr0</code> 桥正在被使用且被正确设置，你将会看到如下输出:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">ifconfig cbr0 |grep PROMISC
</code></pre></div><pre tabindex="0"><code class="language-none" data-lang="none">UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1460  Metric:1
</code></pre></li>
</ul>
<!--
* Seek help if none of above works out.
-->
<ul>
<li>如果以上步骤都不能解决问题，请寻求帮助。</li>
</ul>
<!--
## Seek help

If you get this far, something very strange is happening.  Your Service is
running, has Endpoints, and your Pods are actually serving.  You have DNS
working, and `kube-proxy` does not seem to be misbehaving.  And yet your
Service is not working.  Please let us know what is going on, so we can help
investigate!

Contact us on
[Slack](/docs/tasks/debug-application-cluster/troubleshooting/#slack) or
[Forum](https://discuss.kubernetes.io) or
[GitHub](https://github.com/kubernetes/kubernetes).
-->
<h2 id="寻求帮助">寻求帮助</h2>
<p>如果你走到这一步，那么就真的是奇怪的事情发生了。你的 Service 正在运行，有 Endpoints 存在，
你的 Pods 也确实在提供服务。你的 DNS 正常，<code>iptables</code> 规则已经安装，<code>kube-proxy</code> 看起来也正常。
然而 Service 还是没有正常工作。这种情况下，请告诉我们，以便我们可以帮助调查！</p>
<p>通过
<a href="/zh/docs/tasks/debug-application-cluster/troubleshooting/#slack">Slack</a> 或者
<a href="https://discuss.kubernetes.io">Forum</a> 或者
<a href="https://github.com/kubernetes/kubernetes">GitHub</a>
联系我们。</p>
<h2 id="接下来">接下来</h2>
<!--
Visit [troubleshooting document](/docs/tasks/debug-application-cluster/troubleshooting/)
for more information.
-->
<p>访问<a href="/zh/docs/tasks/debug-application-cluster/troubleshooting/">故障排查文档</a> 获取更多信息。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-a070b1250ee142402d492b505a56ca83">13 - 调试StatefulSet</h1>
    
	<!-- overview -->
<!--
This task shows you how to debug a StatefulSet.
-->
<p>此任务展示如何调试 StatefulSet。</p>
<h2 id="准备开始">准备开始</h2>
<!--
* You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster.
* You should have a StatefulSet running that you want to investigate.
-->
<ul>
<li>你需要有一个 Kubernetes 集群，已配置好的 kubectl 命令行工具与你的集群进行通信。</li>
<li>你应该有一个运行中的 StatefulSet，以便用于调试。</li>
</ul>
<!-- steps -->
<!--
## Debugging a StatefulSet

In order to list all the pods which belong to a StatefulSet, which have a label `app=myapp` set on them,
you can use the following:
-->
<h2 id="debuggin-a-statefulset">调试 StatefulSet  </h2>
<p>StatefulSet 在创建 Pod 时为其设置了 <code>app=myapp</code> 标签，列出仅属于某 StatefulSet
的所有 Pod 时，可以使用以下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pods -l <span style="color:#b8860b">app</span><span style="color:#666">=</span>myapp
</code></pre></div><!--
If you find that any Pods listed are in `Unknown` or `Terminating` state for an extended period of time,
refer to the [Deleting StatefulSet Pods](/docs/tasks/run-application/delete-stateful-set/) task for
instructions on how to deal with them.
You can debug individual Pods in a StatefulSet using the
[Debugging Pods](/docs/tasks/debug-application-cluster/debug-pod-replication-controller/) guide.
-->
<p>如果你发现列出的任何 Pod 长时间处于 <code>Unknown</code> 或 <code>Terminating</code> 状态，请参阅
<a href="/zh/docs/tasks/run-application/delete-stateful-set/">删除 StatefulSet Pods</a>
了解如何处理它们的说明。
你可以参考<a href="/zh/docs/tasks/debug-application-cluster/debug-pod-replication-controller/">调试 Pods</a>
来调试 StatefulSet 中的各个 Pod。</p>
<h2 id="接下来">接下来</h2>
<!--
Learn more about [debugging an init-container](/docs/tasks/debug-application-cluster/debug-init-containers/).
-->
<ul>
<li>进一步了解如何<a href="/zh/docs/tasks/debug-application-cluster/debug-init-containers/">调试 Init 容器</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-c0ec963f381296ca26b839cdf0a6f242">14 - 调试运行中的 Pod</h1>
    
	<!-- overview -->
<!--
This page explains how to debug Pods running (or crashing) on a Node.
-->
<p>本页解释如何在节点上调试运行中（或崩溃）的 Pod。</p>
<h2 id="准备开始">准备开始</h2>
<!--
* Your <a class='glossary-tooltip' title='Pod 表示您的集群上一组正在运行的容器。' data-toggle='tooltip' data-placement='top' href='/docs/concepts/workloads/pods/pod-overview/' target='_blank' aria-label='Pod'>Pod</a> should already be
  scheduled and running. If your Pod is not yet running, start with [Troubleshoot
  Applications](/docs/tasks/debug-application-cluster/debug-application/).
* For some of the advanced debugging steps you need to know on which Node the
  Pod is running and have shell access to run commands on that Node. You don't
  need that access to run the standard debug steps that use `kubectl`.
-->
<ul>
<li>
<p>你的 <a class='glossary-tooltip' title='Pod 表示您的集群上一组正在运行的容器。' data-toggle='tooltip' data-placement='top' href='/docs/concepts/workloads/pods/pod-overview/' target='_blank' aria-label='Pod'>Pod</a> 应该已经被调度并正在运行中，
如果你的 Pod 还没有运行，请参阅
<a href="/zh/docs/tasks/debug-application-cluster/debug-application/">应用问题排查</a>。</p>
</li>
<li>
<p>对于一些高级调试步骤，你应该知道 Pod 具体运行在哪个节点上，在该节点上有权限去运行一些命令。
你不需要任何访问权限就可以使用 <code>kubectl</code> 去运行一些标准调试步骤。</p>
</li>
</ul>
<!-- steps -->
<!--
## Examining pod logs {#examine-pod-logs}

First, look at the logs of the affected container:

```shell
kubectl logs ${POD_NAME} ${CONTAINER_NAME}
```

If your container has previously crashed, you can access the previous container's crash log with:

```shell
kubectl logs --previous ${POD_NAME} ${CONTAINER_NAME}
```
-->
<h2 id="examine-pod-logs">检查 Pod 的日志</h2>
<p>首先，查看受到影响的容器的日志：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl logs <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">POD_NAME</span><span style="color:#b68;font-weight:bold">}</span> <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">CONTAINER_NAME</span><span style="color:#b68;font-weight:bold">}</span>
</code></pre></div><p>如果你的容器之前崩溃过，你可以通过下面命令访问之前容器的崩溃日志：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl logs --previous <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">POD_NAME</span><span style="color:#b68;font-weight:bold">}</span> <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">CONTAINER_NAME</span><span style="color:#b68;font-weight:bold">}</span>
</code></pre></div><!--
## Debugging with container exec {#container-exec}

```shell
kubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}
```

As an example, to look at the logs from a running Cassandra pod, you might run

```shell
kubectl exec cassandra -- cat /var/log/cassandra/system.log
```

You can run a shell that's connected to your terminal using the `-i` and `-t`
arguments to `kubectl exec`, for example:

```shell
kubectl exec -it cassandra -- sh
```

For more details, see [Get a Shell to a Running Container](
/docs/tasks/debug-application-cluster/get-shell-running-container/).
-->
<h2 id="container-exec">使用容器 exec 进行调试</h2>
<p>如果 <a class='glossary-tooltip' title='镜像是保存的容器实例，它打包了应用运行所需的一组软件。' data-toggle='tooltip' data-placement='top' href='/zh/docs/reference/glossary/?all=true#term-image' target='_blank' aria-label='容器镜像'>容器镜像</a> 包含调试程序，
比如从 Linux 和 Windows 操作系统基础镜像构建的镜像，你可以使用 <code>kubectl exec</code> 命令
在特定的容器中运行一些命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">POD_NAME</span><span style="color:#b68;font-weight:bold">}</span> -c <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">CONTAINER_NAME</span><span style="color:#b68;font-weight:bold">}</span> -- <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">CMD</span><span style="color:#b68;font-weight:bold">}</span> <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">ARG1</span><span style="color:#b68;font-weight:bold">}</span> <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">ARG2</span><span style="color:#b68;font-weight:bold">}</span> ... <span style="color:#b68;font-weight:bold">${</span><span style="color:#b8860b">ARGN</span><span style="color:#b68;font-weight:bold">}</span>
</code></pre></div><blockquote class="note callout">
  <div><strong>说明：</strong> <code>-c ${CONTAINER_NAME}</code> 是可选择的。如果Pod中仅包含一个容器，就可以忽略它。</div>
</blockquote>
<p>例如，要查看正在运行的 Cassandra pod中的日志，可以运行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> cassandra -- cat /var/log/cassandra/system.log
</code></pre></div><p>你可以在 <code>kubectl exec</code> 命令后面加上 <code>-i</code> 和 <code>-t</code> 来运行一个连接到你的终端的 Shell，比如：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> -it cassandra -- sh
</code></pre></div><p>若要了解更多内容，可查看<a href="/zh/docs/tasks/debug-application-cluster/get-shell-running-container/">获取正在运行容器的 Shell</a>。</p>
<!--
## Debugging with an ephemeral debug container {#ephemeral-container}






<div style="margin-top: 10px; margin-bottom: 10px;">
<b>FEATURE STATE:</b> <code>Kubernetes v1.22 [alpha]</code>
</div>


<a class='glossary-tooltip' title='您可以在 Pod 中临时运行的一种容器类型' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/pods/ephemeral-containers/' target='_blank' aria-label='Ephemeral containers'>Ephemeral containers</a>
are useful for interactive troubleshooting when `kubectl exec` is insufficient
because a container has crashed or a container image doesn't include debugging
utilities, such as with [distroless images](
https://github.com/GoogleContainerTools/distroless).
-->
<h2 id="ephemeral-container">使用临时调试容器来进行调试</h2>





<div style="margin-top: 10px; margin-bottom: 10px;">
<b>FEATURE STATE:</b> <code>Kubernetes v1.22 [alpha]</code>
</div>

<p>当由于容器崩溃或容器镜像不包含调试程序（例如<a href="https://github.com/GoogleContainerTools/distroless">无发行版镜像</a>等）
而导致 <code>kubectl exec</code> 无法运行时，<a class='glossary-tooltip' title='您可以在 Pod 中临时运行的一种容器类型' data-toggle='tooltip' data-placement='top' href='/zh/docs/concepts/workloads/pods/ephemeral-containers/' target='_blank' aria-label='临时容器'>临时容器</a>对于排除交互式故障很有用。</p>
<!--
### Example debugging using ephemeral containers {#ephemeral-container-example}

The examples in this section require the `EphemeralContainers` [feature gate](
/docs/reference/command-line-tools-reference/feature-gates/) enabled in your
cluster and `kubectl` version v1.22 or later.

You can use the `kubectl debug` command to add ephemeral containers to a
running Pod. First, create a pod for the example:

```shell
kubectl run ephemeral-demo --image=k8s.gcr.io/pause:3.1 --restart=Never
```

This section use the `pause` container image in examples because it does not
contain debugging utilities, but this method works with all container
images.
-->
<h2 id="ephemeral-container-example">使用临时容器来调试的例子</h2>
<blockquote class="note callout">
  <div><strong>说明：</strong> 本示例需要你的集群已经开启 <code>EphemeralContainers</code>
<a href="/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a>，
<code>kubectl</code> 版本为 v1.22 或者更高。</div>
</blockquote>
<p>你可以使用 <code>kubectl debug</code> 命令来给正在运行中的 Pod 增加一个临时容器。
首先，像示例一样创建一个 pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run ephemeral-demo --image<span style="color:#666">=</span>k8s.gcr.io/pause:3.1 --restart<span style="color:#666">=</span>Never
</code></pre></div><blockquote class="note callout">
  <div><strong>说明：</strong> 本节示例中使用 <code>pause</code> 容器镜像，因为它不包含调试程序，但是这个方法适用于所有容器镜像。</div>
</blockquote>
<!--
If you attempt to use `kubectl exec` to create a shell you will see an error
because there is no shell in this container image.

```shell
kubectl exec -it ephemeral-demo -- sh
```

```
OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused "exec: \"sh\": executable file not found in $PATH": unknown
```

You can instead add a debugging container using `kubectl debug`. If you
specify the `-i`/`--interactive` argument, `kubectl` will automatically attach
to the console of the Ephemeral Container.

```shell
kubectl debug -it ephemeral-demo --image=busybox --target=ephemeral-demo
```

```
Defaulting debug container name to debugger-8xzrl.
If you don't see a command prompt, try pressing enter.
/ #
```
-->
<p>如果你尝试使用 <code>kubectl exec</code> 来创建一个 shell，你将会看到一个错误，因为这个容器镜像中没有 shell。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl <span style="color:#a2f">exec</span> -it ephemeral-demo -- sh
</code></pre></div><pre tabindex="0"><code>OCI runtime exec failed: exec failed: container_linux.go:346: starting container process caused &quot;exec: \&quot;sh\&quot;: executable file not found in $PATH&quot;: unknown
</code></pre><p>你可以改为使用 <code>kubectl debug</code> 添加调试容器。
如果你指定 <code>-i</code> 或者 <code>--interactive</code> 参数，<code>kubectl</code> 将自动挂接到临时容器的控制台。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl debug -it ephemeral-demo --image<span style="color:#666">=</span>busybox --target<span style="color:#666">=</span>ephemeral-demo
</code></pre></div><pre tabindex="0"><code>Defaulting debug container name to debugger-8xzrl.
If you don't see a command prompt, try pressing enter.
/ #
</code></pre><!--
This command adds a new busybox container and attaches to it. The `--target`
parameter targets the process namespace of another container. It's necessary
here because `kubectl run` does not enable [process namespace sharing](
/docs/tasks/configure-pod-container/share-process-namespace/) in the pod it
creates.

The `--target` parameter must be supported by the <a class='glossary-tooltip' title='容器运行时是负责运行容器的软件。' data-toggle='tooltip' data-placement='top' href='/zh/docs/setup/production-environment/container-runtimes' target='_blank' aria-label='Container Runtime'>Container Runtime</a>. When not supported,
the Ephemeral Container may not be started, or it may be started with an
isolated process namespace so that `ps` does not reveal processes in other containers.

You can view the state of the newly created ephemeral container using `kubectl describe`:
-->
<p>此命令添加一个新的 busybox 容器并将其挂接到该容器。<code>--target</code> 参数指定另一个容器的进程命名空间。
这是必需的，因为 <code>kubectl run</code> 不能在它创建的pod中启用
<a href="/zh/docs/tasks/configure-pod-container/share-process-namespace/">共享进程命名空间</a>。</p>
<blockquote class="note callout">
  <div><strong>说明：</strong> <a class='glossary-tooltip' title='容器运行时是负责运行容器的软件。' data-toggle='tooltip' data-placement='top' href='/zh/docs/setup/production-environment/container-runtimes' target='_blank' aria-label='容器运行时'>容器运行时</a>必须支持<code>--target</code>参数。
如果不支持，则临时容器可能不会启动，或者可能使用隔离的进程命名空间启动，
以便 <code>ps</code> 不显示其他容器内的进程。</div>
</blockquote>
<p>你可以使用 <code>kubectl describe</code> 查看新创建的临时容器的状态：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl describe pod ephemeral-demo
</code></pre></div><pre tabindex="0"><code>...
Ephemeral Containers:
  debugger-8xzrl:
    Container ID:   docker://b888f9adfd15bd5739fefaa39e1df4dd3c617b9902082b1cfdc29c4028ffb2eb
    Image:          busybox
    Image ID:       docker-pullable://busybox@sha256:1828edd60c5efd34b2bf5dd3282ec0cc04d47b2ff9caa0b6d4f07a21d1c08084
    Port:           &lt;none&gt;
    Host Port:      &lt;none&gt;
    State:          Running
      Started:      Wed, 12 Feb 2020 14:25:42 +0100
    Ready:          False
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:         &lt;none&gt;
...
</code></pre><!--
Use `kubectl delete` to remove the Pod when you're finished:
-->
<p>使用 <code>kubectl delete</code> 来移除已经结束掉的 Pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pod ephemeral-demo
</code></pre></div><!--
## Debugging using a copy of the Pod
-->
<h2 id="通过-pod-副本调试">通过 Pod 副本调试</h2>
<!--
Sometimes Pod configuration options make it difficult to troubleshoot in certain
situations. For example, you can't run `kubectl exec` to troubleshoot your
container if your container image does not include a shell or if your application
crashes on startup. In these situations you can use `kubectl debug` to create a
copy of the Pod with configuration values changed to aid debugging.
-->
<p>有些时候 Pod 的配置参数使得在某些情况下很难执行故障排查。
例如，在容器镜像中不包含 shell 或者你的应用程序在启动时崩溃的情况下，
就不能通过运行 <code>kubectl exec</code> 来排查容器故障。
在这些情况下，你可以使用 <code>kubectl debug</code> 来创建 Pod 的副本，通过更改配置帮助调试。</p>
<!--
### Copying a Pod while adding a new container
-->
<h3 id="在添加新的容器时创建-pod-副本">在添加新的容器时创建 Pod 副本</h3>
<!--
Adding a new container can be useful when your application is running but not
behaving as you expect and you'd like to add additional troubleshooting
utilities to the Pod.
-->
<p>当应用程序正在运行但其表现不符合预期时，你会希望在 Pod 中添加额外的调试工具，
这时添加新容器是很有用的。</p>
<!--
For example, maybe your application's container images are built on `busybox`
but you need debugging utilities not included in `busybox`. You can simulate
this scenario using `kubectl run`:
-->
<p>例如，应用的容器镜像是建立在 <code>busybox</code> 的基础上，
但是你需要 <code>busybox</code> 中并不包含的调试工具。
你可以使用 <code>kubectl run</code> 模拟这个场景:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl run myapp --image<span style="color:#666">=</span>busybox --restart<span style="color:#666">=</span>Never -- sleep 1d
</code></pre></div><!--
Run this command to create a copy of `myapp` named `myapp-debug` that adds a
new Ubuntu container for debugging:
-->
<p>通过运行以下命令，建立 <code>myapp</code> 的一个名为 <code>myapp-debug</code> 的副本，
新增了一个用于调试的 Ubuntu 容器，</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl debug myapp -it --image<span style="color:#666">=</span>ubuntu --share-processes --copy-to<span style="color:#666">=</span>myapp-debug
</code></pre></div><pre tabindex="0"><code>Defaulting debug container name to debugger-w7xmf.
If you don't see a command prompt, try pressing enter.
root@myapp-debug:/#
</code></pre><!--
<blockquote class="note callout">
  <div><strong>说明：</strong> <ul>
<li><code>kubectl debug</code> automatically generates a container name if you don't choose
one using the <code>--container</code> flag.</li>
<li>The <code>-i</code> flag causes <code>kubectl debug</code> to attach to the new container by
default.  You can prevent this by specifying <code>--attach=false</code>. If your session
becomes disconnected you can reattach using <code>kubectl attach</code>.</li>
<li>The <code>--share-processes</code> allows the containers in this Pod to see processes
from the other containers in the Pod. For more information about how this
works, see <a href="/docs/tasks/configure-pod-container/share-process-namespace/">Share Process Namespace between Containers in a Pod</a>.</li>
</ul>
</div>
</blockquote>
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> <ul>
<li>如果你没有使用 <code>--container</code> 指定新的容器名，<code>kubectl debug</code> 会自动生成的。</li>
<li>默认情况下，<code>-i</code> 标志使 <code>kubectl debug</code> 附加到新容器上。
你可以通过指定 <code>--attach=false</code> 来防止这种情况。
如果你的会话断开连接，你可以使用 <code>kubectl attach</code> 重新连接。</li>
<li><code>--share-processes</code> 允许在此 Pod 中的其他容器中查看该容器的进程。
参阅<a href="/zh/docs/tasks/configure-pod-container/share-process-namespace/">在 Pod 中的容器之间共享进程命名空间</a>
获取更多信息。</li>
</ul>
</div>
</blockquote>
<!--
Don't forget to clean up the debugging Pod when you're finished with it:
-->
<p>不要忘了清理调试 Pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pod myapp myapp-debug
</code></pre></div><!--
### Copying a Pod while changing its command
-->
<h3 id="在改变-pod-命令时创建-pod-副本">在改变 Pod 命令时创建 Pod 副本</h3>
<!--
Sometimes it's useful to change the command for a container, for example to
add a debugging flag or because the application is crashing.
-->
<p>有时更改容器的命令很有用，例如添加调试标志或因为应用崩溃。</p>
<!--
To simulate a crashing application, use `kubectl run` to create a container
that immediately exits:
-->
<p>为了模拟应用崩溃的场景，使用 <code>kubectl run</code> 命令创建一个立即退出的容器：</p>
<pre tabindex="0"><code>kubectl run --image=busybox myapp -- false
</code></pre><!--
You can see using `kubectl describe pod myapp` that this container is crashing:
-->
<p>使用 <code>kubectl describe pod myapp</code> 命令，你可以看到容器崩溃了：</p>
<pre tabindex="0"><code>Containers:
  myapp:
    Image:         busybox
    ...
    Args:
      false
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
</code></pre><!--
You can use `kubectl debug` to create a copy of this Pod with the command
changed to an interactive shell:
-->
<p>你可以使用 <code>kubectl debug</code> 命令创建该 Pod 的一个副本，
在该副本中命令改变为交互式 shell：</p>
<pre tabindex="0"><code>kubectl debug myapp -it --copy-to=myapp-debug --container=myapp -- sh
</code></pre><pre tabindex="0"><code>If you don't see a command prompt, try pressing enter.
/ #
</code></pre><!--
Now you have an interactive shell that you can use to perform tasks like
checking filesystem paths or running the container command manually.
-->
<p>现在你有了一个可以执行类似检查文件系统路径或者手动运行容器命令的交互式 shell。</p>
<!--
<blockquote class="note callout">
  <div><strong>说明：</strong> <ul>
<li>To change the command of a specific container you must
specify its name using <code>--container</code> or <code>kubectl debug</code> will instead
create a new container to run the command you specified.</li>
<li>The <code>-i</code> flag causes <code>kubectl debug</code> to attach to the container by default.
You can prevent this by specifying <code>--attach=false</code>. If your session becomes
disconnected you can reattach using <code>kubectl attach</code>.</li>
</ul>
</div>
</blockquote>
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> <ul>
<li>要更改指定容器的命令，你必须用 <code>--container</code> 命令指定容器的名字，
否则 <code>kubectl debug</code> 将建立一个新的容器运行你指定的命令。</li>
<li>默认情况下，标志 <code>-i</code> 使 <code>kubectl debug</code> 附加到容器。
你可通过指定 <code>--attach=false</code> 来防止这种情况。
如果你的断开连接，可以使用 <code>kubectl attach</code> 重新连接。</li>
</ul>
</div>
</blockquote>
<!--
Don't forget to clean up the debugging Pod when you're finished with it:
-->
<p>不要忘了清理调试 Pod：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pod myapp myapp-debug
</code></pre></div><!--
### Copying a Pod while changing container images

In some situations you may want to change a misbehaving Pod from its normal
production container images to an image containing a debugging build or
additional utilities.

As an example, create a Pod using `kubectl run`:
-->
<h3 id="在更改容器镜像时创建-pod-副本">在更改容器镜像时创建 Pod 副本</h3>
<p>在某些情况下，你可能想从正常生产容器镜像中
把行为异常的 Pod 改变为包含调试版本或者附加应用的镜像。</p>
<p>下面的例子，用 <code>kubectl run</code>创建一个 Pod：</p>
<pre tabindex="0"><code>kubectl run myapp --image=busybox --restart=Never -- sleep 1d
</code></pre><!--
Now use `kubectl debug` to make a copy and change its container image
to `ubuntu`:
-->
<p>现在可以使用 <code>kubectl debug</code>  创建一个副本
并改变容器镜像为 <code>ubuntu</code>：</p>
<pre tabindex="0"><code>kubectl debug myapp --copy-to=myapp-debug --set-image=*=ubuntu
</code></pre><!--
The syntax of `--set-image` uses the same `container_name=image` syntax as
`kubectl set image`. `*=ubuntu` means change the image of all containers
to `ubuntu`.

Don't forget to clean up the debugging Pod when you're finished with it:
-->
<p><code>--set-image</code> 与 <code>container_name=image</code> 使用相同的 <code>kubectl set image</code> 语法。
<code>*=ubuntu</code> 表示把所有容器的镜像改为 <code>ubuntu</code>。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl delete pod myapp myapp-debug
</code></pre></div><!--
## Debugging via a shell on the node {#node-shell-session}

If none of these approaches work, you can find the host machine that the pod is
running on and SSH into that host, but this should generally not be necessary
given tools in the Kubernetes API. Therefore, if you find yourself needing to
ssh into a machine, please file a feature request on GitHub describing your use
case and why these tools are insufficient.
-->
<h2 id="node-shell-session">在节点上通过 shell 来调试</h2>
<p>如果这些方法都不起作用，你可以找到运行 Pod 的主机并通过 SSH 进入该主机，
但是如果使用 Kubernetes API 中的工具，则通常不需要这样做。
因此，如果你发现自己需要使用 ssh 进入主机，请在GitHub 上提交功能请求，
以描述你的用例以及这些工具不足的原因。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-96b25d30e732385047272b84d3c4188f">15 - 资源指标管道</h1>
    
	<!--
reviewers:
- fgrzadkowski
- piosz
title: Resource metrics pipeline
content_type: concept
-->
<!-- overview -->
<!--
Resource usage metrics, such as container CPU and memory usage,
are available in Kubernetes through the Metrics API. These metrics can be accessed either directly
by the user with the `kubectl top` command, or by a controller in the cluster, for example
Horizontal Pod Autoscaler, to make decisions.
-->
<p>资源使用指标，例如容器 CPU 和内存使用率，可通过 Metrics API 在 Kubernetes 中获得。
这些指标可以直接被用户访问，比如使用 <code>kubectl top</code> 命令行，或者被集群中的控制器
（例如 Horizontal Pod Autoscalers) 使用来做决策。</p>
<!-- body -->
<!--
## The Metrics API

Through the Metrics API, you can get the amount of resource currently used
by a given node or a given pod. This API doesn't store the metric values,
so it's not possible, for example, to get the amount of resources used by a
given node 10 minutes ago.
-->
<h2 id="the-metrics-api">Metrics API  </h2>
<p>通过 Metrics API，你可以获得指定节点或 Pod 当前使用的资源量。
此 API 不存储指标值，因此想要获取某个指定节点 10 分钟前的
资源使用量是不可能的。</p>
<!--
The API is no different from any other API:
-->
<p>此 API 与其他 API 没有区别：</p>
<!--
- it is discoverable through the same endpoint as the other Kubernetes APIs under the path: `/apis/metrics.k8s.io/`
- it offers the same security, scalability, and reliability guarantees
-->
<ul>
<li>此 API 和其它 Kubernetes API 一起位于同一端点（endpoint）之下且可发现，
路径为 <code>/apis/metrics.k8s.io/</code></li>
<li>它具有相同的安全性、可扩展性和可靠性保证</li>
</ul>
<!--
The API is defined in [k8s.io/metrics](https://github.com/kubernetes/metrics/blob/master/pkg/apis/metrics/v1beta1/types.go)
repository. You can find more information about the API there.
-->
<p>Metrics API 在 <a href="https://github.com/kubernetes/metrics/blob/master/pkg/apis/metrics/v1beta1/types.go">k8s.io/metrics</a>
仓库中定义。你可以在那里找到有关 Metrics API 的更多信息。</p>
<!--
The API requires metrics server to be deployed in the cluster. Otherwise it will be not available.
-->
<blockquote class="note callout">
  <div><strong>说明：</strong> Metrics API 需要在集群中部署 Metrics Server。否则它将不可用。</div>
</blockquote>
<!--
## Measuring Resource Usage

### CPU

CPU is reported as the average usage, in
[CPU cores](/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu),
over a period of time. This value is derived by taking a rate over a cumulative CPU counter
provided by the kernel (in both Linux and Windows kernels).
The kubelet chooses the window for the rate calculation.
-->
<h2 id="measuring-resource-usage">度量资源用量  </h2>
<h3 id="cpu">CPU</h3>
<p>CPU 用量按其一段时间内的平均值统计，单位为
<a href="/zh/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu">CPU 核</a>。
此度量值通过在内核（包括 Linux 和 Windows）提供的累积 CPU 计数器乘以一个系数得到。
<code>kubelet</code> 组件负责选择计算系数所使用的窗口大小。</p>
<!--
### Memory

Memory is reported as the working set, in bytes, at the instant the metric was collected.
In an ideal world, the "working set" is the amount of memory in-use that cannot be freed under memory pressure.
However, calculation of the working set varies by host OS, and generally makes heavy use of heuristics to produce an estimate.
It includes all anonymous (non-file-backed) memory since Kubernetes does not support swap.
The metric typically also includes some cached (file-backed) memory, because the host OS cannot always reclaim such pages.
-->
<h3 id="memory">内存 </h3>
<p>内存用量按工作集（Working Set）的大小字节数统计，其数值为收集度量值的那一刻的内存用量。
如果一切都很理想化，“工作集” 是任务在使用的内存总量，该内存是不可以在内存压力较大
的情况下被释放的。
不过，具体的工作集计算方式取决于宿主 OS，有很大不同，且通常都大量使用启发式
规则来给出一个估计值。
其中包含所有匿名内存使用（没有后台文件提供存储者），因为 Kubernetes 不支持交换分区。
度量值通常包含一些高速缓存（有后台文件提供存储）内存，因为宿主操作系统并不是总能
回收这些页面。</p>
<!--
## Metrics Server

[Metrics Server](https://github.com/kubernetes-sigs/metrics-server) is a cluster-wide aggregator of resource usage data.
By default, it is deployed in clusters created by `kube-up.sh` script
as a Deployment object. If you use a different Kubernetes setup mechanism you can deploy it using the provided
[deployment components.yaml](https://github.com/kubernetes-sigs/metrics-server/releases) file.
-->
<h2 id="metrics-server">Metrics 服务器   </h2>
<p><a href="https://github.com/kubernetes-sigs/metrics-server">Metrics 服务器</a>
是集群范围资源用量数据的聚合器。
默认情况下，在由 <code>kube-up.sh</code> 脚本创建的集群中会以 Deployment 的形式被部署。
如果你使用其他 Kubernetes 安装方法，则可以使用提供的
<a href="https://github.com/kubernetes-incubator/metrics-server/tree/master/deploy">部署组件 components.yaml</a>
来部署。</p>
<!--
Metric server collects metrics from the Summary API, exposed by
[Kubelet](/docs/reference/command-line-tools-reference/kubelet/) on each node, and is registered with the main API server via
[Kubernetes aggregator](/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/).
-->
<p>Metric 服务器从每个节点上的 <a href="/zh/docs/reference/command-line-tools-reference/kubelet/">kubelet</a>
公开的 Summary API 中采集指标信息。
该 API 通过
<a href="/zh/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">Kubernetes 聚合器</a>
注册到主 API 服务器上。</p>
<!--
Learn more about the metrics server in
[the design doc](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/metrics-server.md).
-->
<p>在<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/metrics-server.md">设计文档</a>
中可以了解到有关 Metrics 服务器的更多信息。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-9e6e1b706f11386fe2c4b4ffda1409e4">16 - 资源监控工具</h1>
    
	<!--
reviewers:
- mikedanese
content_type: concept
title: Tools for Monitoring Resources
-->
<!-- overview -->
<!--
To scale an application and provide a reliable service, you need to
understand how the application behaves when it is deployed. You can examine
application performance in a Kubernetes cluster by examining the containers,
[pods](/docs/concepts/workloads/pods/),
[services](/docs/concepts/services-networking/service/), and
the characteristics of the overall cluster. Kubernetes provides detailed
information about an application's resource usage at each of these levels.
This information allows you to evaluate your application's performance and
where bottlenecks can be removed to improve overall performance.
-->
<p>要扩展应用程序并提供可靠的服务，你需要了解应用程序在部署时的行为。
你可以通过检测容器检查 Kubernetes 集群中的应用程序性能，
<a href="/zh/docs/concepts/workloads/pods">Pods</a>,
<a href="/zh/docs/concepts/services-networking/service/">服务</a>
和整个集群的特征。
Kubernetes 在每个级别上提供有关应用程序资源使用情况的详细信息。
此信息使你可以评估应用程序的性能，以及在何处可以消除瓶颈以提高整体性能。</p>
<!-- body -->
<!--
In Kubernetes, application monitoring does not depend on a single monitoring solution.
On new clusters, you can use [resource metrics](#resource-metrics-pipeline) or
[full metrics](#full-metrics-pipeline) pipelines to collect monitoring statistics.
-->
<p>在 Kubernetes 中，应用程序监控不依赖单个监控解决方案。
在新集群上，你可以使用<a href="#resource-metrics-pipeline">资源度量</a>或
<a href="#full-metrics-pipeline">完整度量</a>管道来收集监视统计信息。</p>
<!--
## Resource metrics pipeline

The resource metrics pipeline provides a limited set of metrics related to
cluster components such as the
[Horizontal Pod Autoscaler](/docs/tasks/run-application/horizontal-pod-autoscale)
controller, as well as the `kubectl top` utility.
These  metrics are collected by the lightweight, short-term, in-memory 
[metrics-server](https://github.com/kubernetes-sigs/metrics-server) and
 are exposed via the `metrics.k8s.io` API. 
-->
<h2 id="resource-metrics-pipeline">资源度量管道 </h2>
<p>资源指标管道提供了一组与集群组件，例如
<a href="/zh/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler</a>
控制器以及 <code>kubectl top</code> 实用程序相关的有限度量。
这些指标是由轻量级的、短期、内存存储的
<a href="https://github.com/kubernetes-sigs/metrics-server">metrics-server</a> 收集的，
通过 <code>metrics.k8s.io</code> 公开。</p>
<!--
metrics-server discovers all nodes on the cluster and 
queries each node's 
[kubelet](/docs/reference/command-line-tools-reference/kubelet/) for CPU and 
memory usage. The kubelet acts as a bridge between the Kubernetes master and 
the nodes, managing the pods and containers running on a machine. The kubelet 
translates each pod into its constituent containers and fetches individual 
container usage statistics from the container runtime through the container 
runtime interface. The kubelet fetches this information from the integrated 
cAdvisor for the legacy Docker integration.  It then exposes the aggregated pod 
resource usage statistics through the metrics-server Resource Metrics API.
This API is served at `/metrics/resource/v1beta1` on the kubelet's authenticated and 
read-only ports. 
-->
<p>度量服务器发现集群中的所有节点，并且查询每个节点的
<a href="/zh/docs/reference/command-line-tools-reference/kubelet/">kubelet</a>
以获取 CPU 和内存使用情况。
Kubelet 充当 Kubernetes 主节点与节点之间的桥梁，管理机器上运行的 Pod 和容器。
kubelet 将每个 Pod 转换为其组成的容器，并在容器运行时通过容器运行时接口
获取各个容器使用情况统计信息。
kubelet 从集成的 cAdvisor 获取此信息，以进行旧式 Docker 集成。
然后，它通过 metrics-server Resource Metrics API 公开聚合的 pod 资源使用情况统计信息。
该 API 在 kubelet 的经过身份验证和只读的端口上的 <code>/metrics/resource/v1beta1</code> 中提供。</p>
<!--
## Full metrics pipeline

A full metrics pipeline gives you access to richer metrics. Kubernetes can
respond to these metrics by  automatically scaling or adapting the cluster
based on its current state, using mechanisms such as the Horizontal Pod
Autoscaler. The monitoring pipeline fetches metrics from the kubelet and
then exposes them to Kubernetes via an adapter by implementing either the
`custom.metrics.k8s.io` or `external.metrics.k8s.io` API. 
-->
<h2 id="full-metrics-pipeline">完整度量管道 </h2>
<p>一个完整度量管道可以让你访问更丰富的度量。
Kubernetes 还可以根据集群的当前状态，使用 Pod 水平自动扩缩器等机制，
通过自动调用扩展或调整集群来响应这些度量。
监控管道从 kubelet 获取度量值，然后通过适配器将它们公开给 Kubernetes，
方法是实现 <code>custom.metrics.k8s.io</code> 或 <code>external.metrics.k8s.io</code> API。</p>
<!--
[Prometheus](https://prometheus.io), a CNCF project, can natively monitor Kubernetes, nodes, and Prometheus itself.
Full metrics pipeline projects that are not part of the CNCF are outside the scope of Kubernetes documentation.  
-->
<p><a href="https://prometheus.io">Prometheus</a> 是一个 CNCF 项目，可以原生监控 Kubernetes、
节点和 Prometheus 本身。
完整度量管道项目不属于 CNCF 的一部分，不在 Kubernetes 文档的范围之内。</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-47290c80fb8b00accec6729f3da49734">17 - 集群故障排查</h1>
    
	<!--
reviewers:
- davidopp
title: Troubleshoot Clusters
content_type: concept
-->
<!-- overview -->
<!--
This doc is about cluster troubleshooting; we assume you have already ruled out your application as the root cause of the
problem you are experiencing. See
the [application troubleshooting guide](/docs/tasks/debug-application-cluster/debug-application) for tips on application debugging.
You may also visit [troubleshooting document](/docs/tasks/debug-application-cluster/troubleshooting/) for more information.
-->
<p>本篇文档是介绍集群故障排查的；我们假设对于你碰到的问题，你已经排除了是由应用程序造成的。
对于应用的调试，请参阅
<a href="/zh/docs/tasks/debug-application-cluster/debug-application/">应用故障排查指南</a>。
你也可以访问<a href="/zh/docs/tasks/debug-application-cluster/troubleshooting/">故障排查</a>
来获取更多的信息。</p>
<!-- body -->
<!--
## Listing your cluster

The first thing to debug in your cluster is if your nodes are all registered correctly.

Run
-->
<h2 id="列举集群节点">列举集群节点</h2>
<p>调试的第一步是查看所有的节点是否都已正确注册。</p>
<p>运行</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get nodes
</code></pre></div><!--
And verify that all of the nodes you expect to see are present and that they are all in the `Ready` state.

To get detailed information about the overall health of your cluster, you can run:
-->
<p>验证你所希望看见的所有节点都能够显示出来，并且都处于 <code>Ready</code> 状态。</p>
<p>为了了解你的集群的总体健康状况详情，你可以运行：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl cluster-info dump
</code></pre></div><!--
## Looking at logs

For now, digging deeper into the cluster requires logging into the relevant machines.  Here are the locations
of the relevant log files.  (note that on systemd-based systems, you may need to use `journalctl` instead)
-->
<h2 id="查看日志">查看日志</h2>
<p>到这里，挖掘出集群更深层的信息就需要登录到相关的机器上。下面是相关日志文件所在的位置。
（注意，对于基于 systemd 的系统，你可能需要使用<code>journalctl</code>）。</p>
<!--
### Master

   * `/var/log/kube-apiserver.log` - API Server, responsible for serving the API
   * `/var/log/kube-scheduler.log` - Scheduler, responsible for making scheduling decisions
   * `/var/log/kube-controller-manager.log` - Controller that manages replication controllers
-->
<h3 id="主控节点">主控节点</h3>
<ul>
<li><code>/var/log/kube-apiserver.log</code> - API 服务器, 提供API服务</li>
<li><code>/var/log/kube-scheduler.log</code> - 调度器, 负责产生调度决策</li>
<li><code>/var/log/kube-controller-manager.log</code> - 管理副本控制器的控制器</li>
</ul>
<!--
### Worker Nodes

* `/var/log/kubelet.log` - Kubelet, responsible for running containers on the node
* `/var/log/kube-proxy.log` - Kube Proxy, responsible for service load balancing
-->
<h3 id="工作节点">工作节点</h3>
<ul>
<li><code>/var/log/kubelet.log</code> - <code>kubelet</code>，负责在节点运行容器</li>
<li><code>/var/log/kube-proxy.log</code> - <code>kube-proxy</code>, 负责服务的负载均衡</li>
</ul>
<!--
## A general overview of cluster failure modes

This is an incomplete list of things that could go wrong, and how to adjust your cluster setup to mitigate the problems.
-->
<h2 id="集群故障模式的一般性概述">集群故障模式的一般性概述</h2>
<p>下面是一个不完整的列表，列举了一些可能的出错场景，以及通过调整集群配置来解决相关问题的方法。</p>
<!--
### Root causes:

  - VM(s) shutdown
  - Network partition within cluster, or between cluster and users
  - Crashes in Kubernetes software
  - Data loss or unavailability of persistent storage (e.g. GCE PD or AWS EBS volume)
  - Operator error, for example misconfigured Kubernetes software or application software
-->
<h3 id="根本原因">根本原因</h3>
<ul>
<li>VM(s) 关机</li>
<li>集群之间，或者集群和用户之间网络分裂</li>
<li>Kubernetes 软件本身崩溃</li>
<li>数据丢失或者持久化存储不可用（如：GCE PD 或 AWS EBS 卷）</li>
<li>操作错误，如：Kubernetes 或者应用程序配置错误</li>
</ul>
<!--
### Specific scenarios:

  - Apiserver VM shutdown or apiserver crashing
    - Results
      - unable to stop, update, or start new pods, services, replication controller
      - existing pods and services should continue to work normally, unless they depend on the Kubernetes API
  - Apiserver backing storage lost
    - Results
      - apiserver should fail to come up
      - kubelets will not be able to reach it but will continue to run the same pods and provide the same service proxying
      - manual recovery or recreation of apiserver state necessary before apiserver is restarted
-->
<h3 id="具体情况">具体情况:</h3>
<ul>
<li>API 服务器所在的 VM 关机或者 API 服务器崩溃
<ul>
<li>结果
<ul>
<li>不能停止、更新或者启动新的 Pod、服务或副本控制器</li>
<li>现有的 Pod 和服务在不依赖 Kubernetes API 的情况下应该能继续正常工作</li>
</ul>
</li>
</ul>
</li>
<li>API 服务器的后端存储丢失
<ul>
<li>结果
<ul>
<li>API 服务器应该不能启动</li>
<li>kubelet 将不能访问 API 服务器，但是能够继续运行之前的 Pod 和提供相同的服务代理</li>
<li>在 API 服务器重启之前，需要手动恢复或者重建 API 服务器的状态</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--
  - Supporting services (node controller, replication controller manager, scheduler, etc) VM shutdown or crashes
    - currently those are colocated with the apiserver, and their unavailability has similar consequences as apiserver
    - in future, these will be replicated as well and may not be co-located
    - they do not have their own persistent state
  - Individual node (VM or physical machine) shuts down
    - Results
      - pods on that Node stop running
  - Network partition
    - Results
      - partition A thinks the nodes in partition B are down; partition B thinks the apiserver is down. (Assuming the master VM ends up in partition A.)
-->
<ul>
<li>Kubernetes 服务组件（节点控制器、副本控制器管理器、调度器等）所在的 VM 关机或者崩溃
<ul>
<li>当前，这些控制器是和 API 服务器在一起运行的，它们不可用的现象是与 API 服务器类似的</li>
<li>将来，这些控制器也会复制为多份，并且可能不在运行于同一节点上</li>
<li>它们没有自己的持久状态</li>
</ul>
</li>
<li>单个节点（VM 或者物理机）关机
<ul>
<li>结果
<ul>
<li>此节点上的所有 Pod 都停止运行</li>
</ul>
</li>
</ul>
</li>
<li>网络分裂
<ul>
<li>结果
<ul>
<li>分区 A 认为分区 B 中所有的节点都已宕机；分区 B 认为 API 服务器宕机
（假定主控节点所在的 VM 位于分区 A 内)。</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--
  - Kubelet software fault
    - Results
      - crashing kubelet cannot start new pods on the node
      - kubelet might delete the pods or not
      - node marked unhealthy
      - replication controllers start new pods elsewhere
  - Cluster operator error
    - Results
      - loss of pods, services, etc
      - lost of apiserver backing store
      - users unable to read API
      - etc.
-->
<ul>
<li>kubelet 软件故障
<ul>
<li>结果
<ul>
<li>崩溃的 kubelet 就不能在其所在的节点上启动新的 Pod</li>
<li>kubelet 可能删掉 Pod 或者不删</li>
<li>节点被标识为非健康态</li>
<li>副本控制器会在其它的节点上启动新的 Pod</li>
</ul>
</li>
</ul>
</li>
<li>集群操作错误
<ul>
<li>结果
<ul>
<li>丢失 Pod 或服务等等</li>
<li>丢失 API 服务器的后端存储</li>
<li>用户无法读取API</li>
<li>等等</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--
### Mitigations:

- Action: Use IaaS provider's automatic VM restarting feature for IaaS VMs
  - Mitigates: Apiserver VM shutdown or apiserver crashing
  - Mitigates: Supporting services VM shutdown or crashes

- Action: Use IaaS providers reliable storage (e.g. GCE PD or AWS EBS volume) for VMs with apiserver+etcd
  - Mitigates: Apiserver backing storage lost

- Action: Use [high-availability](/docs/setup/production-environment/tools/kubeadm/high-availability/) configuration
  - Mitigates: Control plane node shutdown or control plane components (scheduler, API server, controller-manager) crashing
    - Will tolerate one or more simultaneous node or component failures
  - Mitigates: API server backing storage (i.e., etcd's data directory) lost
    - Assumes HA (highly-available) etcd configuration
-->
<h3 id="缓解措施">缓解措施：</h3>
<ul>
<li>
<p>措施：对于 IaaS 上的 VMs，使用 IaaS 的自动 VM 重启功能</p>
<ul>
<li>缓解：API 服务器 VM 关机或 API 服务器崩溃</li>
<li>缓解：Kubernetes 服务组件所在的 VM 关机或崩溃</li>
</ul>
</li>
<li>
<p>措施: 对于运行 API 服务器和 etcd 的 VM，使用 IaaS 提供的可靠的存储（例如 GCE PD 或者 AWS EBS 卷）</p>
<ul>
<li>缓解：API 服务器后端存储的丢失</li>
</ul>
</li>
<li>
<p>措施：使用<a href="/zh/docs/setup/production-environment/tools/kubeadm/high-availability/">高可用性</a>的配置</p>
<ul>
<li>缓解：主控节点 VM 关机或者主控节点组件（调度器、API 服务器、控制器管理器）崩馈
<ul>
<li>将容许一个或多个节点或组件同时出现故障</li>
</ul>
</li>
<li>缓解：API 服务器后端存储（例如 etcd 的数据目录）丢失
<ul>
<li>假定你使用了高可用的 etcd 配置</li>
</ul>
</li>
</ul>
</li>
</ul>
<!--
- Action: Snapshot apiserver PDs/EBS-volumes periodically
  - Mitigates: Apiserver backing storage lost
  - Mitigates: Some cases of operator error
  - Mitigates: Some cases of Kubernetes software fault

- Action: use replication controller and services in front of pods
  - Mitigates: Node shutdown
  - Mitigates: Kubelet software fault

- Action: applications (containers) designed to tolerate unexpected restarts
  - Mitigates: Node shutdown
  - Mitigates: Kubelet software fault
-->
<ul>
<li>
<p>措施：定期对 API 服务器的 PDs/EBS 卷执行快照操作</p>
<ul>
<li>缓解：API 服务器后端存储丢失</li>
<li>缓解：一些操作错误的场景</li>
<li>缓解：一些 Kubernetes 软件本身故障的场景</li>
</ul>
</li>
<li>
<p>措施：在 Pod 的前面使用副本控制器或服务</p>
<ul>
<li>缓解：节点关机</li>
<li>缓解：kubelet 软件故障</li>
</ul>
</li>
<li>
<p>措施：应用（容器）设计成容许异常重启</p>
<ul>
<li>缓解：节点关机</li>
<li>缓解：kubelet 软件故障</li>
</ul>
</li>
</ul>

</div>



    
	
  



          </main>
        </div>
      </div>
      
<footer class="d-print-none">
  <div class="footer__links">
    <nav>
      
      
      
      <a class="text-white" href="/zh/docs/home/">主页</a>
      
      <a class="text-white" href="/zh/blog/">博客</a>
      
      <a class="text-white" href="/zh/training/">培训</a>
      
      <a class="text-white" href="/zh/partners/">合作伙伴</a>
      
      <a class="text-white" href="/zh/community/">社区</a>
      
      <a class="text-white" href="/zh/case-studies/">案例分析</a>
      
    </nav>
  </div>
  <div class="container-fluid">
    <div class="row">
      <div class="col-6 col-sm-2 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="User mailing list" aria-label="User mailing list">
    <a class="text-white" target="_blank" href="https://discuss.kubernetes.io">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" href="https://twitter.com/kubernetesio">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Calendar" aria-label="Calendar">
    <a class="text-white" target="_blank" href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
      <i class="fas fa-calendar-alt"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Youtube" aria-label="Youtube">
    <a class="text-white" target="_blank" href="https://youtube.com/kubernetescommunity">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" href="https://github.com/kubernetes/kubernetes">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Slack" aria-label="Slack">
    <a class="text-white" target="_blank" href="https://slack.k8s.io">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Contribute" aria-label="Contribute">
    <a class="text-white" target="_blank" href="https://git.k8s.io/community/contributors/guide">
      <i class="fas fa-edit"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Stack Overflow" aria-label="Stack Overflow">
    <a class="text-white" target="_blank" href="https://stackoverflow.com/questions/tagged/kubernetes">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-8 text-center order-sm-2">
        <small class="text-white">&copy; 2021 The Kubernetes 作者 | 文档发布基于 <a href="https://git.k8s.io/website/LICENSE" class="light-text">CC BY 4.0</a> 授权许可</small>
        <br/>
        <small class="text-white">Copyright &copy; 2021 Linux 基金会&reg;。保留所有权利。Linux 基金会已注册并使用商标。如需了解 Linux 基金会的商标列表，请访问<a href="https://www.linuxfoundation.org/trademark-usage" class="light-text">商标使用页面</a></small>
        <br/>
        <small class="text-white">ICP license: 京ICP备17074266号-3</small>
        
        
          
        
      </div>
    </div>
  </div>
</footer>


    </div>
    
<script src="/js/popper-1.14.3.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="/js/bootstrap-4.3.1.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>











<script src="/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js" integrity="sha256-QGFiUam25LaJ53ab4DQGYe&#43;k1&#43;u3P5V0BOlj4TW07VI=" crossorigin="anonymous"></script>






  </body>
</html>
